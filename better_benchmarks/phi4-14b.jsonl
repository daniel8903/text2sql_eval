{"example_id": 2656, "sql_complexity": "multiple_joins", "prompt": "Find the drugs and their respective total sales for rare diseases indication with sales greater than the average sales for infectious diseases.", "context": "CREATE TABLE sales (id INT, drug_id INT, quarter INT, year INT, revenue FLOAT); INSERT INTO sales (id, drug_id, quarter, year, revenue) VALUES (1, 1, 1, 2022, 1500000); CREATE TABLE drugs (id INT, name VARCHAR(50), company VARCHAR(50), indication VARCHAR(50)); INSERT INTO drugs (id, name, company, indication) VALUES (1, 'DrugA', 'ABC Corp', 'Rare_Diseases');", "reference_sql": "SELECT s.drug_id, d.name, SUM(s.revenue) as total_sales FROM sales s JOIN drugs d ON s.drug_id = d.id WHERE d.indication = 'Rare_Diseases' GROUP BY s.drug_id HAVING total_sales > (SELECT AVG(s2.revenue) FROM sales s2 JOIN drugs d2 ON s2.drug_id = d2.id WHERE d2.indication = 'Infectious_Diseases')", "generated_sql": "WITH TotalSales AS (\n    SELECT \n        d.id,\n        d.name,\n        SUM(s.revenue) AS total_revenue\n    FROM \n        sales s\n    JOIN \n        drugs d ON s.drug_id = d.id\n    GROUP BY \n        d.id, d.name\n),\nInfectiousDiseasesAverage AS (\n    SELECT \n        AVG(total_revenue) AS avg_infectious_disease_sales\n    FROM \n        TotalSales ts\n    JOIN \n        drugs dr ON ts.id = dr.id\n    WHERE \n        dr.indication = 'Infectious_Diseases'\n)\nSELECT \n    ts.name,\n    ts.total_revenue\nFROM \n    TotalSales ts\nJOIN \n    drugs d ON ts.id = d.id\nCROSS JOIN \n    InfectiousDiseasesAverage ida\nWHERE \n    d.indication = 'Rare_Diseases' AND\n    ts.total_revenue > ida.avg_infectious_disease_sales;", "raw_model_output": "To solve this problem, we need to perform several steps using SQL:\n\n1. Calculate the total sales revenue for each drug.\n2. Identify which drugs are indicated for \"Rare_Diseases\".\n3. Calculate the average sales revenue for drugs indicated for \"Infectious Diseases\".\n4. Filter the drugs with \"Rare_Diseases\" indication whose total sales exceed this average.\n\nHere's how you can write the SQL query:\n\n```sql\nWITH TotalSales AS (\n    SELECT \n        d.id,\n        d.name,\n        SUM(s.revenue) AS total_revenue\n    FROM \n        sales s\n    JOIN \n        drugs d ON s.drug_id = d.id\n    GROUP BY \n        d.id, d.name\n),\nInfectiousDiseasesAverage AS (\n    SELECT \n        AVG(total_revenue) AS avg_infectious_disease_sales\n    FROM \n        TotalSales ts\n    JOIN \n        drugs dr ON ts.id = dr.id\n    WHERE \n        dr.indication = 'Infectious_Diseases'\n)\nSELECT \n    ts.name,\n    ts.total_revenue\nFROM \n    TotalSales ts\nJOIN \n    drugs d ON ts.id = d.id\nCROSS JOIN \n    InfectiousDiseasesAverage ida\nWHERE \n    d.indication = 'Rare_Diseases' AND\n    ts.total_revenue > ida.avg_infectious_disease_sales;\n```\n\n### Explanation:\n\n- **TotalSales CTE**: This common table expression calculates the total sales revenue for each drug by joining the `sales` and `drugs` tables, grouping by drug ID and name.\n\n- **InfectiousDiseasesAverage CTE**: This CTE computes the average sales revenue of drugs indicated for \"Infectious_Diseases\" using the previously calculated total sales.\n\n- **Final SELECT Statement**: \n  - Joins the `TotalSales` with the `drugs` table to filter only those drugs that have an indication of \"Rare_Diseases\".\n  - Uses a `CROSS JOIN` with the `InfectiousDiseasesAverage` CTE to compare each drug's total revenue against the average sales for \"Infectious_Diseases\".\n  - Filters out the drugs whose total revenue is greater than this calculated average.", "latency_sec": 17.760276794433594, "total_duration_sec": 17.748869741, "load_duration_sec": 5.359828621, "tokens_prompt": 201, "prompt_eval_sec": 0.210104357, "tokens_completion": 472, "completion_eval_sec": 12.175672901, "tokens_total": 673, "tokens_per_sec": 37.89355356279869, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in how they calculate the average revenue. The Reference SQL computes the average of individual sales revenues for 'Infectious_Diseases', while the Generated SQL calculates the average of total drug revenues (aggregated by drug) for 'Infectious_Diseases'. This leads to different threshold values in the HAVING clause, resulting in potentially different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in how they calculate the average sales. The Reference SQL computes the average of individual sales (s2.revenue) for infectious diseases, while the Generated SQL calculates the average of total sales per drug (total_revenue) for infectious diseases. The original question's phrasing ('sales greater than the average sales for infectious diseases') is ambiguous, but the Generated SQL better aligns with the business intent of comparing total drug sales against an average of drug-level sales. The Reference SQL's approach may incorrectly compare against per-sale averages. Both queries are technically valid, but the Generated SQL's structure explicitly computes the average of total sales per drug, which is more aligned with typical business metrics for drug performance.", "overall_assessment": "differently_correct"}}
{"example_id": 3008, "sql_complexity": "multiple_joins", "prompt": "Who are the users who used electric vehicles and their trip details?", "context": "CREATE TABLE users (id INT, name VARCHAR(50), age INT, gender VARCHAR(10), city VARCHAR(50));CREATE TABLE vehicles (id INT, vehicle_type VARCHAR(20), is_electric BOOLEAN);CREATE TABLE trips (id INT, user_id INT, vehicle_id INT, trip_distance FLOAT, trip_duration INT, departure_time TIMESTAMP, arrival_time TIMESTAMP);INSERT INTO users (id, name, age, gender, city) VALUES (3, 'Alex', 30, 'Female', 'New York');INSERT INTO vehicles (id, vehicle_type, is_electric) VALUES (1, 'Tesla', true), (2, 'Bike', false);INSERT INTO trips (id, user_id, vehicle_id, trip_distance, trip_duration, departure_time, arrival_time) VALUES (3, 3, 1, 15.3, 25, '2022-01-03 12:00:00', '2022-01-03 12:25:00');", "reference_sql": "SELECT u.name, v.vehicle_type, t.trip_distance, t.trip_duration FROM users u JOIN trips t ON u.id = t.user_id JOIN vehicles v ON t.vehicle_id = v.id WHERE v.is_electric = true;", "generated_sql": "SELECT \n    u.id AS user_id,\n    u.name AS user_name,\n    v.vehicle_type,\n    t.trip_distance,\n    t.trip_duration,\n    t.departure_time,\n    t.arrival_time\nFROM \n    users u\nJOIN \n    trips t ON u.id = t.user_id\nJOIN \n    vehicles v ON t.vehicle_id = v.id\nWHERE \n    v.is_electric = true;", "raw_model_output": "To find the users who used electric vehicles along with their trip details, we need to join the `users`, `vehicles`, and `trips` tables. We will filter for trips where the vehicle is electric (`is_electric = true`). Here's the SQL query:\n\n```sql\nSELECT \n    u.id AS user_id,\n    u.name AS user_name,\n    v.vehicle_type,\n    t.trip_distance,\n    t.trip_duration,\n    t.departure_time,\n    t.arrival_time\nFROM \n    users u\nJOIN \n    trips t ON u.id = t.user_id\nJOIN \n    vehicles v ON t.vehicle_id = v.id\nWHERE \n    v.is_electric = true;\n```\n\nThis query retrieves the user ID, name, vehicle type, trip distance, trip duration, and departure/arrival times for all trips where an electric vehicle was used.", "latency_sec": 4.807927131652832, "total_duration_sec": 4.802199644, "load_duration_sec": 0.019559814, "tokens_prompt": 291, "prompt_eval_sec": 0.049777459, "tokens_completion": 179, "completion_eval_sec": 4.731516835, "tokens_total": 470, "tokens_per_sec": 97.7552253040131, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL selects only 4 columns (name, vehicle_type, trip_distance, trip_duration), while the Generated SQL includes 7 columns (user_id, user_name, vehicle_type, trip_distance, trip_duration, departure_time, arrival_time). The additional columns in the Generated SQL change the result set structure, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent because the generated query includes additional columns (user_id, departure_time, arrival_time) not present in the reference. Both correctly answer the business question by identifying electric vehicle users and their trip details, but the generated query provides more comprehensive trip information (departure/arrival times) which better fulfills the 'trip details' requirement. The reference query is technically correct but less complete. Both use equivalent joins and filtering, but the generated version is more elegant in its explicit column selection and aliasing.", "overall_assessment": "differently_correct"}}
{"example_id": 2531, "sql_complexity": "basic SQL", "prompt": "Who is the top customer by sales in 2022?", "context": "CREATE TABLE customers (customer_id INT, total_sales_2022 FLOAT); INSERT INTO customers (customer_id, total_sales_2022) VALUES (1, 25000.0), (2, 30000.0), (3, 22000.0), (4, 35000.0);", "reference_sql": "SELECT customer_id, total_sales_2022 FROM customers ORDER BY total_sales_2022 DESC LIMIT 1;", "generated_sql": "SELECT customer_id \nFROM customers \nORDER BY total_sales_2022 DESC \nLIMIT 1;", "raw_model_output": "To find the top customer by sales in 2022 from the `customers` table, you can use the following SQL query:\n\n```sql\nSELECT customer_id \nFROM customers \nORDER BY total_sales_2022 DESC \nLIMIT 1;\n```\n\nThis query orders the customers by their `total_sales_2022` in descending order and selects the top one.", "latency_sec": 1.9551401138305664, "total_duration_sec": 1.950326646, "load_duration_sec": 0.011692255, "tokens_prompt": 149, "prompt_eval_sec": 0.020111577, "tokens_completion": 75, "completion_eval_sec": 1.91785839, "tokens_total": 224, "tokens_per_sec": 114.56979395769892, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query returns both customer_id and total_sales_2022 columns, while the generated query only returns customer_id. Although both order by total_sales_2022 DESC and limit to 1 row, the generated query omits the total_sales_2022 column, making their result sets structurally different.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly identify the top customer by sales in 2022 via the customer_id. The reference query includes an extra column (total_sales_2022) that isn't required by the question, while the generated query is more efficient by selecting only the necessary column. The generated query maintains semantic equivalence for the business intent while being more optimized.", "overall_assessment": "correct"}}
{"example_id": 3792, "sql_complexity": "single join", "prompt": "What is the maximum distance traveled by an electric vehicle in a single trip, grouped by vehicle model?", "context": "CREATE TABLE Trips (trip_id INT, vehicle_id INT, distance FLOAT); CREATE TABLE ElectricVehicleModels (vehicle_id INT, vehicle_model TEXT);", "reference_sql": "SELECT evm.vehicle_model, MAX(trips.distance) AS max_distance_traveled FROM Trips trips INNER JOIN ElectricVehicleModels evm ON trips.vehicle_id = evm.vehicle_id GROUP BY 1;", "generated_sql": "SELECT evm.vehicle_model, MAX(t.distance) AS max_distance\nFROM Trips t\nJOIN ElectricVehicleModels evm ON t.vehicle_id = evm.vehicle_id\nGROUP BY evm.vehicle_model;", "raw_model_output": "To find the maximum distance traveled by an electric vehicle in a single trip, grouped by vehicle model, you can use the following SQL query:\n\n```sql\nSELECT evm.vehicle_model, MAX(t.distance) AS max_distance\nFROM Trips t\nJOIN ElectricVehicleModels evm ON t.vehicle_id = evm.vehicle_id\nGROUP BY evm.vehicle_model;\n```\n\nThis query performs a join between the `Trips` and `ElectricVehicleModels` tables on the `vehicle_id` column. It then groups the results by `vehicle_model` and calculates the maximum distance for each group using the `MAX()` function.", "latency_sec": 3.2715868949890137, "total_duration_sec": 3.266918497, "load_duration_sec": 0.013997457, "tokens_prompt": 122, "prompt_eval_sec": 0.016029513, "tokens_completion": 127, "completion_eval_sec": 3.236338663, "tokens_total": 249, "tokens_per_sec": 76.10985371697919, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries join the same tables on vehicle_id, group by vehicle_model, and calculate the maximum distance. The reference uses GROUP BY 1 (position-based) while the generated query uses the explicit column name, but they reference the same column. Table aliases (trips/t, evm) don't affect semantics.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the maximum distance per vehicle model by joining the Trips and ElectricVehicleModels tables. The Reference SQL uses a positional GROUP BY (GROUP BY 1) while the Generated SQL explicitly groups by the vehicle_model column. Both produce identical results, as the semantic logic and table relationships are equivalent. The Generated SQL improves readability with clearer table aliases (t instead of trips) and explicit grouping, but neither query has technical deficiencies. Both fully address the business intent of identifying maximum trip distances by model.", "overall_assessment": "correct"}}
{"example_id": 2311, "sql_complexity": "subqueries", "prompt": "Determine the percentage of sales from each ingredient category", "context": "CREATE TABLE Sales_Details (sale_id INT, ingredient_id INT, quantity INT); INSERT INTO Sales_Details (sale_id, ingredient_id, quantity) VALUES (1, 1, 2), (1, 2, 8), (2, 1, 3), (2, 2, 7); CREATE TABLE Ingredient_Categories (ingredient_id INT, ingredient_category VARCHAR(255)); INSERT INTO Ingredient_Categories (ingredient_id, ingredient_category) VALUES (1, 'Legumes'), (2, 'Poultry');", "reference_sql": "SELECT ingredient_category, SUM(quantity) AS total_quantity, SUM(quantity) * 100.0 / (SELECT SUM(quantity) FROM Sales_Details) AS percentage_of_sales FROM Sales_Details, Ingredient_Categories WHERE Sales_Details.ingredient_id = Ingredient_Categories.ingredient_id GROUP BY ingredient_category;", "generated_sql": "SELECT \n    ic.ingredient_category,\n    SUM(sd.quantity) AS total_quantity_sold,\n    (SUM(sd.quantity) * 100.0 / (SELECT SUM(quantity) FROM Sales_Details)) AS percentage_of_sales\nFROM \n    Sales_Details sd\nJOIN \n    Ingredient_Categories ic ON sd.ingredient_id = ic.ingredient_id\nGROUP BY \n    ic.ingredient_category;", "raw_model_output": "To determine the percentage of sales from each ingredient category, we need to calculate the total quantity sold for each category and then compute the percentage based on the overall total quantity sold. Here's how you can achieve this with a single SQL statement:\n\n```sql\nSELECT \n    ic.ingredient_category,\n    SUM(sd.quantity) AS total_quantity_sold,\n    (SUM(sd.quantity) * 100.0 / (SELECT SUM(quantity) FROM Sales_Details)) AS percentage_of_sales\nFROM \n    Sales_Details sd\nJOIN \n    Ingredient_Categories ic ON sd.ingredient_id = ic.ingredient_id\nGROUP BY \n    ic.ingredient_category;\n```\n\n### Explanation:\n\n1. **Join Tables**: We join `Sales_Details` (`sd`) with `Ingredient_Categories` (`ic`) on the `ingredient_id` to associate each sale with its ingredient category.\n\n2. **Aggregate Sales by Category**: We use `SUM(sd.quantity)` to calculate the total quantity sold for each ingredient category.\n\n3. **Calculate Total Sales**: The subquery `(SELECT SUM(quantity) FROM Sales_Details)` calculates the overall total quantity of all sales.\n\n4. **Compute Percentage**: For each category, we compute the percentage of total sales using `(SUM(sd.quantity) * 100.0 / (SELECT SUM(quantity) FROM Sales_Details))`.\n\n5. **Group By Category**: We group the results by `ingredient_category` to get the totals and percentages for each category separately.\n\nThis query will output each ingredient category along with its total quantity sold and the percentage of total sales it represents.", "latency_sec": 8.29509687423706, "total_duration_sec": 8.290127958, "load_duration_sec": 0.012916816, "tokens_prompt": 192, "prompt_eval_sec": 0.03182581, "tokens_completion": 316, "completion_eval_sec": 8.244674378, "tokens_total": 508, "tokens_per_sec": 61.240996663673464, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the total quantity sold per ingredient category and the percentage of total sales. They use equivalent JOIN logic (implicit vs explicit), same aggregation functions, and identical subquery for percentage calculation. The GROUP BY clause references the same column in both cases, and the aliases do not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the percentage of sales per ingredient category by summing quantities and dividing by total sales. The reference query uses an implicit join (comma syntax) which is functionally equivalent to the generated query's explicit JOIN. However, the generated query is more readable with table aliases and explicit join syntax. Both handle the percentage calculation correctly using a scalar subquery for total sales. The grouping by ingredient_category is valid given the schema, though it assumes category names are unique. The generated query's structure is more modern and maintainable.", "overall_assessment": "correct"}}
{"example_id": 3329, "sql_complexity": "set operations", "prompt": "Which causes received funding from donors in both the United States and Canada?", "context": "CREATE TABLE donor_location (donor_id INT, country VARCHAR(50), cause VARCHAR(50), donation DECIMAL(10,2)); INSERT INTO donor_location (donor_id, country, cause, donation) VALUES (1, 'United States', 'Global Health', 1000.00), (2, 'Canada', 'Education', 2000.00), (3, 'United States', 'Environment', 1500.00), (4, 'Canada', 'Animal Welfare', 2500.00);", "reference_sql": "SELECT cause FROM donor_location WHERE country = 'United States' INTERSECT SELECT cause FROM donor_location WHERE country = 'Canada';", "generated_sql": "SELECT DISTINCT dl1.cause\nFROM donor_location dl1\nJOIN donor_location dl2 ON dl1.cause = dl2.cause\nWHERE dl1.country = 'United States' AND dl2.country = 'Canada';", "raw_model_output": "To find which causes received funding from donors in both the United States and Canada, we need to identify causes that have donations recorded for each of these countries. We can achieve this by using a self-join on the `donor_location` table.\n\nHere's the SQL query:\n\n```sql\nSELECT DISTINCT dl1.cause\nFROM donor_location dl1\nJOIN donor_location dl2 ON dl1.cause = dl2.cause\nWHERE dl1.country = 'United States' AND dl2.country = 'Canada';\n```\n\n### Explanation:\n- We perform a self-join on the `donor_location` table, aliasing it as `dl1` and `dl2`.\n- The join condition is that the causes (`cause`) in both aliases must be the same.\n- We filter for rows where one instance of the cause comes from the United States (`dl1.country = 'United States'`) and another from Canada (`dl2.country = 'Canada'`).\n- Using `DISTINCT`, we ensure each cause is listed only once, even if there are multiple donors or donations matching the criteria.", "latency_sec": 5.9258809089660645, "total_duration_sec": 5.920895642, "load_duration_sec": 0.015294425, "tokens_prompt": 194, "prompt_eval_sec": 0.033889138, "tokens_completion": 226, "completion_eval_sec": 5.870327216, "tokens_total": 420, "tokens_per_sec": 70.87553841396397, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve causes that exist in both 'United States' and 'Canada' donor records. The reference uses INTERSECT to find common causes, while the generated query uses a JOIN on cause with DISTINCT to achieve the same result. Both ensure uniqueness and only return causes present in both countries.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries correctly identify causes present in both countries. The reference uses INTERSECT which explicitly handles set intersection, while the generated query uses a JOIN with a WHERE clause to achieve the same result. Both would return identical results given the sample data. However, the reference query is more concise and directly expresses the intent of finding common causes. The generated query requires a JOIN and DISTINCT which, while logically correct, adds unnecessary complexity. Both fulfill the business intent of identifying causes with funding from both countries.", "overall_assessment": "correct"}}
{"example_id": 2912, "sql_complexity": "single join", "prompt": "Which company has manufactured the most satellites?", "context": "CREATE TABLE manufacturers (id INT, name TEXT); CREATE TABLE satellites (id INT, manufacturer_id INT, name TEXT, launch_date DATE); INSERT INTO manufacturers (id, name) VALUES (1, 'SpaceX'), (2, 'Blue Origin'), (3, 'ISRO'), (4, 'CAST'); INSERT INTO satellites (id, manufacturer_id, name, launch_date) VALUES (1, 1, 'StarDragon', '2012-05-25'), (2, 1, 'Falcon', '2015-12-21'), (3, 2, 'New Glenn', '2022-01-11'), (4, 3, 'ChinaSat 1E', '2000-12-05'), (5, 3, 'ChinaSat 2A', '2003-08-13'), (6, 4, 'Shijian 9', '2017-11-19'), (7, 1, 'StarLink', '2020-05-24'), (8, 1, 'StarLink', '2020-06-13');", "reference_sql": "SELECT m.name, COUNT(s.id) FROM manufacturers m JOIN satellites s ON m.id = s.manufacturer_id GROUP BY m.name ORDER BY COUNT(s.id) DESC;", "generated_sql": "SELECT m.name AS manufacturer_name, COUNT(s.id) AS satellite_count\nFROM manufacturers m\nJOIN satellites s ON m.id = s.manufacturer_id\nGROUP BY m.id, m.name\nORDER BY satellite_count DESC\nLIMIT 1;", "raw_model_output": "To determine which manufacturer has produced the most satellites, we need to count the number of satellites associated with each manufacturer and then identify the manufacturer with the highest count. Here's how you can achieve this using a single SQL query:\n\n```sql\nSELECT m.name AS manufacturer_name, COUNT(s.id) AS satellite_count\nFROM manufacturers m\nJOIN satellites s ON m.id = s.manufacturer_id\nGROUP BY m.id, m.name\nORDER BY satellite_count DESC\nLIMIT 1;\n```\n\n### Explanation:\n- **Join**: We join the `manufacturers` table with the `satellites` table on the `manufacturer_id` to associate each satellite with its manufacturer.\n- **Group By**: We group the results by `m.id` and `m.name` to count satellites for each manufacturer.\n- **Count**: The `COUNT(s.id)` function counts the number of satellites for each manufacturer.\n- **Order By**: We order the results in descending order based on the satellite count to get the manufacturer with the most satellites at the top.\n- **Limit 1**: We limit the result to just one row, which will be the manufacturer with the highest satellite count.", "latency_sec": 6.323519229888916, "total_duration_sec": 6.318698184, "load_duration_sec": 0.01185305, "tokens_prompt": 312, "prompt_eval_sec": 0.048785726, "tokens_completion": 237, "completion_eval_sec": 6.257309074, "tokens_total": 549, "tokens_per_sec": 86.81874444298072, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns all manufacturers sorted by their satellite count in descending order, while the Generated SQL only returns the top manufacturer (due to LIMIT 1). Additionally, the Generated SQL groups by both m.id and m.name, which is functionally equivalent to grouping by m.name alone in this case (since id is a primary key), but the LIMIT 1 clause makes the result sets fundamentally different.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "While both queries correctly count satellites per manufacturer, the Generated SQL is more technically robust and efficient. The Reference SQL groups by m.name only, which may fail in strict SQL modes where non-aggregated columns must match GROUP BY clauses (since m.id is the primary key, grouping by name alone is functionally dependent but not universally safe). The Generated SQL groups by both m.id and m.name, ensuring compatibility across SQL implementations. Additionally, the Generated SQL uses LIMIT 1 to directly answer the question, whereas the Reference SQL returns all manufacturers ordered by count, requiring additional processing to extract the top result. Both fulfill the business intent, but the Generated SQL is more efficient and precise.", "overall_assessment": "differently_correct"}}
{"example_id": 3170, "sql_complexity": "aggregation", "prompt": "Determine the total production quantity of silver for mining sites in Mexico, between the dates '2017-05-01' and '2017-09-30', having less than 40 employees.", "context": "CREATE TABLE silver_mine_2 (site_id INT, country VARCHAR(50), num_employees INT, extraction_date DATE, quantity INT); INSERT INTO silver_mine_2 (site_id, country, num_employees, extraction_date, quantity) VALUES (1, 'Mexico', 35, '2017-05-02', 1200), (2, 'Mexico', 30, '2017-08-31', 1800), (3, 'Mexico', 37, '2017-07-04', 2200);", "reference_sql": "SELECT country, SUM(quantity) as total_silver_prod FROM silver_mine_2 WHERE num_employees < 40 AND country = 'Mexico' AND extraction_date >= '2017-05-01' AND extraction_date <= '2017-09-30' GROUP BY country;", "generated_sql": "SELECT SUM(quantity) AS total_production_quantity\nFROM silver_mine_2\nWHERE country = 'Mexico'\n  AND extraction_date BETWEEN '2017-05-01' AND '2017-09-30'\n  AND num_employees < 40;", "raw_model_output": "To determine the total production quantity of silver for mining sites in Mexico within the specified date range and employee count, you can use the following SQL query:\n\n```sql\nSELECT SUM(quantity) AS total_production_quantity\nFROM silver_mine_2\nWHERE country = 'Mexico'\n  AND extraction_date BETWEEN '2017-05-01' AND '2017-09-30'\n  AND num_employees < 40;\n```\n\nThis query filters the records based on the specified conditions and calculates the sum of the `quantity` column for those filtered records.", "latency_sec": 3.058274030685425, "total_duration_sec": 3.05352404, "load_duration_sec": 0.022600766, "tokens_prompt": 228, "prompt_eval_sec": 0.038592625, "tokens_completion": 114, "completion_eval_sec": 2.991713294, "tokens_total": 342, "tokens_per_sec": 111.82778147691052, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the total silver production for Mexican mines meeting the same conditions (num_employees < 40, extraction_date between 2017-05-01 and 2017-09-30). The Reference query groups by country (which is fixed as 'Mexico' in the WHERE clause) while the Generated query directly sums the filtered rows. Since all filtered rows belong to Mexico, both return the same aggregate value.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the total silver production for Mexican sites with <40 employees between the specified dates. The Reference SQL includes an unnecessary GROUP BY country clause (since country is filtered to 'Mexico'), while the Generated SQL uses BETWEEN for cleaner date filtering. Both produce identical results, but the Generated SQL is more efficient and directly addresses the question without redundant grouping. The business intent is fully met by both, but the Generated version is more elegant.", "overall_assessment": "correct"}}
{"example_id": 3518, "sql_complexity": "basic SQL", "prompt": "Insert new records of ticket sales for a new event, including event and salesperson information.", "context": "CREATE TABLE salesperson (salesperson_id INT, name VARCHAR(50), position VARCHAR(50)); CREATE TABLE tickets (ticket_id INT, salesperson_id INT, event_id INT, price DECIMAL(5,2), quantity INT); CREATE TABLE events (event_id INT, name VARCHAR(50), date DATE); INSERT INTO salesperson VALUES (1, 'John Doe', 'Senior Salesperson'); INSERT INTO events VALUES (2, 'New Event', '2023-04-15');", "reference_sql": "INSERT INTO tickets (ticket_id, salesperson_id, event_id, price, quantity) VALUES (2, 1, 2, 75, 50), (3, 2, 2, 65, 75); INSERT INTO events (event_id, name, date) VALUES (2, 'New Event', '2023-04-15');", "generated_sql": "-- Step 1: Insert the new event into the events table.\nINSERT INTO events (event_id, name, date)\nVALUES (3, 'Special Concert', '2023-05-20');\n\n-- Step 2: Insert ticket sales for this event by a specific salesperson.\nINSERT INTO tickets (ticket_id, salesperson_id, event_id, price, quantity)\nVALUES \n(1, 1, 3, 50.00, 10);", "raw_model_output": "To insert new records of ticket sales for a new event, we need to ensure that the necessary data is available in all relevant tables. Based on your schema, you have three main tables: `salesperson`, `tickets`, and `events`. \n\nLet's assume you want to add a new event and then record some ticket sales associated with this event by a specific salesperson.\n\nHere\u2019s how you can do it:\n\n1. **Insert the New Event**: First, insert the details of the new event into the `events` table.\n2. **Insert Ticket Sales**: Then, use the newly inserted event's ID to add records in the `tickets` table for ticket sales by a specific salesperson.\n\nAssuming you want to add an event named \"Special Concert\" on '2023-05-20' and record that John Doe (salesperson_id = 1) sold 10 tickets at $50 each, here is how you can do it:\n\n```sql\n-- Step 1: Insert the new event into the events table.\nINSERT INTO events (event_id, name, date)\nVALUES (3, 'Special Concert', '2023-05-20');\n\n-- Step 2: Insert ticket sales for this event by a specific salesperson.\nINSERT INTO tickets (ticket_id, salesperson_id, event_id, price, quantity)\nVALUES \n(1, 1, 3, 50.00, 10);\n```\n\n### Explanation:\n\n- **Insert into `events`**: We insert a new row with an `event_id` of 3 for the \"Special Concert\" on '2023-05-20'.\n  \n- **Insert into `tickets`**: We then add a ticket sale record where:\n  - `ticket_id` is set to 1 (assuming it's unique and not auto-incremented).\n  - `salesperson_id` is 1, corresponding to John Doe.\n  - `event_id` is 3, which matches the newly inserted event.\n  - `price` is $50.00 per ticket.\n  - `quantity` is 10 tickets sold.\n\nMake sure that any IDs used (like `ticket_id`, `salesperson_id`, and `event_id`) are valid according to your database's constraints and existing data. Adjust these values as necessary based on your specific requirements or existing data.", "latency_sec": 12.52997612953186, "total_duration_sec": 12.525272068, "load_duration_sec": 0.011551909, "tokens_prompt": 190, "prompt_eval_sec": 0.026855813, "tokens_completion": 481, "completion_eval_sec": 12.48608308, "tokens_total": 671, "tokens_per_sec": 53.55157847575801, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL inserts tickets for event_id=2 with specific prices/quantities and reinserts the same event_id=2 into events (which may cause duplication). The Generated SQL inserts a new event (event_id=3) and a single ticket for that event with different values. The data inserted (event IDs, prices, quantities) differs between the two queries.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is technically flawed as it attempts to reinsert event_id 2 which likely already exists (from the context's INSERT INTO events). It also inserts tickets into an existing event rather than a 'new' event as requested. The Generated SQL correctly creates a new event (event_id 3) and inserts a ticket for it, aligning with the 'new event' requirement. While neither query fully satisfies the 'insert new records' requirement (both have partial inserts), the Generated SQL better addresses the business intent of creating a new event. The Reference SQL's duplication of existing event data makes it less correct technically and semantically.", "overall_assessment": "differently_correct"}}
{"example_id": 3925, "sql_complexity": "set operations", "prompt": "What is the total number of students and staff with accommodations in the \"disability_services\" schema, excluding the \"accessibility_parking\" type?", "context": "CREATE SCHEMA disability_services; CREATE TABLE staff (id INT, name VARCHAR(50), accommodation VARCHAR(50)); CREATE TABLE students (id INT, name VARCHAR(50), accommodation VARCHAR(50));", "reference_sql": "SELECT COUNT(*) FROM disability_services.staff WHERE accommodation != 'accessibility_parking' UNION SELECT COUNT(*) FROM disability_services.students WHERE accommodation != 'accessibility_parking';", "generated_sql": "SELECT COUNT(*) AS total_count\nFROM (\n    SELECT id FROM disability_services.staff WHERE accommodation <> 'accessibility_parking'\n    UNION ALL\n    SELECT id FROM disability_services.students WHERE accommodation <> 'accessibility_parking'\n) AS combined;", "raw_model_output": "To find the total number of students and staff with accommodations other than \"accessibility_parking\", we need to count entries from both `staff` and `students` tables where the `accommodation` column is not equal to \"accessibility_parking\". We can achieve this by using a UNION ALL to combine results from both tables, followed by counting the distinct rows. Here's how you can write the SQL query:\n\n```sql\nSELECT COUNT(*) AS total_count\nFROM (\n    SELECT id FROM disability_services.staff WHERE accommodation <> 'accessibility_parking'\n    UNION ALL\n    SELECT id FROM disability_services.students WHERE accommodation <> 'accessibility_parking'\n) AS combined;\n```\n\nThis query works as follows:\n- The subquery selects `id` from the `staff` table where `accommodation` is not \"accessibility_parking\".\n- Similarly, it selects `id` from the `students` table with the same condition.\n- These results are combined using `UNION ALL`, which includes all entries (including duplicates) from both tables.\n- The outer query counts the total number of rows in this combined result set.", "latency_sec": 5.923189878463745, "total_duration_sec": 5.91958676, "load_duration_sec": 0.01896953, "tokens_prompt": 142, "prompt_eval_sec": 0.017857339, "tokens_completion": 230, "completion_eval_sec": 5.881824526, "tokens_total": 372, "tokens_per_sec": 62.80399710847746, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns two separate counts (one for staff and one for students) via UNION, producing two rows. The Generated SQL combines all matching rows from both tables using UNION ALL and then counts the total number of rows, producing a single value. The output structure and results differ: the Reference returns two counts, while the Generated returns their sum.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference query uses UNION to combine two separate COUNT(*) results, producing two rows (one for staff, one for students) rather than a single total. This fails to meet the business intent of returning a single total count. The generated query correctly combines all qualifying records (using UNION ALL) into a single result set and then counts them, producing the accurate total. While both exclude 'accessibility_parking', the reference's structure inherently misaligns with the requested output format. The generated query is more efficient as it avoids redundant counting and properly aggregates results.", "overall_assessment": "incorrect"}}
{"example_id": 3340, "sql_complexity": "subqueries", "prompt": "Calculate the total revenue for garments manufactured in the US and sold in California.", "context": "CREATE TABLE garment_manufacturing(id INT PRIMARY KEY, garment_id INT, country VARCHAR(50), material VARCHAR(50), manufacturing_date DATE, quantity INT); CREATE TABLE garment_sales(id INT PRIMARY KEY, garment_id INT, store_id INT, sale_date DATE, units INT, revenue DECIMAL(10,2));", "reference_sql": "SELECT SUM(gs.revenue) FROM garment_manufacturing gm JOIN garment_sales gs ON gm.garment_id = gs.garment_id WHERE gm.country = 'United States' AND gs.store_id IN (SELECT id FROM stores WHERE region = 'California');", "generated_sql": "SELECT SUM(gs.revenue) AS total_revenue\nFROM garment_manufacturing gm\nJOIN garment_sales gs ON gm.garment_id = gs.garment_id\nJOIN stores s ON gs.store_id = s.store_id\nWHERE gm.country = 'US'\n  AND s.location = 'California';", "raw_model_output": "To calculate the total revenue for garments manufactured in the US and sold in California, we need to join the `garment_manufacturing` table with the `garment_sales` table on the `garment_id`. Additionally, we'll assume there is a way to identify stores located in California. Since the schema provided does not include store information or location data, I will proceed under the assumption that such data exists and can be accessed through an additional table named `stores`, which includes columns like `store_id` and `location`.\n\nHere's how you would write the SQL query:\n\n```sql\nSELECT SUM(gs.revenue) AS total_revenue\nFROM garment_manufacturing gm\nJOIN garment_sales gs ON gm.garment_id = gs.garment_id\nJOIN stores s ON gs.store_id = s.store_id\nWHERE gm.country = 'US'\n  AND s.location = 'California';\n```\n\n### Explanation:\n- **Joins**: \n  - We join `garment_manufacturing` (`gm`) with `garment_sales` (`gs`) on the `garment_id`.\n  - We also assume a join with a hypothetical `stores` table to filter sales by location.\n  \n- **Filtering**:\n  - The `WHERE` clause filters garments manufactured in the US (`gm.country = 'US'`).\n  - It further filters sales that occurred in stores located in California (`s.location = 'California'`).\n\n- **Aggregation**:\n  - We use `SUM(gs.revenue)` to calculate the total revenue from these filtered records.\n\nThis query assumes the existence of a `stores` table with relevant location data. If such a table does not exist, additional information would be needed to accurately filter sales by store location.", "latency_sec": 9.352559089660645, "total_duration_sec": 9.34814201, "load_duration_sec": 0.015838695, "tokens_prompt": 151, "prompt_eval_sec": 0.020650767, "tokens_completion": 358, "completion_eval_sec": 9.310644322, "tokens_total": 509, "tokens_per_sec": 54.42360696364966, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in two key aspects. First, the Reference uses 'United States' while the Generated uses 'US' for the country condition. Second, the Reference filters stores via a subquery checking 'region = 'California'', whereas the Generated joins with stores and checks 'location = 'California''. These differences in column names ('region' vs 'location') and literal values ('United States' vs 'US') make the queries non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The queries differ in two critical aspects: 1) The reference uses 'United States' while the generated uses 'US' for country comparison, which may not match stored data. 2) The reference uses a subquery on 'region' while the generated joins on 'location' - the schema doesn't define these columns, but assuming 'region' is correct for California, the generated query's 'location' may be semantically incorrect. Both queries assume a non-existent 'stores' table, but the reference's subquery approach is more directly aligned with the business intent of filtering by California sales. The generated query's JOIN introduces unnecessary complexity and potential performance issues compared to the reference's direct subquery.", "overall_assessment": "differently_correct"}}
{"example_id": 596, "sql_complexity": "basic SQL", "prompt": "What is the minimum energy production cost of wind farms in Spain?", "context": "CREATE TABLE wind_farm_costs (id INT, name TEXT, country TEXT, energy_production_cost FLOAT); INSERT INTO wind_farm_costs (id, name, country, energy_production_cost) VALUES (1, 'Las Tiesas', 'Spain', 0.045), (2, 'Eolo', 'Spain', 0.050);", "reference_sql": "SELECT MIN(energy_production_cost) FROM wind_farm_costs WHERE country = 'Spain';", "generated_sql": "SELECT MIN(energy_production_cost) AS min_energy_production_cost\nFROM wind_farm_costs\nWHERE country = 'Spain';", "raw_model_output": "To find the minimum energy production cost of wind farms located in Spain from the `wind_farm_costs` table, you can use the following SQL query:\n\n```sql\nSELECT MIN(energy_production_cost) AS min_energy_production_cost\nFROM wind_farm_costs\nWHERE country = 'Spain';\n```\n\nThis query selects the smallest value of the `energy_production_cost` column for rows where the `country` is 'Spain'. The result will be labeled as `min_energy_production_cost`.", "latency_sec": 2.5619513988494873, "total_duration_sec": 2.555255366, "load_duration_sec": 0.026312469, "tokens_prompt": 156, "prompt_eval_sec": 0.02462208, "tokens_completion": 99, "completion_eval_sec": 2.502357243, "tokens_total": 255, "tokens_per_sec": 99.53350407603929, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the minimum energy_production_cost for wind farms in Spain. The generated query adds an alias (min_energy_production_cost) to the result column, but this does not affect the semantic value of the output. The MIN() function and WHERE clause are identical in both queries.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly retrieve the minimum energy production cost for Spanish wind farms by filtering on 'Spain' and using MIN(). The generated query adds an alias (AS min_energy_production_cost) which improves readability without altering the result. While the reference query is functionally identical, the generated version provides a more descriptive column name, making the output clearer for business users. Neither query has efficiency issues, but the generated version demonstrates better SQL practices by explicitly naming the output column.", "overall_assessment": "correct"}}
{"example_id": 2604, "sql_complexity": "subqueries", "prompt": "What is the maximum number of virtual tours taken by a single user in the UK?", "context": "CREATE TABLE virtual_tour_data (user_id INT, hotel_id INT, tour_date DATE); INSERT INTO virtual_tour_data (user_id, hotel_id, tour_date) VALUES (1, 10, '2022-01-01'), (2, 11, '2022-01-03'), (3, 12, '2022-01-05'), (4, 10, '2022-01-07'), (5, 10, '2022-01-09'); CREATE TABLE hotels (hotel_id INT, hotel_name TEXT, country TEXT); INSERT INTO hotels (hotel_id, hotel_name, country) VALUES (10, 'Royal Park Hotel', 'UK'), (11, 'The Ritz London', 'UK'), (12, 'Hotel de Crillon', 'France');", "reference_sql": "SELECT MAX(vt.user_tours) FROM (SELECT user_id, COUNT(DISTINCT hotel_id) as user_tours FROM virtual_tour_data WHERE country = 'UK' GROUP BY user_id) as vt;", "generated_sql": "SELECT MAX(tour_count) AS max_tours_in_uk\nFROM (\n    SELECT vd.user_id, COUNT(*) AS tour_count\n    FROM virtual_tour_data vd\n    JOIN hotels h ON vd.hotel_id = h.hotel_id\n    WHERE h.country = 'UK'\n    GROUP BY vd.user_id\n) AS user_tour_counts;", "raw_model_output": "To solve this problem, we need to determine the maximum number of virtual tours taken by a single user for hotels located in the UK. Here's how you can construct the SQL query:\n\n1. **Join** the `virtual_tour_data` table with the `hotels` table on `hotel_id` to filter only those tours that are associated with hotels in the UK.\n2. **Group** the results by `user_id` to count the number of virtual tours each user has taken for hotels in the UK.\n3. Use the `MAX()` function to find the maximum number of tours taken by any single user.\n\nHere's the SQL query:\n\n```sql\nSELECT MAX(tour_count) AS max_tours_in_uk\nFROM (\n    SELECT vd.user_id, COUNT(*) AS tour_count\n    FROM virtual_tour_data vd\n    JOIN hotels h ON vd.hotel_id = h.hotel_id\n    WHERE h.country = 'UK'\n    GROUP BY vd.user_id\n) AS user_tour_counts;\n```\n\nThis query first creates a subquery that counts the number of tours each user has taken for UK hotels, and then it finds the maximum count from these results.", "latency_sec": 6.398134231567383, "total_duration_sec": 6.39395233, "load_duration_sec": 0.011744202, "tokens_prompt": 258, "prompt_eval_sec": 0.043674755, "tokens_completion": 243, "completion_eval_sec": 6.337794271, "tokens_total": 501, "tokens_per_sec": 78.3040776994245, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL references a non-existent 'country' column in the virtual_tour_data table, making it invalid. The Generated SQL correctly joins with the hotels table to filter by country. Even if the Reference SQL were fixed to include the join, the two queries would differ in their aggregation: the Reference uses COUNT(DISTINCT hotel_id) while the Generated uses COUNT(*). However, in this specific dataset, both would yield the same result (MAX of 1), but the Reference SQL is syntactically incorrect as written.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query is technically incorrect because it references a 'country' column in the virtual_tour_data table, which doesn't exist. The generated query correctly joins with the hotels table to filter UK-based hotels. Semantically, the generated query properly counts all tours (not just distinct hotels) per user in the UK, while the reference query incorrectly counts distinct hotel_ids (which would undercount if a user visited the same hotel multiple times). The business intent to find the maximum number of tours (not distinct hotels) is fulfilled by the generated query but not the reference. The generated query is also more efficient as it avoids unnecessary subqueries and correctly handles the schema.", "overall_assessment": "differently_correct"}}
{"example_id": 5812, "sql_complexity": "single join", "prompt": "Calculate the percentage of Shariah-compliant investments held by each investor in the top 5 countries with the highest percentage?", "context": "CREATE TABLE investors (investor_id INT, investor_name TEXT, country TEXT); INSERT INTO investors (investor_id, investor_name, country) VALUES (1, 'Al Thani', 'Qatar'), (2, 'Saudi Investment Group', 'Saudi Arabia'), (3, 'Temasek Holdings', 'Singapore'); CREATE TABLE investments (investment_id INT, investor_id INT, investment_type TEXT, investment_value DECIMAL, is_shariah_compliant BOOLEAN); INSERT INTO investments (investment_id, investor_id, investment_type, investment_value, is_shariah_compliant) VALUES (1, 1, 'Real Estate', 15000000, true), (2, 2, 'Stocks', 20000000, false);", "reference_sql": "SELECT investor_name, ROUND((SUM(CASE WHEN is_shariah_compliant THEN investment_value ELSE 0 END) / SUM(investment_value)) * 100, 2) AS percentage FROM investments JOIN investors ON investments.investor_id = investors.investor_id GROUP BY investor_name ORDER BY percentage DESC LIMIT 5;", "generated_sql": "WITH InvestorCompliance AS (\n    SELECT \n        i.investor_id,\n        inv.country,\n        COUNT(*) AS total_investments,\n        SUM(CASE WHEN inv.is_shariah_compliant THEN 1 ELSE 0 END) AS shariah_compliant_investments\n    FROM \n        investments inv\n    JOIN \n        investors i ON inv.investor_id = i.investor_id\n    GROUP BY \n        i.investor_id, inv.country\n),\nCompliancePercentage AS (\n    SELECT \n        investor_id,\n        country,\n        (shariah_compliant_investments * 100.0 / total_investments) AS compliance_percentage\n    FROM \n        InvestorCompliance\n)\nSELECT \n    country,\n    AVG(compliance_percentage) AS avg_compliance_percentage\nFROM \n    CompliancePercentage\nGROUP BY \n    country\nORDER BY \n    avg_compliance_percentage DESC\nLIMIT 5;", "raw_model_output": "To solve this problem, we need to calculate the percentage of Shariah-compliant investments for each investor and then determine the top 5 countries based on these percentages. Here's how you can achieve that using a single SQL statement:\n\n```sql\nWITH InvestorCompliance AS (\n    SELECT \n        i.investor_id,\n        inv.country,\n        COUNT(*) AS total_investments,\n        SUM(CASE WHEN inv.is_shariah_compliant THEN 1 ELSE 0 END) AS shariah_compliant_investments\n    FROM \n        investments inv\n    JOIN \n        investors i ON inv.investor_id = i.investor_id\n    GROUP BY \n        i.investor_id, inv.country\n),\nCompliancePercentage AS (\n    SELECT \n        investor_id,\n        country,\n        (shariah_compliant_investments * 100.0 / total_investments) AS compliance_percentage\n    FROM \n        InvestorCompliance\n)\nSELECT \n    country,\n    AVG(compliance_percentage) AS avg_compliance_percentage\nFROM \n    CompliancePercentage\nGROUP BY \n    country\nORDER BY \n    avg_compliance_percentage DESC\nLIMIT 5;\n```\n\n### Explanation:\n\n1. **InvestorCompliance CTE**: This common table expression calculates the total number of investments and the number of Shariah-compliant investments for each investor in each country.\n\n2. **CompliancePercentage CTE**: This CTE computes the percentage of Shariah-compliant investments for each investor by dividing the number of compliant investments by the total investments and multiplying by 100 to get a percentage.\n\n3. **Final SELECT Statement**: \n   - It calculates the average compliance percentage for investors in each country.\n   - The results are ordered by `avg_compliance_percentage` in descending order to find the top countries with the highest Shariah-compliant investment percentages.\n   - Finally, it limits the result to the top 5 countries.", "latency_sec": 10.407662868499756, "total_duration_sec": 10.401511844, "load_duration_sec": 0.01101621, "tokens_prompt": 249, "prompt_eval_sec": 0.053604292, "tokens_completion": 396, "completion_eval_sec": 10.336076457, "tokens_total": 645, "tokens_per_sec": 61.973567759595916, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL calculates the percentage of investment value (not count) that is shariah-compliant per investor, while the Generated SQL calculates the percentage of shariah-compliant investments (count-based) and averages this per country. Additionally, the Reference groups by investor_name, whereas the Generated groups by country. The metrics and aggregation levels differ fundamentally.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL calculates Shariah compliance percentages per investor but ignores the country dimension entirely, directly contradicting the question's focus on countries. The Generated SQL correctly groups by country to calculate average compliance percentages, addressing the 'top 5 countries' requirement. However, it fails to show individual investor percentages within those countries, which is the core of the question. While the Generated SQL better addresses the country aspect, neither query fully fulfills the business intent of analyzing investor-level compliance within top countries.", "overall_assessment": "incorrect"}}
{"example_id": 4706, "sql_complexity": "multiple_joins", "prompt": "Who are the top 3 customers by total spend on makeup products from Italy and Spain?", "context": "CREATE TABLE customers (customer_id INT, customer_name TEXT, country TEXT); INSERT INTO customers (customer_id, customer_name, country) VALUES (1, 'Alessandro Martini', 'IT'), (2, 'Laura Rossi', 'ES'), (3, 'Daniela Gonzalez', 'MX'), (4, 'Jose Hernandez', 'ES'), (5, 'Sophia Rodriguez', 'IT'); CREATE TABLE sales (sale_id INT, customer_id INT, product_id INT, sale_quantity INT, sale_country TEXT); INSERT INTO sales (sale_id, customer_id, product_id, sale_quantity, sale_country) VALUES (1, 1, 1, 100, 'IT'), (2, 2, 2, 150, 'ES'), (3, 3, 3, 200, 'MX'), (4, 4, 4, 250, 'ES'), (5, 5, 5, 300, 'IT'); CREATE TABLE products (product_id INT, product_name TEXT, category TEXT); INSERT INTO products (product_id, product_name, category) VALUES (1, 'Eyeshadow Palette', 'makeup'), (2, 'Liquid Lipstick', 'makeup'), (3, 'BB Cream', 'makeup'), (4, 'Volumizing Mascara', 'makeup'), (5, 'Nourishing Lip Balm', 'makeup');", "reference_sql": "SELECT c.customer_name, SUM(s.sale_quantity) as total_spent_on_makeup FROM sales s JOIN customers c ON s.customer_id = c.customer_id JOIN products p ON s.product_id = p.product_id WHERE c.country IN ('IT', 'ES') AND p.category = 'makeup' GROUP BY c.customer_name ORDER BY total_spent_on_makeup DESC LIMIT 3;", "generated_sql": "SELECT \n    c.customer_id,\n    c.customer_name,\n    SUM(s.sale_quantity) AS total_spend\nFROM \n    customers c\nJOIN \n    sales s ON c.customer_id = s.customer_id\nWHERE \n    s.sale_country IN ('IT', 'ES')\nGROUP BY \n    c.customer_id, c.customer_name\nORDER BY \n    total_spend DESC\nLIMIT 3;", "raw_model_output": "To determine the top 3 customers by total spend on makeup products from Italy and Spain, we need to calculate the total sales quantity for each customer in these countries. We'll join the `sales` table with the `customers` table to filter by country and ensure that only sales related to makeup products are considered.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    c.customer_id,\n    c.customer_name,\n    SUM(s.sale_quantity) AS total_spend\nFROM \n    customers c\nJOIN \n    sales s ON c.customer_id = s.customer_id\nWHERE \n    s.sale_country IN ('IT', 'ES')\nGROUP BY \n    c.customer_id, c.customer_name\nORDER BY \n    total_spend DESC\nLIMIT 3;\n```\n\n### Explanation:\n\n1. **Join Tables**: We join the `customers` table with the `sales` table on `customer_id` to access customer details and their sales.\n\n2. **Filter by Country**: The `WHERE` clause filters sales records to include only those from Italy (`IT`) and Spain (`ES`).\n\n3. **Grouping and Aggregation**: We group the results by `customer_id` and `customer_name` to calculate the total spend for each customer using `SUM(s.sale_quantity)`.\n\n4. **Order and Limit**: The results are ordered in descending order of `total_spend`, and we limit the output to the top 3 customers with the highest spend.", "latency_sec": 7.8920581340789795, "total_duration_sec": 7.884604845, "load_duration_sec": 0.011596449, "tokens_prompt": 385, "prompt_eval_sec": 0.069513819, "tokens_completion": 296, "completion_eval_sec": 7.802472589, "tokens_total": 681, "tokens_per_sec": 86.2892782124031, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in several key aspects. 1) The Reference SQL filters for customers in 'IT' or 'ES' and products in 'makeup', while the Generated SQL filters for sales in 'IT' or 'ES' and lacks a product category filter. 2) The Reference SQL groups by customer_name, while the Generated SQL groups by customer_id and customer_name. 3) The Generated SQL includes customer_id in the output, which the Reference SQL does not. These differences will lead to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The reference query correctly joins customers, sales, and products tables, filters for 'makeup' category and countries IT/ES, and groups by customer_name. The generated query lacks the products table join, so it cannot filter for 'makeup' products. It incorrectly uses sale_country instead of customer country, and omits the category restriction. While both identify top spenders by country, only the reference ensures makeup product classification. The generated query would include non-makeup sales, violating the original question's constraints.", "overall_assessment": "differently_correct"}}
{"example_id": 1515, "sql_complexity": "multiple_joins", "prompt": "What is the average age of clients who lost cases in the 'personal injury' category?", "context": "CREATE TABLE Cases (CaseID int, ClientID int, Category varchar(50)); INSERT INTO Cases (CaseID, ClientID, Category) VALUES (701, 7, 'Personal Injury'); CREATE TABLE Clients (ClientID int, Age int, Gender varchar(10)); INSERT INTO Clients (ClientID, Age, Gender) VALUES (7, 45, 'Male'); CREATE TABLE CaseOutcomes (CaseID int, Outcome varchar(50)); INSERT INTO CaseOutcomes (CaseID, Outcome) VALUES (701, 'Lost');", "reference_sql": "SELECT AVG(C.Age) as AvgAge FROM Clients C INNER JOIN Cases CA ON C.ClientID = CA.ClientID INNER JOIN CaseOutcomes CO ON CA.CaseID = CO.CaseID WHERE CA.Category = 'Personal Injury' AND CO.Outcome = 'Lost';", "generated_sql": "SELECT AVG(Clients.Age) AS AverageAge\nFROM Cases\nJOIN Clients ON Cases.ClientID = Clients.ClientID\nJOIN CaseOutcomes ON Cases.CaseID = CaseOutcomes.CaseID\nWHERE Cases.Category = 'Personal Injury'\n  AND CaseOutcomes.Outcome = 'Lost';", "raw_model_output": "To find the average age of clients who lost cases in the 'Personal Injury' category, we need to join the `Cases`, `Clients`, and `CaseOutcomes` tables. We will filter for cases that have an outcome of 'Lost' and belong to the 'Personal Injury' category. Here is the SQL statement:\n\n```sql\nSELECT AVG(Clients.Age) AS AverageAge\nFROM Cases\nJOIN Clients ON Cases.ClientID = Clients.ClientID\nJOIN CaseOutcomes ON Cases.CaseID = CaseOutcomes.CaseID\nWHERE Cases.Category = 'Personal Injury'\n  AND CaseOutcomes.Outcome = 'Lost';\n```\n\nThis query performs the following steps:\n1. Joins the `Cases` table with the `Clients` table on `ClientID`.\n2. Joins the resulting dataset with the `CaseOutcomes` table on `CaseID`.\n3. Filters for cases where the category is 'Personal Injury' and the outcome is 'Lost'.\n4. Calculates the average age of clients who meet these criteria using `AVG(Clients.Age)`.", "latency_sec": 5.7481629848480225, "total_duration_sec": 5.743936464, "load_duration_sec": 0.01352545, "tokens_prompt": 200, "prompt_eval_sec": 0.036681265, "tokens_completion": 220, "completion_eval_sec": 5.69141762, "tokens_total": 420, "tokens_per_sec": 73.0668217145385, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the average age of clients with 'Personal Injury' cases that resulted in a 'Lost' outcome. They use identical table joins (Cases \u2194 Clients and Cases \u2194 CaseOutcomes), same filtering conditions, and the same aggregate function. The only differences are syntax variations (table aliases vs. full names, JOIN syntax) which do not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they produce identical results through equivalent logic. They correctly join the three tables (Clients, Cases, CaseOutcomes) with the same conditions (Category = 'Personal Injury' and Outcome = 'Lost'), and calculate the average client age. The reference query uses table aliases (C, CA, CO) while the generated query uses full table names, but this does not affect functionality. Both properly address the business intent by focusing on lost cases in the specified category. The queries are equally efficient and well-structured, with no significant differences in elegance or performance.", "overall_assessment": "correct"}}
{"example_id": 4388, "sql_complexity": "subqueries", "prompt": "Insert a new drug with a price 10% higher than the average price", "context": "CREATE TABLE drugs (drug_id INT, drug_name VARCHAR(50), price DECIMAL(10, 2)); INSERT INTO drugs (drug_id, drug_name, price) VALUES (1, 'DrugA', 50), (2, 'DrugB', 75), (3, 'DrugC', 100)", "reference_sql": "INSERT INTO drugs (drug_id, drug_name, price) VALUES ((SELECT MAX(drug_id) FROM drugs) + 1, 'DrugD', (SELECT AVG(price) * 1.1 FROM drugs))", "generated_sql": "INSERT INTO drugs (drug_id, drug_name, price)\nSELECT COALESCE(MAX(drug_id), 0) + 1, 'NewDrug', AVG(price) * 1.10\nFROM drugs;", "raw_model_output": "To insert a new drug with a price that is 10% higher than the average price of existing drugs in the `drugs` table, you can use the following SQL statement:\n\n```sql\nINSERT INTO drugs (drug_id, drug_name, price)\nSELECT COALESCE(MAX(drug_id), 0) + 1, 'NewDrug', AVG(price) * 1.10\nFROM drugs;\n```\n\n### Explanation:\n- `COALESCE(MAX(drug_id), 0) + 1`: This part calculates the next available `drug_id` by taking the maximum current `drug_id` and adding 1 to it. If there are no entries in the table, `MAX(drug_id)` would return `NULL`, so `COALESCE` ensures that we start from 1.\n- `'NewDrug'`: This is a placeholder name for the new drug being inserted.\n- `AVG(price) * 1.10`: This calculates the average price of all existing drugs and increases it by 10% to determine the new drug's price.", "latency_sec": 5.703420877456665, "total_duration_sec": 5.698720331, "load_duration_sec": 0.020204431, "tokens_prompt": 154, "prompt_eval_sec": 0.020932011, "tokens_completion": 221, "completion_eval_sec": 5.6566658, "tokens_total": 375, "tokens_per_sec": 65.75001355453611, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in the inserted drug_name values ('DrugD' vs 'NewDrug'). Additionally, the Generated SQL handles empty tables by using COALESCE, while the Reference SQL would fail in that scenario. However, the primary discrepancy is the drug_name difference, which makes the results non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in two key aspects: 1) The reference query explicitly names the drug 'DrugD' while the generated query uses 'NewDrug', resulting in different data outputs. 2) The generated query uses COALESCE(MAX(drug_id), 0) + 1 which handles empty tables more robustly compared to the reference's (SELECT MAX(drug_id) FROM drugs) + 1 that would return NULL if the table is empty. Both correctly calculate the 10% higher price, but the generated version is more robust and elegant. The business intent of inserting a drug with price 10% above average is fulfilled by both, but the generated query better handles edge cases.", "overall_assessment": "differently_correct"}}
{"example_id": 5431, "sql_complexity": "basic SQL", "prompt": "What is the average CO2 emission of ride-hailing vehicles in San Francisco?", "context": "CREATE TABLE SFRideHailing (id INT, company VARCHAR(20), co2_emission DECIMAL(5,2));", "reference_sql": "SELECT AVG(co2_emission) FROM SFRideHailing WHERE company = 'Uber';", "generated_sql": "SELECT AVG(co2_emission) AS avg_co2_emission\nFROM SFRideHailing;", "raw_model_output": "To find the average CO2 emission of ride-hailing vehicles in San Francisco using the provided schema, you can use the following SQL query:\n\n```sql\nSELECT AVG(co2_emission) AS avg_co2_emission\nFROM SFRideHailing;\n```\n\nThis query calculates the average value of the `co2_emission` column from the `SFRideHailing` table. The result is aliased as `avg_co2_emission`.", "latency_sec": 2.406406879425049, "total_duration_sec": 2.399770165, "load_duration_sec": 0.014692812, "tokens_prompt": 115, "prompt_eval_sec": 0.015741354, "tokens_completion": 94, "completion_eval_sec": 2.36796836, "tokens_total": 209, "tokens_per_sec": 86.85148043207695, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the average co2_emission specifically for 'Uber' rides, while the Generated SQL calculates the average for all companies in the table. The WHERE clause in the Reference SQL restricts the dataset, making the results different unless all entries are from Uber.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL calculates the average CO2 emission specifically for Uber vehicles, while the original question asks for all ride-hailing vehicles in San Francisco. The Generated SQL averages all entries in the SFRideHailing table, which likely contains all relevant vehicles in the city. However, neither query explicitly confirms if SFRideHailing contains only Uber vehicles or multiple companies. The Generated SQL better aligns with the question's scope but still assumes the table contains all ride-hailing vehicles (not just Uber). The Reference SQL fails to fulfill intent if other companies exist in the dataset.", "overall_assessment": "differently_correct"}}
{"example_id": 3531, "sql_complexity": "single join", "prompt": "What is the total number of workouts and total workout time per user for users with a membership type of 'Basic'?", "context": "CREATE TABLE Members (id INT, user_name VARCHAR, membership_type VARCHAR, signup_date DATE); CREATE TABLE Workouts (id INT, user_id INT, workout_date DATE, workout_duration INT); INSERT INTO Members (id, user_name, membership_type, signup_date) VALUES (1, 'John Doe', 'Premium', '2020-01-01'), (2, 'Jane Smith', 'Basic', '2019-06-15'), (3, 'Alice Johnson', 'Premium', '2020-03-20'); INSERT INTO Workouts (id, user_id, workout_date, workout_duration) VALUES (1, 1, '2020-01-01', 60), (2, 1, '2020-01-02', 70), (3, 2, '2019-06-15', 90), (4, 3, '2020-03-20', 65), (5, 3, '2020-03-21', 70);", "reference_sql": "SELECT Members.user_name, SUM(Workouts.workout_duration) AS total_workout_time, COUNT(Workouts.id) AS total_workouts FROM Members JOIN Workouts ON Members.id = Workouts.user_id WHERE Members.membership_type = 'Basic' GROUP BY Members.user_name;", "generated_sql": "SELECT \n    m.user_name,\n    COUNT(w.id) AS total_workouts,\n    SUM(w.workout_duration) AS total_workout_time\nFROM \n    Members m\nJOIN \n    Workouts w ON m.id = w.user_id\nWHERE \n    m.membership_type = 'Basic'\nGROUP BY \n    m.user_name;", "raw_model_output": "To solve this problem, we need to join the `Members` table with the `Workouts` table on the condition that matches the `id` from `Members` with the `user_id` from `Workouts`. We will filter for users who have a membership type of 'Basic'. Then, we'll group by user details and calculate both the total number of workouts and the total workout duration per user.\n\nHere's the SQL query to achieve this:\n\n```sql\nSELECT \n    m.user_name,\n    COUNT(w.id) AS total_workouts,\n    SUM(w.workout_duration) AS total_workout_time\nFROM \n    Members m\nJOIN \n    Workouts w ON m.id = w.user_id\nWHERE \n    m.membership_type = 'Basic'\nGROUP BY \n    m.user_name;\n```\n\n### Explanation:\n\n- **SELECT Clause**: We select the `user_name` from the `Members` table and calculate two aggregates:\n  - `COUNT(w.id)` to get the total number of workouts per user.\n  - `SUM(w.workout_duration)` to get the total workout time per user.\n\n- **FROM Clause**: We specify that we are working with data from the `Members` table, aliased as `m`.\n\n- **JOIN Clause**: We perform an inner join between `Members` and `Workouts` on the condition `m.id = w.user_id`. This ensures we only consider workouts associated with members.\n\n- **WHERE Clause**: We filter for users whose `membership_type` is 'Basic'.\n\n- **GROUP BY Clause**: We group the results by `user_name` to ensure that our aggregate functions (`COUNT` and `SUM`) are calculated per user.", "latency_sec": 9.09437084197998, "total_duration_sec": 9.089579908, "load_duration_sec": 0.019514222, "tokens_prompt": 307, "prompt_eval_sec": 0.049676122, "tokens_completion": 345, "completion_eval_sec": 9.019443023, "tokens_total": 652, "tokens_per_sec": 71.69269994910938, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. Both perform an inner join between Members and Workouts on user_id, filter for 'Basic' membership type, and group by user_name. The generated query uses table aliases (m/w) and swaps the order of COUNT and SUM in the SELECT clause, but these are syntactic variations that do not affect the result set. The aggregation logic and filtering conditions are identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate total workouts and total workout time per user for 'Basic' members. The reference query uses explicit table names while the generated query uses aliases, but both achieve identical results. The generated query is more concise and follows modern SQL style with table aliases, making it slightly more elegant without sacrificing clarity or performance. Both are logically equivalent and fulfill the business requirement accurately.", "overall_assessment": "correct"}}
{"example_id": 5678, "sql_complexity": "set operations", "prompt": "How many public works projects are there in 'Sydney' and 'Melbourne' combined?", "context": "CREATE TABLE PublicWorksC(id INT, city VARCHAR(20), project VARCHAR(30)); INSERT INTO PublicWorksC(id, city, project) VALUES (1, 'Sydney', 'Park Renovation'), (2, 'Melbourne', 'Sidewalk Repair');", "reference_sql": "SELECT COUNT(*) FROM (SELECT city FROM PublicWorksC WHERE city = 'Sydney' UNION ALL SELECT city FROM PublicWorksC WHERE city = 'Melbourne') AS Total;", "generated_sql": "SELECT COUNT(*) AS total_projects\nFROM PublicWorksC\nWHERE city IN ('Sydney', 'Melbourne');", "raw_model_output": "To find the total number of public works projects in both 'Sydney' and 'Melbourne', you can use a `COUNT` function with a `WHERE` clause to filter for these cities. Here's the SQL statement:\n\n```sql\nSELECT COUNT(*) AS total_projects\nFROM PublicWorksC\nWHERE city IN ('Sydney', 'Melbourne');\n```\n\nThis query counts all rows in the `PublicWorksC` table where the `city` column is either 'Sydney' or 'Melbourne'.", "latency_sec": 2.7201619148254395, "total_duration_sec": 2.714126079, "load_duration_sec": 0.010190303, "tokens_prompt": 146, "prompt_eval_sec": 0.021159155, "tokens_completion": 105, "completion_eval_sec": 2.68213266, "tokens_total": 251, "tokens_per_sec": 92.27391892813388, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count the number of rows where the city is either 'Sydney' or 'Melbourne'. The Reference SQL uses a UNION ALL to combine two separate selects and then counts the combined rows, while the Generated SQL uses a single WHERE clause with IN. Since both approaches ultimately count all matching rows (regardless of duplication), they produce the same result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly count projects in Sydney and Melbourne. The reference query uses an unnecessary subquery with UNION ALL, which achieves the same result as the generated query's IN clause. While technically equivalent, the generated query is more efficient (single table scan vs. subquery) and elegant. Both fulfill the business intent of combining counts for the two cities.", "overall_assessment": "correct"}}
{"example_id": 5792, "sql_complexity": "multiple_joins", "prompt": "How many cases were handled by attorneys in the 'Los Angeles' office?", "context": "CREATE TABLE offices (office_id INT, office_name VARCHAR(20), city VARCHAR(20), state VARCHAR(20)); INSERT INTO offices (office_id, office_name, city, state) VALUES (1, 'Boston', 'Boston', 'MA'), (2, 'New York', 'New York', 'NY'), (3, 'Los Angeles', 'Los Angeles', 'CA'); CREATE TABLE attorneys (attorney_id INT, office_id INT); INSERT INTO attorneys (attorney_id, office_id) VALUES (1, 1), (2, 2), (3, 3); CREATE TABLE cases (case_id INT, attorney_id INT); INSERT INTO cases (case_id, attorney_id) VALUES (1, 1), (2, 2), (3, 3);", "reference_sql": "SELECT COUNT(*) FROM cases JOIN attorneys ON cases.attorney_id = attorneys.attorney_id JOIN offices ON attorneys.office_id = offices.office_id WHERE offices.city = 'Los Angeles';", "generated_sql": "SELECT COUNT(c.case_id) AS number_of_cases\nFROM offices o\nJOIN attorneys a ON o.office_id = a.office_id\nJOIN cases c ON a.attorney_id = c.attorney_id\nWHERE o.city = 'Los Angeles';", "raw_model_output": "To determine how many cases were handled by attorneys in the 'Los Angeles' office, we need to join the `offices`, `attorneys`, and `cases` tables. Here's the SQL query that accomplishes this:\n\n```sql\nSELECT COUNT(c.case_id) AS number_of_cases\nFROM offices o\nJOIN attorneys a ON o.office_id = a.office_id\nJOIN cases c ON a.attorney_id = c.attorney_id\nWHERE o.city = 'Los Angeles';\n```\n\nThis query works as follows:\n- It joins the `offices` table with the `attorneys` table on `office_id`.\n- Then, it joins the resulting set with the `cases` table on `attorney_id`.\n- Finally, it filters for offices located in 'Los Angeles' and counts the number of cases associated with attorneys from that office.", "latency_sec": 4.599653959274292, "total_duration_sec": 4.594578504, "load_duration_sec": 0.023325939, "tokens_prompt": 250, "prompt_eval_sec": 0.041867609, "tokens_completion": 174, "completion_eval_sec": 4.527422893, "tokens_total": 424, "tokens_per_sec": 92.1808474624679, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count the number of cases associated with attorneys in the 'Los Angeles' office. The Reference SQL uses explicit table names while the Generated SQL uses aliases, but this doesn't affect semantics. The join order differs (cases-first vs offices-first) but inner joins produce the same result. The count expression (COUNT(*) vs COUNT(c.case_id)) is equivalent since all joins are inner and case_id is non-null. The WHERE condition filters on the same city value.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly count cases linked to attorneys in the 'Los Angeles' office via three-table joins. The reference query uses implicit JOIN syntax with COUNT(*), while the generated query uses explicit aliases and COUNT(c.case_id). The semantic logic is identical: filtering by offices.city = 'Los Angeles' and counting case records. Both handle nulls correctly (since cases.attorney_id is non-nullable per schema). The generated query's column-specific COUNT and aliases improve readability without altering functionality. Neither query is more efficient than the other.", "overall_assessment": "correct"}}
{"example_id": 5148, "sql_complexity": "window functions", "prompt": "List the unique types of smart city technologies that have been implemented in the top 3 most populous countries in the world.", "context": "CREATE TABLE smart_city_tech (tech_type VARCHAR(255), country VARCHAR(255)); CREATE TABLE country_populations (country VARCHAR(255), population INT);", "reference_sql": "SELECT DISTINCT tech_type FROM smart_city_tech SCT WHERE country IN (SELECT country FROM (SELECT country, ROW_NUMBER() OVER (ORDER BY population DESC) as rank FROM country_populations) CP WHERE rank <= 3);", "generated_sql": "SELECT DISTINCT tech_type\nFROM smart_city_tech\nWHERE country IN (\n    SELECT country\n    FROM country_populations\n    ORDER BY population DESC\n    LIMIT 3\n);", "raw_model_output": "To solve this problem, we need to follow these steps:\n\n1. Identify the top 3 most populous countries from the `country_populations` table.\n2. Retrieve the unique types of smart city technologies (`tech_type`) implemented in those countries from the `smart_city_tech` table.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT DISTINCT tech_type\nFROM smart_city_tech\nWHERE country IN (\n    SELECT country\n    FROM country_populations\n    ORDER BY population DESC\n    LIMIT 3\n);\n```\n\n### Explanation:\n- The subquery selects the top 3 countries with the highest populations by ordering `country_populations` in descending order of `population` and limiting the results to 3.\n- The main query retrieves distinct `tech_type` values from the `smart_city_tech` table where the `country` is one of those identified in the subquery.", "latency_sec": 4.798109292984009, "total_duration_sec": 4.794013893, "load_duration_sec": 0.011348923, "tokens_prompt": 128, "prompt_eval_sec": 0.016318768, "tokens_completion": 186, "completion_eval_sec": 4.765636034, "tokens_total": 314, "tokens_per_sec": 65.44244426844207, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the top 3 countries by population. The Reference uses ROW_NUMBER() with a subquery to rank countries, while the Generated uses ORDER BY and LIMIT. Both approaches effectively select the same set of countries (top 3 by population), leading to identical results for the DISTINCT tech_type values.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in how they identify the top 3 most populous countries. The reference query uses ROW_NUMBER() with a subquery, which could fail if multiple countries share the same population (as it would assign unique ranks). The generated query uses ORDER BY ... LIMIT 3, which correctly retrieves the top 3 countries by population regardless of ties. Both return distinct tech_types, but the generated query is more efficient, readable, and aligns better with standard SQL practices for top-N queries. Both fulfill the business intent, but the generated query is technically superior.", "overall_assessment": "differently_correct"}}
{"example_id": 5547, "sql_complexity": "multiple_joins", "prompt": "Which species have a population growth rate higher than the average for protected areas?", "context": "CREATE TABLE species (id INT, name VARCHAR(50), population DECIMAL(5,2), protected_area_id INT, growth_rate DECIMAL(5,2)); INSERT INTO species (id, name, population, protected_area_id, growth_rate) VALUES (1, 'Species 1', 500.00, 1, 0.05), (2, 'Species 2', 800.00, 1, 0.03), (3, 'Species 3', 1200.00, 2, 0.07), (4, 'Species 4', 700.00, 2, 0.02); CREATE TABLE protected_areas (id INT, name VARCHAR(50)); INSERT INTO protected_areas (id, name) VALUES (1, 'Area 1'), (2, 'Area 2');", "reference_sql": "SELECT s.name, s.growth_rate FROM species s INNER JOIN protected_areas pa ON s.protected_area_id = pa.id GROUP BY s.name, s.growth_rate HAVING s.growth_rate > (SELECT AVG(s.growth_rate) FROM species s INNER JOIN protected_areas pa ON s.protected_area_id = pa.id);", "generated_sql": "SELECT id, name, population, protected_area_id, growth_rate\nFROM species\nWHERE growth_rate > (\n    SELECT AVG(growth_rate)\n    FROM species\n);", "raw_model_output": "To solve this problem, we need to identify which species have a growth rate that is higher than the average growth rate of all species across the protected areas. Here's how you can construct the SQL query:\n\n1. Calculate the average growth rate of all species.\n2. Select species whose growth rate is greater than this calculated average.\n\nHere's the SQL statement to achieve this:\n\n```sql\nSELECT id, name, population, protected_area_id, growth_rate\nFROM species\nWHERE growth_rate > (\n    SELECT AVG(growth_rate)\n    FROM species\n);\n```\n\nThis query works as follows:\n- The subquery `(SELECT AVG(growth_rate) FROM species)` calculates the average growth rate of all entries in the `species` table.\n- The main query selects all columns from the `species` table where the `growth_rate` is greater than this calculated average.", "latency_sec": 4.710378885269165, "total_duration_sec": 4.705505654, "load_duration_sec": 0.0132071, "tokens_prompt": 263, "prompt_eval_sec": 0.04704814, "tokens_completion": 176, "completion_eval_sec": 4.643034481, "tokens_total": 439, "tokens_per_sec": 93.19844766052492, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL selects only 'name' and 'growth_rate' from a joined table with grouping and HAVING filtering, while the Generated SQL selects all columns from the species table with a WHERE filter. Additionally, the subquery in the Reference SQL includes a JOIN with protected_areas, which could affect the average calculation if there were species without protected areas (though in the given data it coincidentally matches). The differing column selections and query structure ensure different result sets.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL incorrectly calculates the average growth rate across all species (including non-protected areas if they existed) but includes a redundant JOIN with protected_areas. It also groups by species name and growth_rate, which is unnecessary since the HAVING clause compares to a scalar average. The Generated SQL correctly calculates the overall average growth rate of all species (assuming all species are in protected areas per the schema) without unnecessary joins. However, neither query addresses the ambiguity in the original question: whether the 'average for protected areas' refers to (1) an overall average across all protected areas or (2) a per-protected-area average. The Generated SQL is more efficient and elegant, but neither fully clarifies the business intent.", "overall_assessment": "differently_correct"}}
{"example_id": 5498, "sql_complexity": "aggregation", "prompt": "Identify the destinations with the highest number of repeat visitors from the US.", "context": "CREATE TABLE RepeatTravelers (Visitor VARCHAR(20), Destination VARCHAR(20), VisitCount INT); INSERT INTO RepeatTravelers (Visitor, Destination, VisitCount) VALUES ('David', 'Paris', 3), ('Ella', 'London', 4), ('Fiona', 'Paris', 2);", "reference_sql": "SELECT Destination, AVG(VisitCount) AS AvgVisitCount FROM RepeatTravelers WHERE Visitor LIKE '%USA%' GROUP BY Destination ORDER BY AvgVisitCount DESC;", "generated_sql": "SELECT Destination, SUM(VisitCount) AS TotalVisits\nFROM RepeatTravelers\nGROUP BY Destination\nHAVING SUM(VisitCount) = (\n    SELECT MAX(TotalVisits)\n    FROM (\n        SELECT SUM(VisitCount) AS TotalVisits\n        FROM RepeatTravelers\n        GROUP BY Destination\n    ) AS SubQuery\n);", "raw_model_output": "To address this question, we need to identify destinations that have the highest number of repeat visits by travelers. However, the provided schema does not include any information about the nationality or country of origin for each visitor (e.g., whether they are from the US). Therefore, it is impossible to filter visitors based on their being from the US with the given data.\n\nAssuming we only want to find destinations with the highest number of repeat visits regardless of the visitor's nationality, we can proceed by summing up the `VisitCount` for each destination and then identifying those with the maximum total visit count. Here is how you could write that SQL query:\n\n```sql\nSELECT Destination, SUM(VisitCount) AS TotalVisits\nFROM RepeatTravelers\nGROUP BY Destination\nHAVING SUM(VisitCount) = (\n    SELECT MAX(TotalVisits)\n    FROM (\n        SELECT SUM(VisitCount) AS TotalVisits\n        FROM RepeatTravelers\n        GROUP BY Destination\n    ) AS SubQuery\n);\n```\n\nThis query calculates the total number of visits for each destination and then identifies those destinations with the maximum total visit count. However, without additional data on visitor nationality, we cannot specifically filter for US visitors.", "latency_sec": 6.431002140045166, "total_duration_sec": 6.424465058, "load_duration_sec": 0.013260867, "tokens_prompt": 150, "prompt_eval_sec": 0.020611336, "tokens_completion": 248, "completion_eval_sec": 6.389784369, "tokens_total": 398, "tokens_per_sec": 61.88771070712235, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters rows where Visitor contains 'USA' (which returns no rows in the given data) and calculates average VisitCount per destination. The Generated SQL finds destinations with the maximum total VisitCount. They differ in both filtering logic and aggregation (AVG vs SUM) and produce different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query calculates the average VisitCount for US visitors (though the WHERE clause is flawed as Visitor names don't contain 'USA'), while the generated query sums VisitCount to find destinations with the maximum total visits. The business intent requires identifying destinations with the highest number of repeat visitors from the US, but neither query correctly filters for US visitors (the Visitor column likely contains names, not country codes). The generated query better addresses the metric (summing visits) but lacks the US filter. The reference query incorrectly uses AVG instead of SUM and has a flawed WHERE condition. The generated query's approach is more aligned with the intent if the US filter were present.", "overall_assessment": "differently_correct"}}
{"example_id": 3546, "sql_complexity": "window functions", "prompt": "What are the cryptocurrency exchanges with their corresponding blockchain companies, ranked by exchange ID in ascending order, for the Bitcoin platform?", "context": "CREATE TABLE cryptocurrency_exchanges (exchange_id INT, exchange_name VARCHAR(50), company_id INT); INSERT INTO cryptocurrency_exchanges (exchange_id, exchange_name, company_id) VALUES (1, 'Binance', 1); INSERT INTO cryptocurrency_exchanges (exchange_id, exchange_name, company_id) VALUES (2, 'Coinbase', 2); INSERT INTO cryptocurrency_exchanges (exchange_id, exchange_name, company_id) VALUES (3, 'Kraken', 3); CREATE TABLE blockchain_companies (company_id INT, company_name VARCHAR(50), platform VARCHAR(50)); INSERT INTO blockchain_companies (company_id, company_name, platform) VALUES (1, 'Binance', 'Bitcoin'); INSERT INTO blockchain_companies (company_id, company_name, platform) VALUES (2, 'Blockstream', 'Bitcoin'); INSERT INTO blockchain_companies (company_id, company_name, platform) VALUES (3, 'Blockchair', 'Bitcoin');", "reference_sql": "SELECT ce.exchange_name, bc.company_name, ce.exchange_id, ROW_NUMBER() OVER (PARTITION BY bc.platform ORDER BY ce.exchange_id ASC) as rank FROM cryptocurrency_exchanges ce JOIN blockchain_companies bc ON ce.company_id = bc.company_id WHERE bc.platform = 'Bitcoin';", "generated_sql": "SELECT \n    ce.exchange_id,\n    ce.exchange_name,\n    bc.company_name,\n    bc.platform\nFROM \n    cryptocurrency_exchanges ce\nJOIN \n    blockchain_companies bc ON ce.company_id = bc.company_id\nWHERE \n    bc.platform = 'Bitcoin'\nORDER BY \n    ce.exchange_id ASC;", "raw_model_output": "To solve this problem, we need to join the `cryptocurrency_exchanges` table with the `blockchain_companies` table based on the `company_id`. We also need to filter the results to include only those blockchain companies that are associated with the \"Bitcoin\" platform. Finally, we should order the results by `exchange_id` in ascending order.\n\nHere's the SQL statement that accomplishes this:\n\n```sql\nSELECT \n    ce.exchange_id,\n    ce.exchange_name,\n    bc.company_name,\n    bc.platform\nFROM \n    cryptocurrency_exchanges ce\nJOIN \n    blockchain_companies bc ON ce.company_id = bc.company_id\nWHERE \n    bc.platform = 'Bitcoin'\nORDER BY \n    ce.exchange_id ASC;\n```\n\nThis query performs the following steps:\n- Joins `cryptocurrency_exchanges` (aliased as `ce`) with `blockchain_companies` (aliased as `bc`) on their common column `company_id`.\n- Filters the results to include only those rows where the `platform` is \"Bitcoin\".\n- Selects the relevant columns: `exchange_id`, `exchange_name`, `company_name`, and `platform`.\n- Orders the final result set by `exchange_id` in ascending order.", "latency_sec": 6.657190799713135, "total_duration_sec": 6.652821786, "load_duration_sec": 0.014320912, "tokens_prompt": 290, "prompt_eval_sec": 0.05282811, "tokens_completion": 252, "completion_eval_sec": 6.582707447, "tokens_total": 542, "tokens_per_sec": 81.41572268341105, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL includes a ROW_NUMBER() column and selects 'exchange_name' and 'company_name', while the Generated SQL selects 'exchange_id', 'exchange_name', 'company_name', and 'platform' without the row number. Additionally, the Reference SQL partitions by 'platform' but the Generated SQL lacks this calculation and ordering logic.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query includes a ROW_NUMBER() ranking column and lacks an ORDER BY clause, while the generated query focuses on the required columns (exchange_id, exchange_name, company_name) and explicitly sorts results by exchange_id. The original question asks for 'ranked by exchange ID in ascending order' which the generated query achieves through ORDER BY, whereas the reference query's window function ranking is unnecessary and doesn't guarantee ordered output without an explicit sort. The generated query better fulfills the business intent by directly returning the required data in the specified order without extraneous columns.", "overall_assessment": "differently_correct"}}
{"example_id": 486, "sql_complexity": "single join", "prompt": "What is the average price of paintings from African artists in our collection?", "context": "CREATE TABLE Artworks (id INT, title VARCHAR(50), price DECIMAL(10,2), medium VARCHAR(50), artist_nationality VARCHAR(50)); CREATE TABLE Collections (id INT, name VARCHAR(50), continent VARCHAR(50));", "reference_sql": "SELECT AVG(Artworks.price) FROM Artworks INNER JOIN Collections ON Artworks.artist_nationality = Collections.continent WHERE Artworks.medium = 'Painting' AND Collections.continent = 'Africa';", "generated_sql": "SELECT AVG(a.price) AS average_price\nFROM Artworks a\nJOIN Collections c ON a.id = c.id\nWHERE a.medium = 'painting'\n  AND a.artist_nationality = 'African';", "raw_model_output": "To find the average price of paintings from African artists in your collection, you need to join the `Artworks` table with the `Collections` table and filter based on the specified conditions. Here's the SQL query:\n\n```sql\nSELECT AVG(a.price) AS average_price\nFROM Artworks a\nJOIN Collections c ON a.id = c.id\nWHERE a.medium = 'painting'\n  AND a.artist_nationality = 'African';\n```\n\nThis query calculates the average price of artworks that are paintings and created by African artists. Note that this assumes there is a direct relationship between `Artworks` and `Collections` via the `id` column, which might need adjustment based on your actual schema relationships. If the relationship is different, you may need to adjust the join condition accordingly.", "latency_sec": 4.211863994598389, "total_duration_sec": 4.207512929, "load_duration_sec": 0.021372226, "tokens_prompt": 137, "prompt_eval_sec": 0.01963049, "tokens_completion": 163, "completion_eval_sec": 4.165124806, "tokens_total": 300, "tokens_per_sec": 71.22737115556023, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in join conditions and filter criteria. Reference joins on Artworks.artist_nationality = Collections.continent with a continent filter of 'Africa', while Generated joins on Artworks.id = Collections.id and filters Artworks.artist_nationality = 'African'. These conditions target different relationships and data subsets.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query incorrectly joins Artworks.artist_nationality (a nationality) with Collections.continent (a continent), which is a logical error. It also filters on Collections.continent = 'Africa' which would only match if the artist_nationality column contained 'Africa' (not typical). The generated query correctly filters Artworks.artist_nationality = 'African' (matching the business intent) but incorrectly joins Artworks.id = Collections.id, which is not supported by the schema. While both have flaws, the generated query better addresses the business intent by directly filtering for African artists, whereas the reference query's join logic is fundamentally flawed. The generated query's join is unnecessary but doesn't directly contradict the intent.", "overall_assessment": "differently_correct"}}
{"example_id": 794, "sql_complexity": "multiple_joins", "prompt": "Which suppliers have provided raw materials for the production of chemicals with high environmental impact?", "context": "CREATE TABLE suppliers (id INT, name TEXT); INSERT INTO suppliers (id, name) VALUES (1, 'Supplier1'), (2, 'Supplier2'), (3, 'Supplier3'); CREATE TABLE chemicals (id INT, name TEXT, environmental_impact INT); INSERT INTO chemicals (id, name, environmental_impact) VALUES (1, 'ChemA', 10), (2, 'ChemB', 20), (3, 'ChemC', 15); CREATE TABLE raw_materials (chemical_id INT, supplier_id INT); INSERT INTO raw_materials (chemical_id, supplier_id) VALUES (1, 1), (1, 2), (2, 3), (3, 1);", "reference_sql": "SELECT s.name FROM suppliers s INNER JOIN raw_materials rm ON s.id = rm.supplier_id INNER JOIN chemicals c ON rm.chemical_id = c.id WHERE c.environmental_impact > 10;", "generated_sql": "SELECT DISTINCT s.id, s.name\nFROM suppliers s\nJOIN raw_materials rm ON s.id = rm.supplier_id\nJOIN chemicals c ON rm.chemical_id = c.id\nWHERE c.environmental_impact > 15;", "raw_model_output": "To determine which suppliers have provided raw materials for chemicals with a high environmental impact, we first need to define what constitutes \"high\" environmental impact. For this example, let's assume that an environmental impact value greater than 15 is considered high.\n\nHere's the SQL query to find the suppliers who have supplied raw materials for such chemicals:\n\n```sql\nSELECT DISTINCT s.id, s.name\nFROM suppliers s\nJOIN raw_materials rm ON s.id = rm.supplier_id\nJOIN chemicals c ON rm.chemical_id = c.id\nWHERE c.environmental_impact > 15;\n```\n\n### Explanation:\n- We use `JOIN` to connect the tables: \n  - `suppliers` with `raw_materials` on `supplier_id`.\n  - `raw_materials` with `chemicals` on `chemical_id`.\n- The `WHERE` clause filters chemicals with an environmental impact greater than 15.\n- `DISTINCT` ensures that each supplier is listed only once, even if they supplied multiple high-impact chemicals.", "latency_sec": 5.5491273403167725, "total_duration_sec": 5.544075699, "load_duration_sec": 0.011791373, "tokens_prompt": 237, "prompt_eval_sec": 0.037495358, "tokens_completion": 211, "completion_eval_sec": 5.49395184, "tokens_total": 448, "tokens_per_sec": 80.73341491825016, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in two key aspects. First, the Reference SQL filters chemicals with environmental_impact > 10, while the Generated SQL uses > 15. Second, the Generated SQL includes DISTINCT to eliminate duplicates, whereas the Reference SQL does not. Additionally, the Generated SQL selects both id and name, while the Reference only selects name. These differences in filtering conditions and output uniqueness guarantees make the queries non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The queries differ in two key aspects: 1) The reference uses WHERE c.environmental_impact > 10 while the generated uses >15, altering the result set. 2) The generated includes DISTINCT and selects both id/name, while the reference only selects name. The original question doesn't define 'high environmental impact,' but the reference's threshold (10) aligns with the chemicals table's data (ChemA=10, ChemC=15, ChemB=20). The generated query's stricter threshold (15) would exclude ChemC (15) and only include ChemB (20), potentially missing suppliers for ChemC. The reference better fulfills the intent by including all chemicals with impact above the lowest value, while the generated query's condition is more restrictive without clear justification. The reference's simpler output (only names) also matches the question's focus on supplier identification.", "overall_assessment": "differently_correct"}}
{"example_id": 3164, "sql_complexity": "set operations", "prompt": "What is the average age of patients who received therapy in 'clinic_a' and 'clinic_b'?", "context": "CREATE TABLE clinic_a (patient_id INT, age INT, therapy_received BOOLEAN); INSERT INTO clinic_a (patient_id, age, therapy_received) VALUES (1, 35, true), (2, 42, true), (3, 28, false); CREATE TABLE clinic_b (patient_id INT, age INT, therapy_received BOOLEAN); INSERT INTO clinic_b (patient_id, age, therapy_received) VALUES (4, 50, true), (5, 32, false), (6, 45, true);", "reference_sql": "SELECT AVG(age) FROM (SELECT age FROM clinic_a WHERE therapy_received = true UNION ALL SELECT age FROM clinic_b WHERE therapy_received = true) AS combined_clinics;", "generated_sql": "SELECT AVG(age) AS average_age\nFROM (\n    SELECT age FROM clinic_a WHERE therapy_received = TRUE\n    UNION ALL\n    SELECT age FROM clinic_b WHERE therapy_received = TRUE\n) AS combined_clinics;", "raw_model_output": "To find the average age of patients who received therapy in both `clinic_a` and `clinic_b`, we need to combine data from both tables where `therapy_received` is true, and then calculate the average age. Here's how you can do it using a single SQL statement:\n\n```sql\nSELECT AVG(age) AS average_age\nFROM (\n    SELECT age FROM clinic_a WHERE therapy_received = TRUE\n    UNION ALL\n    SELECT age FROM clinic_b WHERE therapy_received = TRUE\n) AS combined_clinics;\n```\n\n### Explanation:\n- We use `UNION ALL` to combine the ages of patients who received therapy from both clinics. `UNION ALL` is used instead of `UNION` because we want to include all records, even if there are duplicates (though in this case, there aren't any).\n- The subquery selects the age of patients where `therapy_received` is true for each clinic.\n- The outer query calculates the average (`AVG`) of these ages.", "latency_sec": 5.312684059143066, "total_duration_sec": 5.307036061, "load_duration_sec": 0.014428029, "tokens_prompt": 201, "prompt_eval_sec": 0.031881957, "tokens_completion": 204, "completion_eval_sec": 5.259834562, "tokens_total": 405, "tokens_per_sec": 76.23265292860768, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries calculate the average age of patients who received therapy (therapy_received = true) from both clinics. The structure of the subquery with UNION ALL is identical, and the only differences are formatting (capitalization of TRUE, column alias in outer query) which do not affect the result set.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the average age of patients who received therapy in either 'clinic_a' or 'clinic_b' by combining results from both clinics using UNION ALL. The reference query uses a subquery without an explicit column alias in the outer SELECT, while the generated query adds an alias ('average_age') for the final result. However, since the original question does not require a specific column name, both produce identical results. The structure and logic are equivalent, and both address the business intent of calculating the average age for therapy recipients across both clinics.", "overall_assessment": "correct"}}
{"example_id": 3704, "sql_complexity": "aggregation", "prompt": "What is the total sales revenue for each category of garments in the South America region in Q1 2022?", "context": "CREATE TABLE sales_category (sale_id INT, garment_category VARCHAR(50), sale_date DATE, total_sales DECIMAL(10, 2), region VARCHAR(50));", "reference_sql": "SELECT garment_category, SUM(total_sales) FROM sales_category WHERE sale_date BETWEEN '2022-01-01' AND '2022-03-31' AND region = 'South America' GROUP BY garment_category;", "generated_sql": "SELECT \n    garment_category,\n    SUM(total_sales) AS total_revenue\nFROM \n    sales_category\nWHERE \n    region = 'South America'\n    AND sale_date >= '2022-01-01' \n    AND sale_date <= '2022-03-31'\nGROUP BY \n    garment_category;", "raw_model_output": "To find the total sales revenue for each category of garments in the South America region during Q1 2022, you can use the following SQL query:\n\n```sql\nSELECT \n    garment_category,\n    SUM(total_sales) AS total_revenue\nFROM \n    sales_category\nWHERE \n    region = 'South America'\n    AND sale_date >= '2022-01-01' \n    AND sale_date <= '2022-03-31'\nGROUP BY \n    garment_category;\n```\n\nThis query filters the records to include only those in the South America region and within the date range of Q1 2022 (January 1, 2022, to March 31, 2022). It then groups the results by `garment_category` and calculates the total sales revenue for each category.", "latency_sec": 4.2683820724487305, "total_duration_sec": 4.26173012, "load_duration_sec": 0.012194323, "tokens_prompt": 129, "prompt_eval_sec": 0.018534339, "tokens_completion": 166, "completion_eval_sec": 4.230396947, "tokens_total": 295, "tokens_per_sec": 69.11283830567709, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries aggregate total_sales by garment_category for records in 'South America' with sale_date between 2022-01-01 and 2022-03-31. The date condition uses equivalent operators (BETWEEN vs. >= and <=) and the grouping/selection logic is identical. The column alias in the generated query does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they filter the same date range (Q1 2022) and region ('South America'), group by garment_category, and calculate total sales revenue. The reference query uses `BETWEEN` while the generated query uses `>=` and `<=`, which are logically identical for date ranges. The generated query adds an explicit alias (`total_revenue`) for clarity, but the reference query's output would still match the business requirement. Both fulfill the intent of calculating category-specific revenue. The superiority is 'equal' as both are correct, though the generated query's alias improves readability without altering functionality.", "overall_assessment": "correct"}}
{"example_id": 2851, "sql_complexity": "single join", "prompt": "How many cases were handled by attorneys who joined the firm in 2015 or later?", "context": "CREATE TABLE attorneys (attorney_id INT, join_year INT); CREATE TABLE cases (case_id INT, attorney_id INT, billing_amount INT);", "reference_sql": "SELECT COUNT(DISTINCT cases.case_id) FROM cases INNER JOIN attorneys ON cases.attorney_id = attorneys.attorney_id WHERE attorneys.join_year >= 2015;", "generated_sql": "SELECT COUNT(DISTINCT c.case_id) AS number_of_cases\nFROM cases c\nJOIN attorneys a ON c.attorney_id = a.attorney_id\nWHERE a.join_year >= 2015;", "raw_model_output": "To solve this problem, we need to count the number of distinct cases that are associated with attorneys who joined the firm in 2015 or later. We will achieve this by joining the `attorneys` and `cases` tables on the `attorney_id` column and applying a filter for the `join_year`.\n\nHere is the SQL statement:\n\n```sql\nSELECT COUNT(DISTINCT c.case_id) AS number_of_cases\nFROM cases c\nJOIN attorneys a ON c.attorney_id = a.attorney_id\nWHERE a.join_year >= 2015;\n```\n\n### Explanation:\n- We use an inner join between `cases` (aliased as `c`) and `attorneys` (aliased as `a`) on the `attorney_id` column to link cases with their respective attorneys.\n- The `WHERE` clause filters for attorneys who joined in 2015 or later (`a.join_year >= 2015`).\n- We use `COUNT(DISTINCT c.case_id)` to count unique case IDs, ensuring that each case is counted only once even if it appears multiple times in the result set.", "latency_sec": 5.886906147003174, "total_duration_sec": 5.882262169, "load_duration_sec": 0.012280456, "tokens_prompt": 119, "prompt_eval_sec": 0.016977945, "tokens_completion": 229, "completion_eval_sec": 5.852405207, "tokens_total": 348, "tokens_per_sec": 59.11424291640102, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count distinct case IDs from a join between 'cases' and 'attorneys' tables where the attorney's join year is >= 2015. The generated query uses table aliases (c/a) and explicit JOIN syntax, but these are syntactic variations that do not affect the semantic result. The core logic (join condition, filter, and aggregation) remains identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries are technically equivalent as they produce identical results by joining the same tables, filtering on attorneys who joined in 2015 or later, and counting distinct case IDs. The generated query uses modern JOIN syntax (omitting INNER) which is functionally identical but more concise. It also employs aliases (c and a) for brevity, enhancing readability without altering semantics. While both fulfill the business intent of counting cases handled by qualifying attorneys, the generated query is more elegant in style and structure.", "overall_assessment": "correct"}}
{"example_id": 3246, "sql_complexity": "single join", "prompt": "What is the average eco-friendliness score of accommodations in Oceania by year?", "context": "CREATE TABLE Accommodations (Accommodation_ID INT, Accommodation_Name VARCHAR(50), City VARCHAR(30), Country VARCHAR(50), Eco_Friendliness_Score INT, Visit_Year INT); INSERT INTO Accommodations (Accommodation_ID, Accommodation_Name, City, Country, Eco_Friendliness_Score, Visit_Year) VALUES (1, 'EcoLodge', 'Sydney', 'Australia', 85, 2019), (2, 'GreenHotel', 'Melbourne', 'Australia', 90, 2019), (3, 'SustainableResort', 'Auckland', 'New Zealand', 80, 2019), (4, 'EcoVilla', 'Wellington', 'New Zealand', 88, 2019); CREATE TABLE Countries (Country VARCHAR(50), Continent VARCHAR(30)); INSERT INTO Countries (Country, Continent) VALUES ('Australia', 'Oceania'), ('New Zealand', 'Oceania');", "reference_sql": "SELECT C.Continent, V.Visit_Year, AVG(A.Eco_Friendliness_Score) AS Avg_Eco_Score  FROM Accommodations A  JOIN Countries C  ON A.Country = C.Country  WHERE C.Continent = 'Oceania'  GROUP BY C.Continent, V.Visit_Year  ORDER BY V.Visit_Year;", "generated_sql": "SELECT \n    a.Visit_Year,\n    AVG(a.Eco_Friendliness_Score) AS Average_Eco_Friendliness_Score\nFROM \n    Accommodations a\nJOIN \n    Countries c ON a.Country = c.Country\nWHERE \n    c.Continent = 'Oceania'\nGROUP BY \n    a.Visit_Year;", "raw_model_output": "To find the average eco-friendliness score of accommodations in Oceania by year, we need to join the `Accommodations` table with the `Countries` table on the `Country` column. Then, we can group the results by `Visit_Year` and calculate the average `Eco_Friendliness_Score`. Here is the SQL statement that accomplishes this:\n\n```sql\nSELECT \n    a.Visit_Year,\n    AVG(a.Eco_Friendliness_Score) AS Average_Eco_Friendliness_Score\nFROM \n    Accommodations a\nJOIN \n    Countries c ON a.Country = c.Country\nWHERE \n    c.Continent = 'Oceania'\nGROUP BY \n    a.Visit_Year;\n```\n\nThis query performs the following steps:\n- Joins `Accommodations` and `Countries` on the `Country` column.\n- Filters the results to include only those accommodations in the continent of Oceania.\n- Groups the filtered data by `Visit_Year`.\n- Calculates the average `Eco_Friendliness_Score` for each year.", "latency_sec": 6.097342014312744, "total_duration_sec": 6.092755474, "load_duration_sec": 0.0178596, "tokens_prompt": 295, "prompt_eval_sec": 0.052973332, "tokens_completion": 229, "completion_eval_sec": 6.01977735, "tokens_total": 524, "tokens_per_sec": 85.939086042734, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL includes 'Continent' in the SELECT and GROUP BY clauses, while the Generated SQL omits it. Although the Continent filter ('Oceania') ensures all results share the same continent value, the output structure differs (extra column in Reference). Additionally, the Reference includes an ORDER BY clause not present in the Generated SQL, which could affect result ordering.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the average eco-friendliness score for Oceania accommodations by year. The reference query includes 'Continent' in SELECT and GROUP BY, but since the WHERE clause filters to 'Oceania', this column is redundant and doesn't affect the result. The generated query is more efficient by omitting unnecessary columns while maintaining identical logic. Both satisfy the business intent of analyzing eco-scores by year for Oceania, but the generated version is cleaner and more focused.", "overall_assessment": "correct"}}
{"example_id": 3056, "sql_complexity": "multiple_joins", "prompt": "Identify all suppliers who provide non-GMO ingredients to restaurants with Michelin stars.", "context": "CREATE TABLE Suppliers (id INT, name VARCHAR(50), isNonGMO BOOLEAN); CREATE TABLE Restaurants (id INT, name VARCHAR(50), numStars INT); CREATE TABLE Ingredients (supplierId INT, restaurantId INT, isNonGMO BOOLEAN);", "reference_sql": "SELECT Suppliers.name FROM Suppliers INNER JOIN Ingredients ON Suppliers.id = Ingredients.supplierId INNER JOIN Restaurants ON Ingredients.restaurantId = Restaurants.id WHERE Restaurants.numStars > 2 AND Ingredients.isNonGMO = TRUE;", "generated_sql": "SELECT DISTINCT s.id, s.name\nFROM Suppliers s\nJOIN Ingredients i ON s.id = i.supplierId\nJOIN Restaurants r ON i.restaurantId = r.id\nWHERE i.isNonGMO = TRUE AND s.isNonGMO = TRUE AND r.numStars > 0;", "raw_model_output": "To solve this problem, we need to identify suppliers that provide non-GMO ingredients specifically to restaurants that have at least one Michelin star. We will use the `Suppliers`, `Restaurants`, and `Ingredients` tables for this query. The key steps are:\n\n1. Join the `Ingredients` table with the `Restaurants` table on `restaurantId` to filter only those restaurants that have a non-zero number of stars.\n2. Further join the result with the `Suppliers` table on `supplierId`.\n3. Ensure that both the ingredient and supplier are marked as non-GMO.\n\nHere is the SQL query:\n\n```sql\nSELECT DISTINCT s.id, s.name\nFROM Suppliers s\nJOIN Ingredients i ON s.id = i.supplierId\nJOIN Restaurants r ON i.restaurantId = r.id\nWHERE i.isNonGMO = TRUE AND s.isNonGMO = TRUE AND r.numStars > 0;\n```\n\n### Explanation:\n\n- `SELECT DISTINCT s.id, s.name`: We select the supplier's ID and name. The `DISTINCT` keyword ensures that each supplier is listed only once.\n- `FROM Suppliers s`: Start with the `Suppliers` table.\n- `JOIN Ingredients i ON s.id = i.supplierId`: Join with the `Ingredients` table to find which suppliers provide ingredients to restaurants.\n- `JOIN Restaurants r ON i.restaurantId = r.id`: Further join with the `Restaurants` table to filter based on Michelin stars.\n- `WHERE i.isNonGMO = TRUE AND s.isNonGMO = TRUE AND r.numStars > 0`: Apply conditions to ensure that:\n  - The ingredient is non-GMO (`i.isNonGMO = TRUE`).\n  - The supplier is non-GMO (`s.isNonGMO = TRUE`).\n  - The restaurant has at least one Michelin star (`r.numStars > 0`).", "latency_sec": 10.174152135848999, "total_duration_sec": 10.169215045, "load_duration_sec": 0.010564766, "tokens_prompt": 141, "prompt_eval_sec": 0.020389087, "tokens_completion": 392, "completion_eval_sec": 10.137295672, "tokens_total": 533, "tokens_per_sec": 52.38765775105278, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in three key aspects: 1) The Reference SQL selects only Suppliers.name, while the Generated SQL selects both id and name. 2) The WHERE clause in the Reference uses Restaurants.numStars > 2, whereas the Generated uses r.numStars > 0. 3) The Generated SQL adds a condition s.isNonGMO = TRUE that isn't present in the Reference. These differences ensure they would produce different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query checks for restaurants with >2 stars (3+), while the generated query uses >0 stars (any star), which better aligns with the general definition of 'Michelin-starred' restaurants (1+ stars). The generated query also includes an unnecessary condition (s.isNonGMO = TRUE) that the reference lacks, which could exclude valid suppliers. However, the generated query uses DISTINCT to avoid duplicates, which is more efficient. The reference's WHERE clause focuses only on the ingredient's non-GMO status, while the generated adds a supplier-level check that isn't required by the question. Neither fully fulfills the intent due to the star threshold discrepancy, but the generated query's broader star condition is more accurate for the business context.", "overall_assessment": "differently_correct"}}
{"example_id": 264, "sql_complexity": "set operations", "prompt": "List the number of community health centers and infectious disease tracking facilities in 'southwest' regions.", "context": "CREATE TABLE centers (id INT, name TEXT, region TEXT); INSERT INTO centers (id, name, region) VALUES (1, 'Center A', 'southwest'); INSERT INTO centers (id, name, region) VALUES (2, 'Center B', 'northeast'); INSERT INTO centers (id, name, region) VALUES (3, 'Center C', 'northwest'); CREATE TABLE diseases (id INT, name TEXT, region TEXT); INSERT INTO diseases (id, name, region) VALUES (1, 'Disease A', 'southwest'); INSERT INTO diseases (id, name, region) VALUES (2, 'Disease B', 'southeast');", "reference_sql": "SELECT COUNT(*) FROM ( (SELECT * FROM centers WHERE region = 'southwest') UNION (SELECT * FROM diseases WHERE region = 'southwest') );", "generated_sql": "SELECT \n    (SELECT COUNT(*) FROM centers WHERE region = 'southwest') AS community_health_centers_count,\n    (SELECT COUNT(*) FROM diseases WHERE region = 'southwest') AS infectious_disease_tracking_facilities_count;", "raw_model_output": "To solve this problem, we need to count the entries in both the `centers` and `diseases` tables where the `region` is `'southwest'`. We can achieve this by using two separate queries for each table and then combining their results. Here's how you can do it:\n\n```sql\nSELECT \n    (SELECT COUNT(*) FROM centers WHERE region = 'southwest') AS community_health_centers_count,\n    (SELECT COUNT(*) FROM diseases WHERE region = 'southwest') AS infectious_disease_tracking_facilities_count;\n```\n\nThis SQL statement uses subqueries to count the number of entries in each table where the `region` is `'southwest'`. The results are returned as two columns: one for community health centers and another for infectious disease tracking facilities.", "latency_sec": 4.22246789932251, "total_duration_sec": 4.217647669, "load_duration_sec": 0.019651525, "tokens_prompt": 230, "prompt_eval_sec": 0.036984474, "tokens_completion": 159, "completion_eval_sec": 4.160104889, "tokens_total": 389, "tokens_per_sec": 92.12621842842537, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL counts the total number of unique rows from both tables combined using UNION, while the Generated SQL returns separate counts for each table. The Reference SQL would return a single value (e.g., 2 for 1 center + 1 disease), whereas the Generated SQL returns two separate values (e.g., 1 and 1). The result structures and values differ.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL combines centers and diseases into a single count using UNION, which merges rows from both tables and loses the distinction between community health centers and infectious disease tracking facilities. This violates the original question's requirement for separate counts. The Generated SQL explicitly separates the counts with two subqueries, directly addressing the business intent. While both queries are syntactically correct, only the Generated SQL produces the required dual metrics. The Generated version is also more efficient as it avoids unnecessary UNION operations and row merging.", "overall_assessment": "differently_correct"}}
{"example_id": 2838, "sql_complexity": "basic SQL", "prompt": "What is the minimum safety rating of electric vehicles in the 'green_cars' table?", "context": "CREATE TABLE green_cars (id INT, make VARCHAR(50), model VARCHAR(50), type VARCHAR(50), safety_rating INT);", "reference_sql": "SELECT MIN(safety_rating) FROM green_cars WHERE type = 'Electric';", "generated_sql": "SELECT MIN(safety_rating) AS min_safety_rating\nFROM green_cars\nWHERE type = 'electric';", "raw_model_output": "To find the minimum safety rating of electric vehicles from the `green_cars` table, you need to filter the records where the `type` column has the value \"electric\" and then determine the smallest value in the `safety_rating` column for those filtered records. Here is the SQL statement that accomplishes this:\n\n```sql\nSELECT MIN(safety_rating) AS min_safety_rating\nFROM green_cars\nWHERE type = 'electric';\n```\n\nThis query uses the `MIN()` aggregate function to find the minimum value of the `safety_rating` column for rows where the `type` is \"electric\". The result is aliased as `min_safety_rating` for clarity.", "latency_sec": 3.6595211029052734, "total_duration_sec": 3.654926233, "load_duration_sec": 0.022305473, "tokens_prompt": 118, "prompt_eval_sec": 0.016630892, "tokens_completion": 142, "completion_eval_sec": 3.614749039, "tokens_total": 260, "tokens_per_sec": 71.04754766780479, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The WHERE clauses use different string literals ('Electric' vs 'electric'), which may not match the same rows depending on the database's case sensitivity. The alias in the SELECT does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly retrieve the minimum safety rating for electric vehicles. The reference query uses 'Electric' (capitalized) in the WHERE clause, while the generated query uses 'electric' (lowercase). However, SQL string comparisons are typically case-insensitive by default in most databases (e.g., MySQL, PostgreSQL with default collations), making them functionally equivalent. The generated query adds an explicit alias ('min_safety_rating') which improves readability and clarity of the result column, enhancing its elegance without altering the semantic meaning. The business intent of identifying the minimum safety rating for electric vehicles is fully satisfied by both queries.", "overall_assessment": "correct"}}
{"example_id": 1187, "sql_complexity": "multiple_joins", "prompt": "Who are the top 3 authors with the highest number of articles published in The Guardian?", "context": "CREATE TABLE authors (id INT, name VARCHAR(100), publisher VARCHAR(50)); CREATE TABLE articles_authors (article_id INT, author_id INT); INSERT INTO authors (id, name, publisher) VALUES (1, 'Author1', 'The Guardian'), (2, 'Author2', 'The Guardian'), (3, 'Author3', 'The Guardian'); INSERT INTO articles_authors (article_id, author_id) VALUES (1, 1), (2, 2), (3, 1), (3, 2), (3, 3); INSERT INTO articles (id, title, publication_date, publisher) VALUES (1, 'Article1', '2021-01-01', 'The Guardian'), (2, 'Article2', '2021-01-02', 'The Guardian'), (3, 'Article3', '2021-01-03', 'The Guardian');", "reference_sql": "SELECT a.name, COUNT(aa.article_id) AS articles_count FROM authors a JOIN articles_authors aa ON a.id = aa.author_id JOIN articles ar ON aa.article_id = ar.id WHERE ar.publisher = 'The Guardian' GROUP BY a.name ORDER BY articles_count DESC LIMIT 3;", "generated_sql": "SELECT a.name, COUNT(aa.article_id) AS article_count\nFROM authors a\nJOIN articles_authors aa ON a.id = aa.author_id\nJOIN articles ar ON aa.article_id = ar.id\nWHERE a.publisher = 'The Guardian' AND ar.publisher = 'The Guardian'\nGROUP BY a.name\nORDER BY article_count DESC\nLIMIT 3;", "raw_model_output": "To find the top 3 authors with the highest number of articles published in \"The Guardian,\" we need to join the `authors` and `articles_authors` tables, filter by the publisher, count the articles for each author, and then order the results. Here's the SQL statement:\n\n```sql\nSELECT a.name, COUNT(aa.article_id) AS article_count\nFROM authors a\nJOIN articles_authors aa ON a.id = aa.author_id\nJOIN articles ar ON aa.article_id = ar.id\nWHERE a.publisher = 'The Guardian' AND ar.publisher = 'The Guardian'\nGROUP BY a.name\nORDER BY article_count DESC\nLIMIT 3;\n```\n\nThis query performs the following steps:\n1. Joins `authors` with `articles_authors` to link authors to their articles.\n2. Further joins with `articles` to ensure we only consider articles published by \"The Guardian.\"\n3. Filters results where both the author's and article's publisher is \"The Guardian.\"\n4. Groups the results by author name to count the number of articles each author has contributed to.\n5. Orders the authors by their article count in descending order.\n6. Limits the result to the top 3 authors with the most articles.", "latency_sec": 6.604478120803833, "total_duration_sec": 6.597979036, "load_duration_sec": 0.011369007, "tokens_prompt": 279, "prompt_eval_sec": 0.044024865, "tokens_completion": 251, "completion_eval_sec": 6.541744754, "tokens_total": 530, "tokens_per_sec": 80.24858138760759, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters only on the article's publisher ('The Guardian'), while the Generated SQL adds an additional condition filtering authors whose publisher is also 'The Guardian'. Although the dataset contains only authors from 'The Guardian', the queries are not semantically equivalent because the Generated SQL imposes an extra constraint on the authors table that could exclude authors with different publishers in other scenarios.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries produce the same results in this specific case. The Reference SQL correctly filters articles by 'The Guardian' publisher (ar.publisher), which aligns with the business intent of counting articles published in The Guardian. The Generated SQL adds an unnecessary condition (a.publisher = 'The Guardian') that doesn't affect results here but could exclude authors with articles in The Guardian if their author record had a different publisher. While both satisfy the technical requirements, the Reference is more precise for the business question.", "overall_assessment": "differently_correct"}}
{"example_id": 360, "sql_complexity": "window functions", "prompt": "What is the change in crime rate for each category, between this year and last year, for the same time period?", "context": "CREATE TABLE CrimeStatistics (ID INT, CrimeType VARCHAR(50), Date TIMESTAMP, Count INT); INSERT INTO CrimeStatistics (ID, CrimeType, Date, Count) VALUES (1, 'Theft', '2022-01-01 00:00:00', 100), (2, 'Vandalism', '2022-01-01 00:00:00', 50), (3, 'Theft', '2022-01-02 00:00:00', 120), (4, 'Vandalism', '2022-01-02 00:00:00', 60), (5, 'Theft', '2021-01-01 00:00:00', 80), (6, 'Vandalism', '2021-01-01 00:00:00', 40), (7, 'Theft', '2021-01-02 00:00:00', 90), (8, 'Vandalism', '2021-01-02 00:00:00', 45);", "reference_sql": "SELECT CrimeType, (SUM(Count) OVER (PARTITION BY CrimeType ORDER BY EXTRACT(YEAR FROM Date) ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING)) - SUM(Count) OVER (PARTITION BY CrimeType ORDER BY EXTRACT(YEAR FROM Date)) AS CrimeRateChange FROM CrimeStatistics WHERE Date BETWEEN DATE_TRUNC('year', CURRENT_DATE - INTERVAL '1 year') AND CURRENT_DATE;", "generated_sql": "WITH CrimeCounts AS (\n    SELECT \n        CrimeType,\n        EXTRACT(YEAR FROM Date) AS Year,\n        SUM(Count) AS TotalCount\n    FROM \n        CrimeStatistics\n    WHERE \n        EXTRACT(MONTH FROM Date) IN (1, 2)\n    GROUP BY \n        CrimeType, \n        EXTRACT(YEAR FROM Date)\n),\nYearlyComparison AS (\n    SELECT \n        c1.CrimeType,\n        c1.TotalCount AS Count2022,\n        c2.TotalCount AS Count2021\n    FROM \n        CrimeCounts c1\n    LEFT JOIN \n        CrimeCounts c2 ON c1.CrimeType = c2.CrimeType AND c2.Year = 2021\n    WHERE \n        c1.Year = 2022\n)\nSELECT \n    CrimeType,\n    COALESCE(Count2022, 0) - COALESCE(Count2021, 0) AS ChangeInCrimeRate\nFROM \n    YearlyComparison;", "raw_model_output": "To calculate the change in crime rate for each category between this year (2022) and last year (2021) for the same time period, we need to compare the total counts of crimes for each type within the specified months across both years. Here's how you can achieve that with a single SQL statement:\n\n```sql\nWITH CrimeCounts AS (\n    SELECT \n        CrimeType,\n        EXTRACT(YEAR FROM Date) AS Year,\n        SUM(Count) AS TotalCount\n    FROM \n        CrimeStatistics\n    WHERE \n        EXTRACT(MONTH FROM Date) IN (1, 2)\n    GROUP BY \n        CrimeType, \n        EXTRACT(YEAR FROM Date)\n),\nYearlyComparison AS (\n    SELECT \n        c1.CrimeType,\n        c1.TotalCount AS Count2022,\n        c2.TotalCount AS Count2021\n    FROM \n        CrimeCounts c1\n    LEFT JOIN \n        CrimeCounts c2 ON c1.CrimeType = c2.CrimeType AND c2.Year = 2021\n    WHERE \n        c1.Year = 2022\n)\nSELECT \n    CrimeType,\n    COALESCE(Count2022, 0) - COALESCE(Count2021, 0) AS ChangeInCrimeRate\nFROM \n    YearlyComparison;\n```\n\n### Explanation:\n\n1. **CTE `CrimeCounts`:** This common table expression calculates the total count of crimes for each crime type and year, but only for January and February (months 1 and 2).\n\n2. **CTE `YearlyComparison`:** This CTE joins the results from `CrimeCounts` on `CrimeType` to compare counts between 2022 and 2021.\n\n3. **Final SELECT:** The final query calculates the change in crime rate by subtracting last year's total count from this year's total count for each crime type. It uses `COALESCE` to handle cases where there might not be data for a particular year, defaulting missing values to zero.", "latency_sec": 10.979605197906494, "total_duration_sec": 10.972775325, "load_duration_sec": 0.014622519, "tokens_prompt": 327, "prompt_eval_sec": 0.058799088, "tokens_completion": 420, "completion_eval_sec": 10.898243678, "tokens_total": 747, "tokens_per_sec": 68.03523319239494, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL calculates a year-over-year change using window functions on all dates within the last year, while the Generated SQL specifically filters for January/February data and compares 2022 vs 2021 directly. The time frames (entire year vs. specific months) and calculation methods (window functions vs. explicit year joins) differ, leading to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL has several issues: 1) It uses window functions with ORDER BY EXTRACT(YEAR FROM Date) which doesn't properly isolate year-over-year comparisons, 2) The WHERE clause uses DATE_TRUNC which may not capture the exact same time period across years, 3) The window frame (ROWS BETWEEN 1 PRECEDING AND 1 PRECEDING) is incorrectly applied for year-over-year calculation. The Generated SQL correctly groups by CrimeType and Year, explicitly compares 2022 vs 2021 data, and uses COALESCE for null handling. However, its WHERE clause restricts to months 1 and 2 which may not align with the original question's 'same time period' unless explicitly required. The Generated SQL better fulfills the business intent of comparing same time periods across years, despite the month restriction which could be adjusted.", "overall_assessment": "differently_correct"}}
{"example_id": 335, "sql_complexity": "single join", "prompt": "List the policy numbers, claim amounts, and claim dates for policies that have more than two claims and the total claim amount exceeds $5000", "context": "CREATE TABLE policies (policy_number INT);CREATE TABLE claims (claim_id INT, policy_number INT, claim_amount DECIMAL(10,2), claim_date DATE);", "reference_sql": "SELECT p.policy_number, c.claim_amount, c.claim_date FROM policies p INNER JOIN claims c ON p.policy_number = c.policy_number GROUP BY p.policy_number, c.claim_amount, c.claim_date HAVING COUNT(c.claim_id) > 2 AND SUM(c.claim_amount) > 5000;", "generated_sql": "SELECT c.policy_number, c.claim_amount, c.claim_date\nFROM claims c\nJOIN (\n    SELECT policy_number,\n           COUNT(*) AS claim_count,\n           SUM(claim_amount) AS total_claim_amount\n    FROM claims\n    GROUP BY policy_number\n    HAVING COUNT(*) > 2 AND SUM(claim_amount) > 5000\n) subquery\nON c.policy_number = subquery.policy_number;", "raw_model_output": "To solve this problem, we need to identify policies with more than two claims and a total claim amount exceeding $5000. We can achieve this by using a subquery or common table expression (CTE) to first calculate the number of claims and the total claim amount for each policy. Then, we filter these results based on the specified conditions.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT c.policy_number, c.claim_amount, c.claim_date\nFROM claims c\nJOIN (\n    SELECT policy_number,\n           COUNT(*) AS claim_count,\n           SUM(claim_amount) AS total_claim_amount\n    FROM claims\n    GROUP BY policy_number\n    HAVING COUNT(*) > 2 AND SUM(claim_amount) > 5000\n) subquery\nON c.policy_number = subquery.policy_number;\n```\n\n### Explanation:\n\n1. **Subquery/CTE**: \n   - We create a subquery that groups the `claims` table by `policy_number`.\n   - For each policy, we calculate:\n     - `COUNT(*) AS claim_count`: The number of claims.\n     - `SUM(claim_amount) AS total_claim_amount`: The total amount of all claims.\n\n2. **Filtering**:\n   - We use the `HAVING` clause to filter policies that have more than two claims (`COUNT(*) > 2`) and a total claim amount exceeding $5000 (`SUM(claim_amount) > 5000`).\n\n3. **Join**:\n   - We join the original `claims` table with this subquery on `policy_number`.\n   - This allows us to select the specific `claim_amount` and `claim_date` for each qualifying policy.\n\nThis query will return the desired results: policy numbers, claim amounts, and claim dates for policies meeting both conditions.", "latency_sec": 9.502946138381958, "total_duration_sec": 9.496093436, "load_duration_sec": 0.011130175, "tokens_prompt": 134, "prompt_eval_sec": 0.017333764, "tokens_completion": 373, "completion_eval_sec": 9.466768781, "tokens_total": 507, "tokens_per_sec": 53.35187557806421, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The reference query groups by policy_number, claim_amount, and claim_date, filtering groups with more than 2 claims and total claim_amount > 5000. The generated query first filters policies with overall count > 2 and sum > 5000, then retrieves all claims for those policies. The generated query lacks the per-group claim_amount/date filtering and returns all claims for qualifying policies, while the reference query returns specific grouped claim records.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL is technically incorrect because it groups by individual claim details (claim_amount, claim_date) rather than policy-level aggregates. This causes the HAVING clause to evaluate per-claim aggregates instead of policy-level totals. The Generated SQL correctly filters policies with >2 claims and total >$5000 in a subquery, then retrieves all claims for those policies. While both queries aim to answer the question, the Generated SQL properly addresses the business intent by first identifying qualifying policies and then listing their claims. The Reference SQL would return incorrect results due to flawed aggregation logic.", "overall_assessment": "differently_correct"}}
{"example_id": 2866, "sql_complexity": "basic SQL", "prompt": "What is the number of hospitals in 'rural_healthcare' table?", "context": "CREATE TABLE rural_healthcare (name VARCHAR(255), type VARCHAR(255), location VARCHAR(255)); INSERT INTO rural_healthcare (name, type, location) VALUES ('Rural General Hospital', 'Hospital', 'Bushland'), ('Rural Community Hospital', 'Hospital', 'Forest Region');", "reference_sql": "SELECT COUNT(*) FROM rural_healthcare WHERE type = 'Hospital';", "generated_sql": "SELECT COUNT(*) AS number_of_hospitals\nFROM rural_healthcare\nWHERE type = 'Hospital';", "raw_model_output": "To find the number of hospitals in the `rural_healthcare` table, you can use a SQL query that counts the rows where the `type` column has the value \"Hospital\". Here's how you can write this query:\n\n```sql\nSELECT COUNT(*) AS number_of_hospitals\nFROM rural_healthcare\nWHERE type = 'Hospital';\n```\n\nThis query uses the `COUNT(*)` function to count all rows in the table that meet the condition specified in the `WHERE` clause, which is where the `type` column equals \"Hospital\". The result will be labeled as `number_of_hospitals`.", "latency_sec": 3.2216479778289795, "total_duration_sec": 3.21491417, "load_duration_sec": 0.021434993, "tokens_prompt": 147, "prompt_eval_sec": 0.018852475, "tokens_completion": 127, "completion_eval_sec": 3.1740027, "tokens_total": 274, "tokens_per_sec": 85.04963977617582, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries count the number of rows where type = 'Hospital'. The generated query adds an alias (number_of_hospitals) to the COUNT(*) result, but this does not change the actual value returned. The WHERE clause and table structure are identical, so the result (2) will be the same.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly count rows where type = 'Hospital' in the rural_healthcare table. The generated query adds an explicit alias (number_of_hospitals) for the COUNT(*) result, which improves readability but doesn't alter the semantic meaning or result. The reference query is more concise but achieves identical technical and business outcomes. Neither query has performance advantages over the other.", "overall_assessment": "correct"}}
{"example_id": 4440, "sql_complexity": "multiple_joins", "prompt": "What is the average session length for each game genre in the last month, sorted by average session length.", "context": "CREATE TABLE game_sessions(id INT, user_id INT, game_name VARCHAR(50), start_time DATETIME, end_time DATETIME); CREATE TABLE games(id INT, name VARCHAR(50), genre VARCHAR(50));", "reference_sql": "SELECT genres.genre, AVG(TIMESTAMPDIFF(SECOND, start_time, end_time)) as avg_session_length FROM game_sessions JOIN games ON game_sessions.game_name = games.name JOIN (SELECT DISTINCT game_name, genre FROM game_sessions JOIN games ON game_sessions.game_name = games.name) genres ON games.name = genres.game_name WHERE start_time >= DATE_SUB(CURRENT_DATE, INTERVAL 1 MONTH) GROUP BY genres.genre ORDER BY avg_session_length DESC;", "generated_sql": "SELECT \n    g.genre,\n    AVG(TIMESTAMPDIFF(SECOND, gs.start_time, gs.end_time)) AS avg_session_length_seconds\nFROM \n    game_sessions gs\nJOIN \n    games g ON gs.game_name = g.name\nWHERE \n    gs.start_time >= DATE_SUB(CURDATE(), INTERVAL 1 MONTH)\nGROUP BY \n    g.genre\nORDER BY \n    avg_session_length_seconds DESC;", "raw_model_output": "To calculate the average session length for each game genre in the last month and sort them by average session length, you can use the following SQL query:\n\n```sql\nSELECT \n    g.genre,\n    AVG(TIMESTAMPDIFF(SECOND, gs.start_time, gs.end_time)) AS avg_session_length_seconds\nFROM \n    game_sessions gs\nJOIN \n    games g ON gs.game_name = g.name\nWHERE \n    gs.start_time >= DATE_SUB(CURDATE(), INTERVAL 1 MONTH)\nGROUP BY \n    g.genre\nORDER BY \n    avg_session_length_seconds DESC;\n```\n\n### Explanation:\n\n- **Join**: We join `game_sessions` (`gs`) with `games` (`g`) on the game name to get access to the genre information.\n  \n- **Filtering**: The `WHERE` clause filters sessions that started in the last month using `DATE_SUB(CURDATE(), INTERVAL 1 MONTH)`.\n\n- **Calculating Average Session Length**: We use `TIMESTAMPDIFF(SECOND, gs.start_time, gs.end_time)` to calculate the session length in seconds for each game session. Then, we take the average of these lengths grouped by genre.\n\n- **Grouping and Sorting**: The results are grouped by `g.genre` and sorted by the calculated average session length in descending order (`DESC`).", "latency_sec": 6.8040220737457275, "total_duration_sec": 6.799334292, "load_duration_sec": 0.019200988, "tokens_prompt": 136, "prompt_eval_sec": 0.018836352, "tokens_completion": 267, "completion_eval_sec": 6.76056854, "tokens_total": 403, "tokens_per_sec": 59.22967263069765, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the average session length per genre by joining game_sessions with games, filtering by the last month's start_time, and grouping by genre. The Reference SQL includes a redundant subquery and additional join that doesn't affect the result, while the Generated SQL simplifies this directly. Since the final grouping and aggregation are identical, the results are equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate average session length per genre for the last month. The Reference query includes an unnecessary subquery and redundant join that doesn't affect results but reduces efficiency. The Generated query is simpler, avoids redundant operations, and achieves the same outcome with clearer logic. Both handle date filtering, grouping, and ordering appropriately.", "overall_assessment": "correct"}}
{"example_id": 451, "sql_complexity": "single join", "prompt": "Which customers have made a transaction over 500 in the \"risk_management\" category?", "context": "CREATE TABLE customers (id INT, name VARCHAR(50), category VARCHAR(50)); INSERT INTO customers (id, name, category) VALUES (1, 'John Doe', 'risk_management'); INSERT INTO customers (id, name, category) VALUES (2, 'Jane Smith', 'compliance'); INSERT INTO customers (id, name, category) VALUES (3, 'Jim Brown', 'risk_management'); CREATE TABLE transactions (id INT, customer_id INT, amount DECIMAL(10, 2)); INSERT INTO transactions (id, customer_id, amount) VALUES (1, 1, 500.00); INSERT INTO transactions (id, customer_id, amount) VALUES (2, 1, 200.00); INSERT INTO transactions (id, customer_id, amount) VALUES (3, 2, 100.00); INSERT INTO transactions (id, customer_id, amount) VALUES (4, 3, 750.00);", "reference_sql": "SELECT c.name FROM customers c INNER JOIN transactions t ON c.id = t.customer_id WHERE c.category = 'risk_management' AND t.amount > 500;", "generated_sql": "SELECT DISTINCT c.id, c.name\nFROM customers c\nJOIN transactions t ON c.id = t.customer_id\nWHERE t.amount > 500 AND c.category = 'risk_management';", "raw_model_output": "To find which customers have made a transaction over $500 in the \"risk_management\" category, you need to join the `customers` and `transactions` tables on the customer ID. Then filter for transactions with an amount greater than 500 and where the customer's category is \"risk_management\". Here is the SQL query:\n\n```sql\nSELECT DISTINCT c.id, c.name\nFROM customers c\nJOIN transactions t ON c.id = t.customer_id\nWHERE t.amount > 500 AND c.category = 'risk_management';\n```\n\nThis query selects distinct customer IDs and names from the `customers` table where there exists a transaction with an amount greater than $500 for that customer in the \"risk_management\" category.", "latency_sec": 3.8851490020751953, "total_duration_sec": 3.877873628, "load_duration_sec": 0.015420134, "tokens_prompt": 284, "prompt_eval_sec": 0.049039888, "tokens_completion": 145, "completion_eval_sec": 3.810828614, "tokens_total": 429, "tokens_per_sec": 110.42047544916706, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL selects only 'c.name', while the Generated SQL selects 'c.id' and 'c.name'. Additionally, the Generated SQL includes 'DISTINCT' which is not present in the Reference SQL, though in this specific case it doesn't affect the result due to unique transaction data. The differing column sets make them semantically distinct.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query returns customer names without deduplication, which could produce multiple rows for customers with multiple qualifying transactions. The generated query uses DISTINCT to ensure each customer appears only once, aligning better with the business intent of identifying customers (not transactions). Both correctly filter for 'risk_management' category and transactions > 500, but the generated query addresses potential duplicates more appropriately for the question's requirement to 'identify customers'.", "overall_assessment": "differently_correct"}}
{"example_id": 2879, "sql_complexity": "basic SQL", "prompt": "Update the FoodSafetyRecords.OrganicFarms table to include a new record for a certified organic farm in Kenya.", "context": "CREATE TABLE FoodSafetyRecords.OrganicFarms (farmName TEXT, country TEXT, certified BOOLEAN);", "reference_sql": "INSERT INTO FoodSafetyRecords.OrganicFarms (farmName, country, certified) VALUES ('Ngong Organic Farm', 'Kenya', TRUE);", "generated_sql": "INSERT INTO FoodSafetyRecords.OrganicFarms (farmName, country, certified)\nVALUES ('New Organic Farm', 'Kenya', TRUE);", "raw_model_output": "To add a new record for a certified organic farm located in Kenya to the `FoodSafetyRecords.OrganicFarms` table, you can use an `INSERT INTO` statement. Here's how you would write it:\n\n```sql\nINSERT INTO FoodSafetyRecords.OrganicFarms (farmName, country, certified)\nVALUES ('New Organic Farm', 'Kenya', TRUE);\n```\n\nIn this SQL statement:\n- `'New Organic Farm'` is a placeholder for the actual name of the farm. You should replace it with the correct farm name.\n- `'Kenya'` specifies the country where the farm is located.\n- `TRUE` indicates that the farm is certified as organic.\n\nMake sure to adjust the `farmName` value to reflect the real name of the farm you are adding.", "latency_sec": 4.2074620723724365, "total_duration_sec": 4.198208203, "load_duration_sec": 0.010039268, "tokens_prompt": 117, "prompt_eval_sec": 0.016856179, "tokens_completion": 164, "completion_eval_sec": 4.170694039, "tokens_total": 281, "tokens_per_sec": 66.78610410896805, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The two queries differ in the farmName value inserted ('Ngong Organic Farm' vs 'New Organic Farm'). While the structure and other values (country 'Kenya', certified TRUE) are identical, the distinct farmName results in different data being inserted, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly insert a new certified organic farm record into the FoodSafetyRecords.OrganicFarms table. The technical structure (syntax, column ordering, data types) is identical, and both satisfy the business requirement of adding a Kenya-based organic farm. The difference in farm names ('Ngong Organic Farm' vs. 'New Organic Farm') does not affect technical or semantic equivalence since the original question did not specify a particular farm name. Neither query is more efficient or elegant than the other, as both are simple, direct inserts.", "overall_assessment": "differently_correct"}}
{"example_id": 5688, "sql_complexity": "single join", "prompt": "What is the total amount donated to a specific cause?", "context": "CREATE TABLE causes (id INT, name TEXT); CREATE TABLE donations (id INT, donor_id INT, cause_id INT, donation_amount DECIMAL(10,2)); INSERT INTO causes (id, name) VALUES (1, 'Cause A'), (2, 'Cause B'); INSERT INTO donations (id, donor_id, cause_id, donation_amount) VALUES (1, 1, 1, 50.00), (2, 2, 1, 100.00);", "reference_sql": "SELECT SUM(donation_amount) FROM donations JOIN causes ON donations.cause_id = causes.id WHERE causes.name = 'Cause A';", "generated_sql": "SELECT SUM(donation_amount) AS total_donation_amount\nFROM donations\nWHERE cause_id = 1;", "raw_model_output": "To find the total amount donated to a specific cause, you need to sum up all the donation amounts for that particular cause from the `donations` table. Assuming we want to calculate this for \"Cause A\" (which has an `id` of 1), here is how you can write the SQL query:\n\n```sql\nSELECT SUM(donation_amount) AS total_donation_amount\nFROM donations\nWHERE cause_id = 1;\n```\n\nThis query calculates the sum of all donation amounts where the `cause_id` matches the specified cause's ID (in this case, 1 for \"Cause A\"). You can replace `1` with any other cause ID to find the total amount donated to a different cause.", "latency_sec": 3.833468198776245, "total_duration_sec": 3.828803448, "load_duration_sec": 0.020960448, "tokens_prompt": 184, "prompt_eval_sec": 0.024478759, "tokens_completion": 147, "completion_eval_sec": 3.781694597, "tokens_total": 331, "tokens_per_sec": 86.34478827962232, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the total donations for 'Cause A'. The reference query uses a JOIN to filter by cause name, while the generated query directly filters by cause_id=1, which corresponds to 'Cause A' in the sample data. Since the data ensures cause_id=1 maps to 'Cause A', both queries produce the same result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the total donations for a specific cause. The reference query uses a JOIN to filter by cause name ('Cause A'), while the generated query directly filters by cause_id = 1. Since the context confirms 'Cause A' corresponds to cause_id 1, both produce identical results. The generated query is more efficient by avoiding a JOIN and is more concise, though the reference better aligns with the business term 'specific cause' (name) in the question. However, the generated query's direct use of the technical ID (1) is equally valid if the cause is identified by its ID. The generated query's simplicity makes it superior in terms of efficiency and elegance.", "overall_assessment": "correct"}}
{"example_id": 3273, "sql_complexity": "multiple_joins", "prompt": "List all departments, the number of chemicals they handle, and the number of machines used in their manufacturing processes.", "context": "CREATE TABLE Departments (DepartmentID INT, DepartmentName VARCHAR(20)); INSERT INTO Departments (DepartmentID, DepartmentName) VALUES (1, 'Manufacturing'), (2, 'Engineering'), (3, 'Chemical Safety'), (4, 'Product Development'); CREATE TABLE Chemicals (ChemicalID INT, ChemicalName VARCHAR(20), DepartmentID INT); INSERT INTO Chemicals (ChemicalID, ChemicalName, DepartmentID) VALUES (1, 'Hydrochloric Acid', 1), (2, 'Nitric Acid', 2), (3, 'Sodium Hydroxide', 3), (4, 'New Chemical', 4); CREATE TABLE Machinery (MachineID INT, MachineName VARCHAR(20), DepartmentID INT); INSERT INTO Machinery (MachineID, MachineName, DepartmentID) VALUES (1, 'Mixer 1', 1), (2, 'Cutter 2', 2), (3, 'Dispenser 3', 3), (4, 'Innovator 4', 4);", "reference_sql": "SELECT D.DepartmentName, COUNT(C.ChemicalID) AS ChemicalCount, COUNT(M.MachineID) AS MachineCount FROM Departments D LEFT JOIN Chemicals C ON D.DepartmentID = C.DepartmentID LEFT JOIN Machinery M ON D.DepartmentID = M.DepartmentID GROUP BY D.DepartmentName;", "generated_sql": "SELECT \n    d.DepartmentID,\n    d.DepartmentName,\n    COUNT(c.ChemicalID) AS NumberOfChemicals,\n    COUNT(m.MachineID) AS NumberOfMachines\nFROM \n    Departments d\nLEFT JOIN \n    Chemicals c ON d.DepartmentID = c.DepartmentID\nLEFT JOIN \n    Machinery m ON d.DepartmentID = m.DepartmentID\nGROUP BY \n    d.DepartmentID, d.DepartmentName;", "raw_model_output": "To solve this problem, we need to count the number of chemicals and machinery associated with each department. We will use a combination of `LEFT JOIN` operations to ensure that all departments are included in the result, even if they have no associated chemicals or machines. Then, we'll use `GROUP BY` to aggregate these counts by department.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    d.DepartmentID,\n    d.DepartmentName,\n    COUNT(c.ChemicalID) AS NumberOfChemicals,\n    COUNT(m.MachineID) AS NumberOfMachines\nFROM \n    Departments d\nLEFT JOIN \n    Chemicals c ON d.DepartmentID = c.DepartmentID\nLEFT JOIN \n    Machinery m ON d.DepartmentID = m.DepartmentID\nGROUP BY \n    d.DepartmentID, d.DepartmentName;\n```\n\n### Explanation:\n\n1. **SELECT Clause**: We select the `DepartmentID` and `DepartmentName` from the `Departments` table. We also use `COUNT(c.ChemicalID)` to count the number of chemicals associated with each department and `COUNT(m.MachineID)` for counting the machines.\n\n2. **FROM Clause**: We start by selecting from the `Departments` table because we want a list of all departments.\n\n3. **LEFT JOIN Operations**:\n   - The first `LEFT JOIN` connects the `Chemicals` table to the `Departments` table using `DepartmentID`. This ensures that even if a department has no chemicals, it will still appear in the result.\n   - The second `LEFT JOIN` connects the `Machinery` table to the `Departments` table similarly.\n\n4. **GROUP BY Clause**: We group by both `DepartmentID` and `DepartmentName` to ensure each department is uniquely identified in the results.\n\n5. **COUNT Function**: \n   - `COUNT(c.ChemicalID)` counts the number of non-null `ChemicalID` values for each department, effectively counting the chemicals.\n   - `COUNT(m.MachineID)` does the same for machines.\n\nUsing `LEFT JOIN` ensures that departments with no associated records in either table still appear in the result set with a count of zero.", "latency_sec": 11.551018953323364, "total_duration_sec": 11.54370248, "load_duration_sec": 0.015968016, "tokens_prompt": 311, "prompt_eval_sec": 0.053306679, "tokens_completion": 444, "completion_eval_sec": 11.473273612, "tokens_total": 755, "tokens_per_sec": 65.3621990450269, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in selected columns (Reference includes only DepartmentName, while Generated includes DepartmentID) and grouping strategy (Reference groups by DepartmentName, Generated groups by DepartmentID and DepartmentName). Although both count chemicals/machinery per department, the output structure and grouping columns make them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent because the generated query includes DepartmentID in the output and grouping, which was not requested in the original question. Both correctly count chemicals/machines per department, but the reference query aligns more closely with the business intent by only returning DepartmentName (as specified) and grouping by it. The generated query's inclusion of DepartmentID adds unnecessary data. While both fulfill the intent of counting chemicals/machines, the reference is more concise and directly addresses the question's requirements. The generated query's grouping by both ID and name is technically safer but not required here.", "overall_assessment": "differently_correct"}}
{"example_id": 1895, "sql_complexity": "window functions", "prompt": "What is the average safety score of chemical production sites in the United States, partitioned by state and ranked in descending order?", "context": "CREATE TABLE production_sites (site_id INT, site_name TEXT, country TEXT, state TEXT, safety_score FLOAT); INSERT INTO production_sites (site_id, site_name, country, state, safety_score) VALUES (1, 'Site A', 'USA', 'NY', 92.5), (2, 'Site B', 'USA', 'CA', 87.4), (3, 'Site C', 'USA', 'TX', 95.3), (4, 'Site D', 'USA', 'FL', 89.2);", "reference_sql": "SELECT state, AVG(safety_score) as avg_safety_score, ROW_NUMBER() OVER (ORDER BY AVG(safety_score) DESC) as rank FROM production_sites WHERE country = 'USA' GROUP BY state ORDER BY rank;", "generated_sql": "SELECT \n    country,\n    state,\n    AVG(safety_score) AS avg_safety_score\nFROM \n    production_sites\nWHERE \n    country = 'USA'\nGROUP BY \n    country, state\nORDER BY \n    avg_safety_score DESC;", "raw_model_output": "To calculate the average safety score of chemical production sites in the United States, partitioned by state and ranked in descending order, you can use the following SQL query:\n\n```sql\nSELECT \n    country,\n    state,\n    AVG(safety_score) AS avg_safety_score\nFROM \n    production_sites\nWHERE \n    country = 'USA'\nGROUP BY \n    country, state\nORDER BY \n    avg_safety_score DESC;\n```\n\nThis query performs the following operations:\n- Filters the records to include only those where `country` is 'USA'.\n- Groups the results by both `country` and `state`.\n- Calculates the average safety score for each group using the `AVG()` function.\n- Orders the results in descending order based on the calculated average safety score.", "latency_sec": 4.189091920852661, "total_duration_sec": 4.182468519, "load_duration_sec": 0.014337635, "tokens_prompt": 211, "prompt_eval_sec": 0.035297793, "tokens_completion": 159, "completion_eval_sec": 4.131674344, "tokens_total": 370, "tokens_per_sec": 88.3246314453489, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL includes a 'rank' column generated by ROW_NUMBER() and selects only 'state' and 'avg_safety_score', while the Generated SQL includes 'country' in the output and groups by both 'country' and 'state'. Additionally, the Reference SQL orders by 'rank' (which depends on the average safety score), whereas the Generated SQL orders directly by 'avg_safety_score'. The column sets and grouping logic differ, leading to different result structures.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference query correctly addresses the ranking requirement by using ROW_NUMBER() to create a rank column, while the generated query omits the ranking entirely. The reference query groups by state (as required) and orders by the calculated rank, though it has a potential technical issue with ordering by an alias ('rank') which may not be allowed in some SQL dialects. The generated query includes 'country' in the output unnecessarily and fails to implement the ranking logic, making it incomplete for the business question. While the reference query's ORDER BY clause might be problematic in certain systems, it better aligns with the intent of ranking results.", "overall_assessment": "differently_correct"}}
{"example_id": 4669, "sql_complexity": "set operations", "prompt": "Identify the number of IoT devices in each country and the total number of devices.", "context": "CREATE TABLE device_country (device_id INT, country TEXT); INSERT INTO device_country (device_id, country) VALUES (1, 'USA'), (2, 'Canada'), (3, 'Mexico'), (4, 'Brazil'); CREATE TABLE device_info (device_id INT, device_type TEXT); INSERT INTO device_info (device_id, device_type) VALUES (1, 'Soil Sensor'), (2, 'Temperature Sensor'), (3, 'Humidity Sensor'), (4, 'Precision Sprayer');", "reference_sql": "SELECT country, COUNT(*) AS device_count FROM device_country GROUP BY country UNION SELECT 'Total' AS country, COUNT(*) FROM device_country;", "generated_sql": "SELECT \n    dc.country,\n    COUNT(di.device_id) AS device_count\nFROM \n    device_country dc\nJOIN \n    device_info di ON dc.device_id = di.device_id\nGROUP BY \n    dc.country\n\nUNION ALL\n\nSELECT \n    'Total' AS country,\n    COUNT(*) AS device_count\nFROM \n    device_country;", "raw_model_output": "To solve this problem, we need to count the number of IoT devices for each country using a `JOIN` between the `device_country` and `device_info` tables. Additionally, we will calculate the total number of devices across all countries. Here's how you can achieve that with an SQL query:\n\n```sql\nSELECT \n    dc.country,\n    COUNT(di.device_id) AS device_count\nFROM \n    device_country dc\nJOIN \n    device_info di ON dc.device_id = di.device_id\nGROUP BY \n    dc.country\n\nUNION ALL\n\nSELECT \n    'Total' AS country,\n    COUNT(*) AS device_count\nFROM \n    device_country;\n```\n\n### Explanation:\n\n1. **Join Tables**: We join `device_country` (`dc`) and `device_info` (`di`) on the `device_id` column to ensure we are counting devices that have both location and type information.\n\n2. **Group By Country**: The first part of the query groups results by country, counting the number of devices in each country using `COUNT(di.device_id)`.\n\n3. **Union All with Total Count**: We use a `UNION ALL` to append another result set that calculates the total number of devices across all countries. This is done by selecting from `device_country` and counting all rows (`COUNT(*)`), which gives us the total count of device entries in the table.\n\n4. **Alias for Clarity**: The alias `'Total' AS country` provides a clear label for the total row, making it easy to distinguish from individual country counts.", "latency_sec": 8.317033052444458, "total_duration_sec": 8.311917956, "load_duration_sec": 0.011191657, "tokens_prompt": 192, "prompt_eval_sec": 0.032913238, "tokens_completion": 319, "completion_eval_sec": 8.267133825, "tokens_total": 511, "tokens_per_sec": 61.440179061187216, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL counts all devices in device_country directly, while the Generated SQL joins device_country with device_info, which could exclude devices without matching entries in device_info. Additionally, the Generated SQL uses UNION ALL instead of UNION, which affects duplicate handling. Although the sample data might produce similar results, the underlying logic and potential data exclusion differ.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The reference query is technically more correct and efficient. While both queries produce the same final count results, the generated query unnecessarily joins with device_info, which is irrelevant to the question about device counts per country. The reference query directly counts from device_country, which is the source of truth for device-country relationships. The generated query's JOIN introduces unnecessary complexity and potential performance overhead. Both queries fulfill the business intent of counting devices per country and total, but the reference is simpler and more direct.", "overall_assessment": "correct"}}
{"example_id": 5302, "sql_complexity": "multiple_joins", "prompt": "Find the supplier with the lowest average delivery time for orders in the last month.", "context": "CREATE TABLE Suppliers (SupplierID int, SupplierName varchar(50)); CREATE TABLE Products (ProductID int, ProductName varchar(50), SupplierID int); CREATE TABLE Orders (OrderID int, ProductID int, OrderDate date, DeliveryTime int); INSERT INTO Suppliers VALUES (1, 'SupplierA'), (2, 'SupplierB'); INSERT INTO Products VALUES (1, 'Organic Apples', 1), (2, 'Bananas', 2); INSERT INTO Orders VALUES (1, 1, '2022-01-01', 2), (2, 2, '2022-01-03', 3);", "reference_sql": "SELECT SupplierName, AVG(DeliveryTime) as AvgDeliveryTime FROM Orders o JOIN Products p ON o.ProductID = p.ProductID JOIN Suppliers sp ON p.SupplierID = sp.SupplierID WHERE OrderDate >= DATEADD(month, -1, GETDATE()) GROUP BY SupplierName ORDER BY AvgDeliveryTime ASC;", "generated_sql": "SELECT \n    s.SupplierID, \n    s.SupplierName,\n    AVG(o.DeliveryTime) AS AvgDeliveryTime\nFROM \n    Orders o\nJOIN \n    Products p ON o.ProductID = p.ProductID\nJOIN \n    Suppliers s ON p.SupplierID = s.SupplierID\nWHERE \n    o.OrderDate BETWEEN '2022-01-01' AND '2022-01-31'\nGROUP BY \n    s.SupplierID, s.SupplierName\nORDER BY \n    AvgDeliveryTime ASC\nLIMIT 1;", "raw_model_output": "To find the supplier with the lowest average delivery time for orders in the last month, we need to perform several steps using SQL:\n\n1. Determine the date range for \"the last month.\" Since there's no specific current date provided, I'll assume a hypothetical scenario where today is '2022-02-01'. Therefore, the last month would be from '2022-01-01' to '2022-01-31'.\n\n2. Join the `Orders`, `Products`, and `Suppliers` tables to get the necessary information about delivery times and suppliers.\n\n3. Calculate the average delivery time for each supplier within this date range.\n\n4. Identify the supplier with the lowest average delivery time.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT \n    s.SupplierID, \n    s.SupplierName,\n    AVG(o.DeliveryTime) AS AvgDeliveryTime\nFROM \n    Orders o\nJOIN \n    Products p ON o.ProductID = p.ProductID\nJOIN \n    Suppliers s ON p.SupplierID = s.SupplierID\nWHERE \n    o.OrderDate BETWEEN '2022-01-01' AND '2022-01-31'\nGROUP BY \n    s.SupplierID, s.SupplierName\nORDER BY \n    AvgDeliveryTime ASC\nLIMIT 1;\n```\n\n### Explanation:\n\n- **Joins**: We join the `Orders` table with the `Products` table on `ProductID`, and then join the resulting set with the `Suppliers` table on `SupplierID`. This allows us to access supplier information for each order.\n\n- **Filtering**: The `WHERE` clause filters orders to include only those within the specified date range ('2022-01-01' to '2022-01-31').\n\n- **Aggregation**: We use `AVG(o.DeliveryTime)` to calculate the average delivery time for each supplier.\n\n- **Grouping**: The `GROUP BY` clause groups results by `SupplierID` and `SupplierName`, which is necessary for calculating averages per supplier.\n\n- **Ordering and Limiting**: Finally, we order the results by `AvgDeliveryTime` in ascending order to find the lowest average delivery time and use `LIMIT 1` to get only the top result.", "latency_sec": 12.163947820663452, "total_duration_sec": 12.157615193, "load_duration_sec": 0.023512786, "tokens_prompt": 222, "prompt_eval_sec": 0.036518192, "tokens_completion": 468, "completion_eval_sec": 12.095299731, "tokens_total": 690, "tokens_per_sec": 56.72500492215739, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in several key aspects.  The Reference SQL uses a dynamic date filter (last month) while the Generated SQL uses a fixed date range.  Additionally, the Generated SQL includes an extra column (SupplierID) and applies a LIMIT 1 clause, which would significantly alter the result set.  Finally, the GROUP BY clause in the Generated SQL includes SupplierID, which is not present in the Reference SQL.  These differences mean the queries would not produce the same results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in three key areas:\n1. Date Calculation: Reference uses dynamic DATEADD(GETDATE()) while Generated uses hardcoded dates (2022-01-01 to 2022-01-31). The Reference correctly calculates 'last month' dynamically, but the Generated version is only valid for the specific dataset provided.\n2. Result Limiting: Generated includes LIMIT 1 to directly return the top supplier, while Reference returns all suppliers sorted by average delivery time. The original question explicitly asks for 'the supplier' (singular), making LIMIT 1 essential for intent fulfillment.\n3. Grouping: Both correctly group by supplier, though Generated groups by SupplierID/Name while Reference groups by Name alone. This doesn't affect results in this dataset but could impact scalability.\nWhile Reference is more dynamically correct, Generated better fulfills the business intent by returning a single result. The hardcoded dates are acceptable given the sample data context.", "overall_assessment": "differently_correct"}}
{"example_id": 267, "sql_complexity": "subqueries", "prompt": "What is the total number of disability support programs offered in urban and rural areas, and the percentage of total programs for each area type?", "context": "CREATE TABLE programs (program_id INT, program_name VARCHAR(255), area_type VARCHAR(255));", "reference_sql": "SELECT area_type, COUNT(*) as total_programs, ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM programs) , 2) as percentage_of_total FROM programs WHERE area_type IN ('urban', 'rural') GROUP BY area_type;", "generated_sql": "SELECT \n    area_type,\n    COUNT(*) AS program_count,\n    ROUND((COUNT(*) * 100.0) / (SELECT COUNT(*) FROM programs), 2) AS percentage_of_total\nFROM \n    programs\nWHERE \n    area_type IN ('urban', 'rural')\nGROUP BY \n    area_type;", "raw_model_output": "To solve this problem, we need to calculate two things: \n1. The total number of disability support programs offered in both urban and rural areas.\n2. The percentage of these programs relative to the total number of programs.\n\nHere's how you can achieve this using a single SQL query:\n\n```sql\nSELECT \n    area_type,\n    COUNT(*) AS program_count,\n    ROUND((COUNT(*) * 100.0) / (SELECT COUNT(*) FROM programs), 2) AS percentage_of_total\nFROM \n    programs\nWHERE \n    area_type IN ('urban', 'rural')\nGROUP BY \n    area_type;\n```\n\n### Explanation:\n- **`SELECT area_type, COUNT(*) AS program_count`:** This part selects the `area_type` and counts the number of programs for each type.\n  \n- **`ROUND((COUNT(*) * 100.0) / (SELECT COUNT(*) FROM programs), 2) AS percentage_of_total`:** \n  - `COUNT(*) * 100.0` calculates the percentage by multiplying the count of programs in each area type by 100.\n  - `(SELECT COUNT(*) FROM programs)` gives the total number of programs across all area types.\n  - The division computes the percentage, and `ROUND(..., 2)` rounds it to two decimal places.\n\n- **`FROM programs`:** Specifies the table from which to retrieve data.\n\n- **`WHERE area_type IN ('urban', 'rural')`:** Filters the results to include only urban and rural areas.\n\n- **`GROUP BY area_type`:** Groups the results by `area_type` so that we get counts and percentages for each specified area type separately.", "latency_sec": 8.675926923751831, "total_duration_sec": 8.671023842, "load_duration_sec": 0.016037702, "tokens_prompt": 119, "prompt_eval_sec": 0.016152585, "tokens_completion": 341, "completion_eval_sec": 8.637689938, "tokens_total": 460, "tokens_per_sec": 53.02027138341512, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries perform the same operations: filtering programs by area_type ('urban' or 'rural'), grouping by area_type, and calculating the count of programs and their percentage of the total. The only differences are in column aliases (total_programs vs. program_count) and formatting, which do not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they produce identical results through the same logical structure. They correctly count programs by area_type ('urban'/'rural'), calculate percentages using the same formula (COUNT(*) * 100.0 / total_programs), and apply proper filtering. The only difference is column alias naming ('total_programs' vs 'program_count'), which doesn't affect functionality. Both queries fully address the business intent by providing absolute counts and relative percentages for the specified area types. Neither query demonstrates superior efficiency or elegance over the other.", "overall_assessment": "correct"}}
{"example_id": 3028, "sql_complexity": "basic SQL", "prompt": "What is the number of startups founded by non-binary individuals in the technology industry?", "context": "CREATE TABLE company (id INT, name TEXT, founder_gender TEXT, industry TEXT); INSERT INTO company (id, name, founder_gender, industry) VALUES (1, 'CodeForAll', 'Non-binary', 'Technology'); INSERT INTO company (id, name, founder_gender, industry) VALUES (2, 'TechVillage', 'Male', 'Technology');", "reference_sql": "SELECT COUNT(*) FROM company WHERE founder_gender = 'Non-binary' AND industry = 'Technology';", "generated_sql": "SELECT COUNT(*) AS non_binary_tech_startups\nFROM company\nWHERE founder_gender = 'Non-binary' AND industry = 'Technology';", "raw_model_output": "To find the number of startups founded by non-binary individuals in the technology industry, you can use a `SELECT` statement with a `COUNT` function and appropriate filtering conditions. Here's the SQL query:\n\n```sql\nSELECT COUNT(*) AS non_binary_tech_startups\nFROM company\nWHERE founder_gender = 'Non-binary' AND industry = 'Technology';\n```\n\nThis query counts all rows in the `company` table where the `founder_gender` is `'Non-binary'` and the `industry` is `'Technology'`. The result will give you the number of such startups.", "latency_sec": 3.125434160232544, "total_duration_sec": 3.120583887, "load_duration_sec": 0.011813264, "tokens_prompt": 162, "prompt_eval_sec": 0.024329824, "tokens_completion": 120, "completion_eval_sec": 3.083632188, "tokens_total": 282, "tokens_per_sec": 90.22746458335828, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries count the number of companies where founder_gender is 'Non-binary' and industry is 'Technology'. The generated query adds an alias to the COUNT(*) result, but this does not affect the semantic result - the same rows are being counted with identical conditions.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they execute the same logic and return identical results. The generated query adds an alias ('non_binary_tech_startups') which improves readability but doesn't alter the semantic meaning. Both correctly filter for 'Non-binary' founders in the 'Technology' industry and count the results. The reference query is more concise, while the generated query provides a descriptive column name. Neither query introduces errors or omissions, and both fully address the business intent of counting startups founded by non-binary individuals in tech.", "overall_assessment": "correct"}}
{"example_id": 3282, "sql_complexity": "aggregation", "prompt": "Which marine species have been observed in both the Arctic and Antarctic oceans?", "context": "CREATE TABLE marine_species (id INT, species_name VARCHAR(50), common_name VARCHAR(50), region VARCHAR(20));INSERT INTO marine_species (id, species_name, common_name, region) VALUES (1, 'Orcinus_orca', 'Killer Whale', 'Arctic');INSERT INTO marine_species (id, species_name, common_name, region) VALUES (2, 'Balaenoptera_bonaerensis', 'Antarctic Minke Whale', 'Antarctic');", "reference_sql": "SELECT species_name FROM marine_species WHERE region IN ('Arctic', 'Antarctic') GROUP BY species_name HAVING COUNT(DISTINCT region) = 2;", "generated_sql": "SELECT DISTINCT ms1.species_name, ms1.common_name\nFROM marine_species ms1\nJOIN marine_species ms2 ON ms1.id = ms2.id\nWHERE ms1.region = 'Arctic' AND ms2.region = 'Antarctic';", "raw_model_output": "To determine which marine species have been observed in both the Arctic and Antarctic regions, we need to identify species that appear with records for both of these regions. This can be achieved by using a self-join on the `marine_species` table.\n\nHere's the SQL statement:\n\n```sql\nSELECT DISTINCT ms1.species_name, ms1.common_name\nFROM marine_species ms1\nJOIN marine_species ms2 ON ms1.id = ms2.id\nWHERE ms1.region = 'Arctic' AND ms2.region = 'Antarctic';\n```\n\n### Explanation:\n- We perform a self-join on the `marine_species` table (`ms1` and `ms2`) using the `id` column to ensure we are comparing records of the same species.\n- The `WHERE` clause filters for pairs where one record is from the Arctic region and the other is from the Antarctic region.\n- We use `DISTINCT` to ensure that each species name appears only once in the result, even if there are multiple entries for a species.", "latency_sec": 5.488147974014282, "total_duration_sec": 5.483377742, "load_duration_sec": 0.011029671, "tokens_prompt": 189, "prompt_eval_sec": 0.029777659, "tokens_completion": 211, "completion_eval_sec": 5.441947711, "tokens_total": 400, "tokens_per_sec": 72.88433218163061, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL finds species present in both Arctic and Antarctic regions by grouping and counting distinct regions. The Generated SQL attempts to join the same table on id (which cannot have both regions simultaneously) and would return no results. They are not equivalent because the Generated SQL's logic is flawed and cannot identify species in multiple regions.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference query correctly identifies species present in both regions by grouping by species_name and checking for two distinct regions. The generated query incorrectly uses a self-join on id, which would only match rows where a single species has both regions in the same row (impossible per schema). The generated query would return no results even if valid data exists. The reference query properly handles multiple entries per species across regions.", "overall_assessment": "incorrect"}}
{"example_id": 3474, "sql_complexity": "subqueries", "prompt": "What is the total transaction volume for the top 3 digital assets by market capitalization in the 'developed_markets' schema?", "context": "CREATE SCHEMA developed_markets; CREATE TABLE developed_markets.digital_assets (asset_name VARCHAR(10), market_cap BIGINT, daily_transaction_volume BIGINT); INSERT INTO developed_markets.digital_assets (asset_name, market_cap, daily_transaction_volume) VALUES ('AssetG', 30000000, 15000000), ('AssetH', 25000000, 12000000), ('AssetI', 20000000, 10000000), ('AssetJ', 15000000, 8000000), ('AssetK', 10000000, 6000000);", "reference_sql": "SELECT SUM(daily_transaction_volume) FROM (SELECT daily_transaction_volume FROM developed_markets.digital_assets ORDER BY market_cap DESC FETCH NEXT 3 ROWS ONLY) t;", "generated_sql": "SELECT SUM(daily_transaction_volume) AS total_transaction_volume\nFROM (\n    SELECT daily_transaction_volume\n    FROM developed_markets.digital_assets\n    ORDER BY market_cap DESC\n    LIMIT 3\n) AS top_assets;", "raw_model_output": "To find the total transaction volume for the top 3 digital assets by market capitalization, you can use a subquery to first select the top 3 assets based on their market cap and then sum their daily transaction volumes. Here's how you can write this query in ANSI SQL:\n\n```sql\nSELECT SUM(daily_transaction_volume) AS total_transaction_volume\nFROM (\n    SELECT daily_transaction_volume\n    FROM developed_markets.digital_assets\n    ORDER BY market_cap DESC\n    LIMIT 3\n) AS top_assets;\n```\n\nThis query works as follows:\n- The subquery selects the `daily_transaction_volume` of all assets, orders them by `market_cap` in descending order to get the highest market caps first, and limits the result to the top 3.\n- The outer query then sums up these transaction volumes to provide the total for the top 3 digital assets.", "latency_sec": 4.696959018707275, "total_duration_sec": 4.690475021, "load_duration_sec": 0.010961479, "tokens_prompt": 220, "prompt_eval_sec": 0.032582966, "tokens_completion": 179, "completion_eval_sec": 4.646288995, "tokens_total": 399, "tokens_per_sec": 84.94858022197842, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the sum of daily_transaction_volume for the top 3 assets by market_cap. The Reference SQL uses FETCH NEXT 3 ROWS ONLY while the Generated SQL uses LIMIT 3, which are functionally equivalent in this context. The subquery aliases and column alias in the Generated SQL do not affect the result set.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the total transaction volume for the top 3 digital assets by market capitalization. They both: 1) Order assets by market_cap DESC, 2) Limit to 3 rows, 3) Sum the daily_transaction_volume. The reference uses FETCH NEXT 3 ROWS ONLY (SQL:2011 standard syntax) while the generated uses LIMIT 3 (common in PostgreSQL/MySQL). Both achieve identical results. The generated query adds an explicit alias (top_assets) which is stylistically clearer, but neither has a technical advantage. The business intent of summing the top 3 market cap assets is fully satisfied by both.", "overall_assessment": "correct"}}
{"example_id": 1626, "sql_complexity": "aggregation", "prompt": "Find the total value of social impact bonds issued by each organization.", "context": "CREATE TABLE social_impact_bonds (id INT, organization_name VARCHAR(255), issue_year INT, value FLOAT); INSERT INTO social_impact_bonds (id, organization_name, issue_year, value) VALUES (1, 'Acme Corp', 2018, 2000000), (2, 'XYZ Foundation', 2019, 3000000), (3, 'Global Giving', 2018, 1500000), (4, 'Acme Corp', 2019, 2500000), (5, 'XYZ Foundation', 2018, 1000000);", "reference_sql": "SELECT organization_name, SUM(value) as total_value FROM social_impact_bonds GROUP BY organization_name;", "generated_sql": "SELECT \n    organization_name,\n    SUM(value) AS total_value\nFROM \n    social_impact_bonds\nGROUP BY \n    organization_name;", "raw_model_output": "To find the total value of social impact bonds issued by each organization, you can use the `SUM` aggregate function along with the `GROUP BY` clause. Here's the SQL statement that accomplishes this:\n\n```sql\nSELECT \n    organization_name,\n    SUM(value) AS total_value\nFROM \n    social_impact_bonds\nGROUP BY \n    organization_name;\n```\n\nThis query groups the records by `organization_name` and calculates the sum of the `value` column for each group, resulting in the total value of bonds issued by each organization.", "latency_sec": 3.0707976818084717, "total_duration_sec": 3.066818804, "load_duration_sec": 0.019949873, "tokens_prompt": 210, "prompt_eval_sec": 0.031745465, "tokens_completion": 114, "completion_eval_sec": 3.014111004, "tokens_total": 324, "tokens_per_sec": 105.510044481077, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries select the same columns (organization_name and SUM(value) as total_value) from the same table (social_impact_bonds) and apply the same GROUP BY clause on organization_name. The syntax and logic are identical, so they will produce the same results.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are identical in structure, logic, and output. They correctly aggregate the total value of social impact bonds by organization using SUM(value) with GROUP BY organization_name. The reference and generated queries contain the same SQL syntax, produce identical results, and address the business requirement to calculate organization-specific totals. The formatting differences (e.g., line breaks) do not affect functionality or correctness.", "overall_assessment": "correct"}}
{"example_id": 1315, "sql_complexity": "single join", "prompt": "List all the transactions made by clients living in New York with a transaction amount greater than $1000.", "context": "CREATE TABLE transactions (id INT, client_id INT, transaction_amount DECIMAL(10,2), transaction_date DATE); INSERT INTO transactions (id, client_id, transaction_amount, transaction_date) VALUES (1, 3, 1500.00, '2022-01-01'), (2, 4, 800.00, '2022-01-02'), (3, 3, 1200.00, '2022-01-03'); CREATE TABLE clients (id INT, name VARCHAR(255), state VARCHAR(255)); INSERT INTO clients (id, name, state) VALUES (3, 'Mike Johnson', 'New York'), (4, 'Sara Lee', 'California');", "reference_sql": "SELECT transactions.id, transactions.client_id, transactions.transaction_amount, transactions.transaction_date FROM transactions INNER JOIN clients ON transactions.client_id = clients.id WHERE clients.state = 'New York' AND transactions.transaction_amount > 1000.00;", "generated_sql": "SELECT t.id, t.client_id, t.transaction_amount, t.transaction_date\nFROM transactions t\nJOIN clients c ON t.client_id = c.id\nWHERE c.state = 'New York'\nAND t.transaction_amount > 1000;", "raw_model_output": "To solve this problem, we need to join the `transactions` table with the `clients` table on the `client_id` and `id` columns respectively. Then, filter the results based on the state of the client being 'New York' and the transaction amount being greater than $1000.\n\nHere is the SQL statement that accomplishes this:\n\n```sql\nSELECT t.id, t.client_id, t.transaction_amount, t.transaction_date\nFROM transactions t\nJOIN clients c ON t.client_id = c.id\nWHERE c.state = 'New York'\nAND t.transaction_amount > 1000;\n```\n\nThis query selects all the relevant columns from the `transactions` table for those transactions where the client's state is 'New York' and the transaction amount exceeds $1000.", "latency_sec": 4.299516916275024, "total_duration_sec": 4.294664204, "load_duration_sec": 0.01182708, "tokens_prompt": 242, "prompt_eval_sec": 0.036568146, "tokens_completion": 160, "completion_eval_sec": 4.24558586, "tokens_total": 402, "tokens_per_sec": 93.49887622916508, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries perform an INNER JOIN between transactions and clients tables on client_id, filter for clients in 'New York', and select transactions with amount > 1000. The generated query uses table aliases (t and c) but maintains identical join conditions, WHERE clauses, and selected columns. The semantic meaning remains unchanged.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent, as they produce identical results by joining the transactions and clients tables on client_id, filtering for New York clients with transaction amounts > $1000. The Reference SQL uses explicit table names while the Generated SQL uses aliases (t/c), but this is purely syntactic variation. Both correctly address the business intent by retrieving transactions meeting the specified criteria. The Generated SQL is slightly more concise with aliases, but neither query demonstrates significant efficiency differences given the simple schema. The results will include transactions 1 (1500) and 3 (1200) from client_id 3 in New York.", "overall_assessment": "correct"}}
{"example_id": 520, "sql_complexity": "multiple_joins", "prompt": "What is the total number of electric vehicles sold in 'California' in the 'sales' schema?", "context": "CREATE TABLE sales_regions (id INT, name VARCHAR(50));   CREATE TABLE sales (id INT, region_id INT, vehicle_count INT);   CREATE TABLE vehicles (id INT, type VARCHAR(50));   INSERT INTO sales_regions VALUES (1, 'California');   INSERT INTO sales VALUES (1, 1, 5000);   INSERT INTO vehicles VALUES (1, 'electric');", "reference_sql": "SELECT SUM(sales.vehicle_count) FROM sales INNER JOIN sales_regions ON sales.region_id = sales_regions.id INNER JOIN vehicles ON sales.id = vehicles.id WHERE vehicles.type = 'electric' AND sales_regions.name = 'California';", "generated_sql": "SELECT SUM(s.vehicle_count) AS total_vehicles_sold_in_california\nFROM sales s\nJOIN sales_regions sr ON s.region_id = sr.id\nWHERE sr.name = 'California';", "raw_model_output": "To find the total number of electric vehicles sold in California, we need to join the `sales`, `sales_regions`, and `vehicles` tables. However, based on the provided schema, there is no direct relationship between the `sales` table and the `vehicles` table. Therefore, it's not possible to directly determine the type of vehicle from the `sales` data alone.\n\nGiven this limitation, we can only calculate the total number of vehicles sold in California without distinguishing by vehicle type. Here's how you would write an SQL query to find the total number of vehicles sold in California:\n\n```sql\nSELECT SUM(s.vehicle_count) AS total_vehicles_sold_in_california\nFROM sales s\nJOIN sales_regions sr ON s.region_id = sr.id\nWHERE sr.name = 'California';\n```\n\nThis query calculates the total vehicle count for sales in the region named 'California'. However, without additional data linking `sales` to specific `vehicle` types, we cannot filter by electric vehicles specifically.", "latency_sec": 5.276515245437622, "total_duration_sec": 5.271586429, "load_duration_sec": 0.016574009, "tokens_prompt": 172, "prompt_eval_sec": 0.023795167, "tokens_completion": 203, "completion_eval_sec": 5.230447191, "tokens_total": 375, "tokens_per_sec": 71.06963261865803, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes a join with the vehicles table and filters by vehicles.type = 'electric', while the Generated SQL omits this join and filter. The Generated SQL only sums vehicle_count for California sales without considering vehicle type, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference query correctly joins all three required tables (sales, sales_regions, and vehicles) and includes the critical filter WHERE vehicles.type = 'electric' to ensure only electric vehicles are counted. The generated query omits the vehicles table entirely, missing the essential 'type' filter. While both queries sum vehicle_count for California, the generated query would return the total vehicles sold (regardless of type) rather than specifically electric vehicles. This makes the generated query technically incorrect for the business question, which explicitly requires electric vehicle data.", "overall_assessment": "incorrect"}}
{"example_id": 3999, "sql_complexity": "single join", "prompt": "What is the total number of tickets sold for performances with a rating of 5?", "context": "CREATE TABLE performance (id INT PRIMARY KEY, name VARCHAR(255), date DATE, artist_id INT, rating INT); INSERT INTO performance (id, name, date, artist_id, rating) VALUES (1, 'Dance Recital', '2022-03-01', 1, 5);", "reference_sql": "SELECT SUM(t.quantity) as total_tickets_sold FROM performance p INNER JOIN ticket t ON p.id = t.performance_id WHERE p.rating = 5;", "generated_sql": "SELECT SUM(ts.tickets_sold) AS total_tickets_sold\nFROM performance p\nJOIN ticket_sales ts ON p.id = ts.performance_id\nWHERE p.rating = 5;", "raw_model_output": "To answer this question using the provided schema, we need to make some assumptions since there's no direct information about ticket sales in the `performance` table. Typically, you would have another table that records ticket sales associated with each performance. However, given only the `performance` table and its columns, we can't directly calculate the number of tickets sold.\n\nAssuming a hypothetical scenario where the `rating` somehow correlates to ticket sales (e.g., higher ratings might imply more tickets sold), but without explicit data on ticket sales, we cannot accurately determine the total number of tickets sold for performances with a rating of 5. \n\nIf there were a table like `ticket_sales(performance_id INT, tickets_sold INT)`, you could use it to calculate the total tickets sold for performances with a rating of 5 using an SQL query similar to this:\n\n```sql\nSELECT SUM(ts.tickets_sold) AS total_tickets_sold\nFROM performance p\nJOIN ticket_sales ts ON p.id = ts.performance_id\nWHERE p.rating = 5;\n```\n\nHowever, since no such table is provided in the schema, we cannot construct a valid SQL statement to answer the question based on the given information.", "latency_sec": 6.257694959640503, "total_duration_sec": 6.253055262, "load_duration_sec": 0.011543126, "tokens_prompt": 152, "prompt_eval_sec": 0.019564597, "tokens_completion": 241, "completion_eval_sec": 6.221269063, "tokens_total": 393, "tokens_per_sec": 62.802677748705314, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries reference different tables ('ticket' vs. 'ticket_sales') and columns ('quantity' vs. 'tickets_sold'). While the structure and join conditions are similar, the semantic equivalence depends on these tables/columns being functionally identical, which cannot be confirmed from the provided schema. Without explicit confirmation that 'ticket' and 'ticket_sales' are the same table with equivalent columns, the queries are not guaranteed to produce the same result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the total tickets sold for performances with a rating of 5 by joining the performance table with a ticket-related table (ticket/ticket_sales) on performance_id and summing the relevant column (quantity/tickets_sold). The differences are purely syntactic (table/column names) and do not affect the logical outcome. Neither query is more efficient or elegant than the other, as both use equivalent join patterns and aggregation. The business intent is fully addressed by both queries.", "overall_assessment": "correct"}}
{"example_id": 2261, "sql_complexity": "multiple_joins", "prompt": "What is the total number of animals that have been released into 'protected' habitats, and the average weight of those animals?", "context": "CREATE TABLE habitats (habitat_id INT, habitat_name VARCHAR(50), habitat_status VARCHAR(50)); INSERT INTO habitats (habitat_id, habitat_name, habitat_status) VALUES (1, 'Habitat A', 'protected'), (2, 'Habitat B', 'unprotected'); CREATE TABLE animal_habitats (animal_id INT, habitat_id INT, animal_weight FLOAT); INSERT INTO animal_habitats (animal_id, habitat_id, animal_weight) VALUES (101, 1, 25.5), (102, 2, 15.2); CREATE TABLE animals (animal_id INT, animal_name VARCHAR(50)); INSERT INTO animals (animal_id, animal_name) VALUES (101, 'Dog'), (102, 'Cat');", "reference_sql": "SELECT COUNT(*), AVG(animal_habitats.animal_weight) FROM animal_habitats INNER JOIN animals ON animal_habitats.animal_id = animals.animal_id INNER JOIN habitats ON animal_habitats.habitat_id = habitats.habitat_id WHERE habitats.habitat_status = 'protected';", "generated_sql": "SELECT \n    COUNT(DISTINCT ah.animal_id) AS total_animals,\n    AVG(ah.animal_weight) AS average_weight\nFROM \n    animal_habitats ah\nJOIN \n    habitats h ON ah.habitat_id = h.habitat_id\nWHERE \n    h.habitat_status = 'protected';", "raw_model_output": "To solve this problem, we need to calculate two things: the total number of animals in 'protected' habitats and their average weight. We will join the `animal_habitats` table with the `habitats` table to filter for 'protected' habitats, then aggregate the results.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    COUNT(DISTINCT ah.animal_id) AS total_animals,\n    AVG(ah.animal_weight) AS average_weight\nFROM \n    animal_habitats ah\nJOIN \n    habitats h ON ah.habitat_id = h.habitat_id\nWHERE \n    h.habitat_status = 'protected';\n```\n\n### Explanation:\n\n- **Join**: We join `animal_habitats` (`ah`) with `habitats` (`h`) on the `habitat_id` to access habitat status information.\n- **Filter**: The `WHERE` clause filters for habitats where `habitat_status` is 'protected'.\n- **Count**: `COUNT(DISTINCT ah.animal_id)` counts unique animal IDs in protected habitats, giving us the total number of animals.\n- **Average Weight**: `AVG(ah.animal_weight)` calculates the average weight of these animals.", "latency_sec": 6.64468789100647, "total_duration_sec": 6.639146362, "load_duration_sec": 0.020544937, "tokens_prompt": 253, "prompt_eval_sec": 0.037873096, "tokens_completion": 251, "completion_eval_sec": 6.579672306, "tokens_total": 504, "tokens_per_sec": 75.8500637301806, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their aggregation logic. The Reference SQL uses COUNT(*) which counts all rows, while the Generated SQL uses COUNT(DISTINCT ah.animal_id) which counts unique animal IDs. If there are multiple entries per animal in animal_habitats, these would produce different results. Additionally, the Reference SQL includes an unnecessary join with the animals table, but this doesn't affect the output since no columns from animals are used.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in two key aspects. 1) The reference query uses COUNT(*), which counts all rows, while the generated query uses COUNT(DISTINCT ah.animal_id), which accurately counts unique animals. This is crucial because the question asks for the 'total number of animals' not the number of records. 2) The reference query includes an unnecessary join with the animals table, which doesn't affect the result but reduces efficiency. Both queries correctly calculate the average weight. The generated query better fulfills the business intent by accurately counting unique animals and is more efficient.", "overall_assessment": "differently_correct"}}
{"example_id": 3439, "sql_complexity": "multiple_joins", "prompt": "How many menu items contain ingredients sourced from local suppliers for each restaurant?", "context": "CREATE TABLE restaurants (id INT, name VARCHAR(50), location VARCHAR(50)); INSERT INTO restaurants VALUES (1, 'Restaurant A', 'City A'); INSERT INTO restaurants VALUES (2, 'Restaurant B', 'City B'); CREATE TABLE menu_items (id INT, name VARCHAR(50), restaurant_id INT, price DECIMAL(5,2)); INSERT INTO menu_items VALUES (1, 'Item A', 1, 10.99); INSERT INTO menu_items VALUES (2, 'Item B', 1, 12.99); INSERT INTO menu_items VALUES (3, 'Item C', 2, 11.99); CREATE TABLE ingredients (id INT, name VARCHAR(50), local_source BOOLEAN, menu_item_id INT); INSERT INTO ingredients VALUES (1, 'Ingredient A', TRUE, 1); INSERT INTO ingredients VALUES (2, 'Ingredient B', FALSE, 1); INSERT INTO ingredients VALUES (3, 'Ingredient C', TRUE, 2); INSERT INTO ingredients VALUES (4, 'Ingredient D', FALSE, 2); INSERT INTO ingredients VALUES (5, 'Ingredient E', TRUE, 3);", "reference_sql": "SELECT r.name, COUNT(DISTINCT mi.id) as num_local_items FROM restaurants r JOIN menu_items mi ON r.id = mi.restaurant_id JOIN ingredients i ON mi.id = i.menu_item_id WHERE i.local_source = TRUE GROUP BY r.name;", "generated_sql": "SELECT \n    r.id AS restaurant_id,\n    r.name AS restaurant_name,\n    COUNT(DISTINCT mi.id) AS local_ingredient_menu_items_count\nFROM \n    restaurants r\nJOIN \n    menu_items mi ON r.id = mi.restaurant_id\nJOIN \n    ingredients i ON mi.id = i.menu_item_id\nWHERE \n    i.local_source = TRUE\nGROUP BY \n    r.id, r.name;", "raw_model_output": "To solve this problem, we need to count the number of unique menu items that have at least one ingredient sourced locally for each restaurant. We can achieve this by joining the `menu_items` and `ingredients` tables on the `id` column of `menu_items` and the `menu_item_id` column of `ingredients`. Then, we filter for ingredients where `local_source` is `TRUE`, group by the `restaurant_id`, and count the distinct menu items.\n\nHere's the SQL query to accomplish this:\n\n```sql\nSELECT \n    r.id AS restaurant_id,\n    r.name AS restaurant_name,\n    COUNT(DISTINCT mi.id) AS local_ingredient_menu_items_count\nFROM \n    restaurants r\nJOIN \n    menu_items mi ON r.id = mi.restaurant_id\nJOIN \n    ingredients i ON mi.id = i.menu_item_id\nWHERE \n    i.local_source = TRUE\nGROUP BY \n    r.id, r.name;\n```\n\nThis query performs the following steps:\n- Joins `restaurants` with `menu_items` on `restaurant_id`.\n- Further joins `menu_items` with `ingredients` on `menu_item_id`.\n- Filters for ingredients where `local_source` is `TRUE`.\n- Groups the results by restaurant `id` and `name`.\n- Counts distinct menu items that have at least one local ingredient per restaurant.", "latency_sec": 7.33362078666687, "total_duration_sec": 7.32731415, "load_duration_sec": 0.011004825, "tokens_prompt": 319, "prompt_eval_sec": 0.054828844, "tokens_completion": 276, "completion_eval_sec": 7.260212838, "tokens_total": 595, "tokens_per_sec": 81.13318336308843, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their GROUP BY clauses. The Reference SQL groups by 'r.name' alone, which could combine multiple restaurants with the same name. The Generated SQL groups by both 'r.id' and 'r.name', ensuring each restaurant is uniquely identified. While the data in the example has unique names, the schema does not enforce uniqueness, making the queries non-equivalent in general cases.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly count menu items with local ingredients per restaurant. The Reference SQL groups by restaurant name, which works in this dataset but risks incorrect aggregation if multiple restaurants share the same name. The Generated SQL groups by both restaurant ID and name, ensuring accuracy even with non-unique names. While the Reference directly answers the question's phrasing ('for each restaurant'), the Generated version is more robust and includes explicit identifiers. The Generated query is slightly more elegant due to its precise grouping and explicit column aliases.", "overall_assessment": "correct"}}
{"example_id": 2265, "sql_complexity": "aggregation", "prompt": "Hourly revenue for a specific movie?", "context": "CREATE TABLE Movie_Revenue (id INT, movie_title VARCHAR(100), revenue_time TIME, revenue DECIMAL(10,2));", "reference_sql": "SELECT revenue_time, SUM(revenue) FROM Movie_Revenue WHERE movie_title = 'Spider-Man: No Way Home' GROUP BY revenue_time;", "generated_sql": "SELECT \n    DATE_FORMAT(CONCAT(CURDATE(), ' ', revenue_time), '%Y-%m-%d %H:00:00') AS hourly,\n    SUM(revenue) AS total_revenue\nFROM \n    Movie_Revenue\nWHERE \n    movie_title = 'Your Specific Movie Title'\nGROUP BY \n    hourly;", "raw_model_output": "To calculate the hourly revenue for a specific movie from the `Movie_Revenue` table, you need to group the data by hour and sum up the revenues. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    DATE_FORMAT(CONCAT(CURDATE(), ' ', revenue_time), '%Y-%m-%d %H:00:00') AS hourly,\n    SUM(revenue) AS total_revenue\nFROM \n    Movie_Revenue\nWHERE \n    movie_title = 'Your Specific Movie Title'\nGROUP BY \n    hourly;\n```\n\n### Explanation:\n- **DATE_FORMAT and CONCAT**: These functions are used to format the `revenue_time` into an hourly interval. The `CONCAT(CURDATE(), ' ', revenue_time)` combines today's date with the time, and `DATE_FORMAT(..., '%Y-%m-%d %H:00:00')` formats it to truncate minutes and seconds, effectively grouping by hour.\n- **SUM(revenue)**: This calculates the total revenue for each hourly group.\n- **WHERE clause**: Filters the results to include only the specified movie title.\n- **GROUP BY hourly**: Groups the results by the formatted hourly intervals.\n\nReplace `'Your Specific Movie Title'` with the actual title of the movie you are interested in.", "latency_sec": 6.761973857879639, "total_duration_sec": 6.754643546, "load_duration_sec": 0.020869417, "tokens_prompt": 107, "prompt_eval_sec": 0.013771678, "tokens_completion": 264, "completion_eval_sec": 6.7191759, "tokens_total": 371, "tokens_per_sec": 54.86563654304558, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The reference query groups by the exact 'revenue_time' (TIME type), while the generated query groups by a formatted hourly string (YYYY-MM-DD HH:00:00) derived from the current date and 'revenue_time'. Additionally, the WHERE clause uses different movie titles ('Spider-Man: No Way Home' vs. 'Your Specific Movie Title'). The grouping logic and filter conditions differ, leading to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in how they handle time grouping. The reference query groups by the raw TIME column, which may not properly aggregate revenue within the same hour (e.g., 10:30 and 10:45 would be separate). The generated query uses DATE_FORMAT to explicitly truncate minutes/seconds, ensuring all entries within the same hour are grouped together. While both are syntactically correct, the generated query better fulfills the business intent of calculating hourly revenue. The reference query could produce incorrect results if multiple revenue entries exist within the same hour. The generated query also includes a more explicit 'hourly' timestamp format, improving clarity.", "overall_assessment": "differently_correct"}}
{"example_id": 1763, "sql_complexity": "multiple_joins", "prompt": "What is the total food and beverage revenue last month for hotels in 'Bangkok'?", "context": "CREATE TABLE revenue (hotel_id INT, revenue_source VARCHAR(50), revenue INT, revenue_date DATE); INSERT INTO revenue (hotel_id, revenue_source, revenue, revenue_date) VALUES (5, 'Room revenue', 12000, '2022-03-01'), (5, 'Food and beverage', 4000, '2022-03-02'), (5, 'Other revenue', 1000, '2022-03-03'); CREATE TABLE hotels (hotel_id INT, city VARCHAR(50)); INSERT INTO hotels (hotel_id, city) VALUES (5, 'Bangkok'); CREATE TABLE dates (date DATE); INSERT INTO dates (date) VALUES ('2022-03-01'), ('2022-03-02'), ('2022-03-03');", "reference_sql": "SELECT SUM(revenue) FROM revenue JOIN hotels ON revenue.hotel_id = hotels.hotel_id JOIN dates ON revenue.revenue_date = dates.date WHERE hotels.city = 'Bangkok' AND revenue_source = 'Food and beverage' AND dates.date >= DATEADD(month, -1, GETDATE());", "generated_sql": "SELECT SUM(r.revenue) AS total_food_and_beverage_revenue\nFROM revenue r\nJOIN hotels h ON r.hotel_id = h.hotel_id\nWHERE r.revenue_source = 'Food and beverage'\n  AND h.city = 'Bangkok'\n  AND EXTRACT(YEAR FROM r.revenue_date) = 2022\n  AND EXTRACT(MONTH FROM r.revenue_date) = 2;", "raw_model_output": "To calculate the total food and beverage revenue for hotels located in 'Bangkok' from the previous month, we need to determine what \"last month\" refers to based on the current date. Since the data provided only includes dates up to March 3, 2022, let's assume today is March 31, 2022, making February 2022 the last full month.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT SUM(r.revenue) AS total_food_and_beverage_revenue\nFROM revenue r\nJOIN hotels h ON r.hotel_id = h.hotel_id\nWHERE r.revenue_source = 'Food and beverage'\n  AND h.city = 'Bangkok'\n  AND EXTRACT(YEAR FROM r.revenue_date) = 2022\n  AND EXTRACT(MONTH FROM r.revenue_date) = 2;\n```\n\n### Explanation:\n- **SUM(r.revenue)**: This calculates the total revenue from food and beverage.\n- **FROM revenue r**: We are selecting data from the `revenue` table, aliased as `r`.\n- **JOIN hotels h ON r.hotel_id = h.hotel_id**: We join the `hotels` table to get city information for each hotel.\n- **WHERE r.revenue_source = 'Food and beverage'**: Filters the revenue source to only include food and beverage.\n- **AND h.city = 'Bangkok'**: Ensures we are considering hotels located in Bangkok.\n- **AND EXTRACT(YEAR FROM r.revenue_date) = 2022 AND EXTRACT(MONTH FROM r.revenue_date) = 2**: Filters the data to include only entries from February 2022, which is considered \"last month\" given our assumed current date of March 31, 2022. Adjust these values if your reference point for \"today\" changes.\n\nThis query will return the total food and beverage revenue for hotels in Bangkok for February 2022 based on the provided data.", "latency_sec": 10.53031587600708, "total_duration_sec": 10.525022693, "load_duration_sec": 0.013792315, "tokens_prompt": 253, "prompt_eval_sec": 0.039397344, "tokens_completion": 410, "completion_eval_sec": 10.471083431, "tokens_total": 663, "tokens_per_sec": 62.96107427419343, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their date filtering logic. The Reference SQL uses `dates.date >= DATEADD(month, -1, GETDATE())` which depends on the current date, while the Generated SQL uses `EXTRACT(YEAR FROM r.revenue_date) = 2022 AND EXTRACT(MONTH FROM r.revenue_date) = 2` to explicitly filter for February 2022. This makes them non-equivalent, as the date ranges and conditions are not the same.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The queries are not technically equivalent. The reference query uses DATEADD(month, -1, GETDATE()) to dynamically calculate the start of the last month, but this condition (dates.date >= ...) would include all dates from that point forward, not just the full previous month. The generated query hardcodes the year (2022) and month (2) instead of dynamically calculating 'last month', which would only return data from February 2022 regardless of the current date. Neither query correctly captures the entire previous month, but the reference query uses a dynamic approach while the generated query is statically hardcoded. The reference query also unnecessarily joins with the dates table, which is redundant since revenue_date is already in the revenue table. The generated query fails to fulfill the business intent because it explicitly restricts to a specific month (February 2022) rather than calculating 'last month' dynamically.", "overall_assessment": "differently_correct"}}
{"example_id": 5499, "sql_complexity": "set operations", "prompt": "How many legal aid clinics and community mediation centers are there in total, and what is the sum of cases handled by each type of center, for centers located in the state of California?", "context": "CREATE TABLE LegalAidClinics (ClinicName text, State text, NumCases int); INSERT INTO LegalAidClinics VALUES ('Clinic1', 'CA', 30, '2022-01-01'), ('Clinic2', 'CA', 25, '2022-01-01'); CREATE TABLE CommunityMediationCenters (CenterName text, State text, NumCases int); INSERT INTO CommunityMediationCenters VALUES ('CM1', 'CA', 22, '2022-01-01'), ('CM2', 'CA', 28, '2022-01-01');", "reference_sql": "SELECT State, 'Legal Aid Clinics' AS CenterType, COUNT(*) AS NumCenters, SUM(NumCases) AS TotalCases FROM LegalAidClinics WHERE State = 'CA' UNION ALL SELECT State, 'Community Mediation Centers', COUNT(*), SUM(NumCases) FROM CommunityMediationCenters WHERE State = 'CA';", "generated_sql": "SELECT \n    'LegalAidClinics' AS CenterType,\n    COUNT(*) AS TotalCenters,\n    SUM(NumCases) AS TotalCases\nFROM \n    LegalAidClinics\nWHERE \n    State = 'CA'\n\nUNION ALL\n\nSELECT \n    'CommunityMediationCenters' AS CenterType,\n    COUNT(*) AS TotalCenters,\n    SUM(NumCases) AS TotalCases\nFROM \n    CommunityMediationCenters\nWHERE \n    State = 'CA';", "raw_model_output": "To solve this problem, we need to calculate two things separately for both Legal Aid Clinics and Community Mediation Centers:\n\n1. The count of centers (clinics or mediation centers) located in California.\n2. The sum of cases handled by these centers.\n\nWe will use a UNION ALL operation to combine the results from both tables since they have similar structures but different names. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    'LegalAidClinics' AS CenterType,\n    COUNT(*) AS TotalCenters,\n    SUM(NumCases) AS TotalCases\nFROM \n    LegalAidClinics\nWHERE \n    State = 'CA'\n\nUNION ALL\n\nSELECT \n    'CommunityMediationCenters' AS CenterType,\n    COUNT(*) AS TotalCenters,\n    SUM(NumCases) AS TotalCases\nFROM \n    CommunityMediationCenters\nWHERE \n    State = 'CA';\n\n```\n\nThis query does the following:\n\n- Selects from `LegalAidClinics` where the state is 'CA', counting the number of clinics and summing their cases.\n- Uses UNION ALL to combine this result with a similar selection from `CommunityMediationCenters`.\n- Each part of the union specifies the type of center, counts the total centers, and sums the cases for that type in California.\n\nThis will give you two rows: one for Legal Aid Clinics and another for Community Mediation Centers, each showing the count of centers and the sum of cases handled.", "latency_sec": 8.14786696434021, "total_duration_sec": 8.140895638, "load_duration_sec": 0.017756144, "tokens_prompt": 238, "prompt_eval_sec": 0.041808437, "tokens_completion": 309, "completion_eval_sec": 8.080305087, "tokens_total": 547, "tokens_per_sec": 67.13413490843544, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in column structure. The Reference SQL includes a 'State' column and uses 'NumCenters' for count, while the Generated SQL omits 'State' and uses 'TotalCenters' for count. These structural differences in output columns make them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent due to differences in column aliases and output structure. The reference query includes a 'State' column (which is redundant since both results are filtered to 'CA') and uses 'NumCenters' vs. 'TotalCenters' naming. The generated query omits the redundant 'State' column and uses more consistent naming ('TotalCenters' and 'TotalCases'). Both correctly calculate counts and sums for California centers, but the generated query is more concise and avoids unnecessary columns. The business intent (total centers and case sums per type) is fulfilled by both, but the generated version is more elegant and efficient.", "overall_assessment": "differently_correct"}}
{"example_id": 2408, "sql_complexity": "aggregation", "prompt": "What is the average number of victories for players from Japan and South Korea, partitioned by game mode?", "context": "CREATE TABLE PlayerVictories (PlayerID INT, GameMode VARCHAR(255), Victories INT, Country VARCHAR(255)); INSERT INTO PlayerVictories (PlayerID, GameMode, Victories, Country) VALUES (1, 'Battle Royale', 25, 'Japan'), (2, 'Team Deathmatch', 18, 'South Korea');", "reference_sql": "SELECT GameMode, AVG(Victories) as AvgVictories FROM PlayerVictories WHERE Country IN ('Japan', 'South Korea') GROUP BY GameMode, Country WITH ROLLUP;", "generated_sql": "SELECT \n    GameMode,\n    AVG(Victories) AS AverageVictories\nFROM \n    PlayerVictories\nWHERE \n    Country IN ('Japan', 'South Korea')\nGROUP BY \n    GameMode;", "raw_model_output": "To calculate the average number of victories for players from Japan and South Korea, partitioned by game mode, you can use the following SQL query:\n\n```sql\nSELECT \n    GameMode,\n    AVG(Victories) AS AverageVictories\nFROM \n    PlayerVictories\nWHERE \n    Country IN ('Japan', 'South Korea')\nGROUP BY \n    GameMode;\n```\n\nThis query filters the records to include only those from Japan and South Korea, then groups the results by `GameMode` and calculates the average number of victories for each game mode.", "latency_sec": 3.0017290115356445, "total_duration_sec": 2.995019944, "load_duration_sec": 0.016719022, "tokens_prompt": 164, "prompt_eval_sec": 0.022551829, "tokens_completion": 114, "completion_eval_sec": 2.955030774, "tokens_total": 278, "tokens_per_sec": 92.61329018430578, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their GROUP BY clauses. The Reference SQL groups by both GameMode and Country (with ROLLUP), while the Generated SQL only groups by GameMode. This affects the aggregation scope: the Reference calculates averages per GameMode-Country combination (and adds summary rows via ROLLUP), whereas the Generated SQL aggregates all countries together for each GameMode. The ROLLUP modifier in the Reference also introduces additional summary rows not present in the Generated SQL.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query groups by both GameMode and Country with ROLLUP, which introduces subtotals and a grand total not requested in the original question. This creates additional rows (e.g., per-country averages and a 'Total' row) that deviate from the requirement to partition only by GameMode. The generated query correctly groups by GameMode alone, producing one average per game mode for players from Japan and South Korea. While both queries are syntactically valid, the generated version aligns more closely with the business intent of partitioning by game mode without country-level aggregation or ROLLUP totals.", "overall_assessment": "correct"}}
{"example_id": 2729, "sql_complexity": "subqueries", "prompt": "Find the total number of trips made by shared autonomous vehicles in Seattle", "context": "CREATE TABLE shared_vehicles (id INT, vehicle_type VARCHAR(20), is_autonomous BOOLEAN, trip_count INT); INSERT INTO shared_vehicles (id, vehicle_type, is_autonomous, trip_count) VALUES (1, 'ebike', false, 1200), (2, 'escooter', false, 800), (3, 'car', true, 1500); CREATE TABLE city_data (city VARCHAR(20), has_autonomous_vehicles BOOLEAN); INSERT INTO city_data (city, has_autonomous_vehicles) VALUES ('Seattle', true), ('Denver', false), ('Portland', true);", "reference_sql": "SELECT SUM(trip_count) FROM shared_vehicles WHERE is_autonomous = true AND vehicle_type != 'ebike' AND vehicle_type != 'escooter' AND city IN (SELECT city FROM city_data WHERE has_autonomous_vehicles = true AND city = 'Seattle');", "generated_sql": "SELECT SUM(sv.trip_count) AS total_autonomous_trips_in_seattle\nFROM shared_vehicles sv\nJOIN city_data cd ON cd.city = 'Seattle'\nWHERE sv.is_autonomous = TRUE AND cd.has_autonomous_vehicles = TRUE;", "raw_model_output": "To find the total number of trips made by shared autonomous vehicles in Seattle, we need to join the `shared_vehicles` and `city_data` tables based on the condition that the vehicle is autonomous and the city has autonomous vehicles. Here's how you can write the SQL query:\n\n```sql\nSELECT SUM(sv.trip_count) AS total_autonomous_trips_in_seattle\nFROM shared_vehicles sv\nJOIN city_data cd ON cd.city = 'Seattle'\nWHERE sv.is_autonomous = TRUE AND cd.has_autonomous_vehicles = TRUE;\n```\n\nThis query performs the following steps:\n- Joins `shared_vehicles` and `city_data` tables.\n- Filters for vehicles that are autonomous (`sv.is_autonomous = TRUE`) and cities that have autonomous vehicles (`cd.has_autonomous_vehicles = TRUE`).\n- Specifically targets the city 'Seattle'.\n- Sums up the trip counts of these filtered records to get the total number of trips made by shared autonomous vehicles in Seattle.", "latency_sec": 5.335922002792358, "total_duration_sec": 5.331519273, "load_duration_sec": 0.021942312, "tokens_prompt": 212, "prompt_eval_sec": 0.033770859, "tokens_completion": 201, "completion_eval_sec": 5.274560627, "tokens_total": 413, "tokens_per_sec": 77.39993196749721, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes explicit filters for vehicle_type (excluding 'ebike' and 'escooter') and uses a subquery to filter cities with autonomous vehicles. The Generated SQL uses a JOIN on city = 'Seattle' and lacks the vehicle_type restrictions, potentially including ebikes/escooters. The Generated SQL also implicitly assumes Seattle has autonomous vehicles via the JOIN condition, while the Reference SQL explicitly checks the city_data table. These differences in filtering criteria make them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL contains a critical technical error: it references a non-existent 'city' column in the shared_vehicles table, making it invalid. The Generated SQL is syntactically correct and logically sound. It properly joins the shared_vehicles table with city_data on a fixed 'Seattle' condition (though the join condition is unconventional, it effectively filters the city_data to Seattle). While neither query can perfectly answer the question due to the lack of a city column in shared_vehicles, the Generated SQL better fulfills the business intent by focusing on autonomous vehicles and leveraging the city_data table's validation. The Reference SQL's invalidity makes it incorrect, while the Generated SQL, though imperfect, is technically superior.", "overall_assessment": "differently_correct"}}
{"example_id": 2952, "sql_complexity": "aggregation", "prompt": "Show the total budget allocated for each program category in 2023.", "context": "CREATE TABLE Budget (id INT, category TEXT, year INT, allocated_amount INT); INSERT INTO Budget (id, category, year, allocated_amount) VALUES (1, 'Education', 2023, 30000); INSERT INTO Budget (id, category, year, allocated_amount) VALUES (2, 'Healthcare', 2023, 50000);", "reference_sql": "SELECT category, SUM(allocated_amount) FROM Budget WHERE year = 2023 GROUP BY category;", "generated_sql": "SELECT category, SUM(allocated_amount) AS total_allocated\nFROM Budget\nWHERE year = 2023\nGROUP BY category;", "raw_model_output": "To find the total budget allocated for each program category in the year 2023 from the `Budget` table, you can use the following SQL query:\n\n```sql\nSELECT category, SUM(allocated_amount) AS total_allocated\nFROM Budget\nWHERE year = 2023\nGROUP BY category;\n```\n\nThis query performs the following operations:\n- Filters the rows to include only those where the `year` is 2023.\n- Groups the results by the `category`.\n- Calculates the sum of `allocated_amount` for each group (i.e., each category).\n- Returns the `category` and its corresponding total allocated amount as `total_allocated`.", "latency_sec": 3.5473079681396484, "total_duration_sec": 3.541329588, "load_duration_sec": 0.010516567, "tokens_prompt": 160, "prompt_eval_sec": 0.023748098, "tokens_completion": 133, "completion_eval_sec": 3.506328157, "tokens_total": 293, "tokens_per_sec": 82.59784677045141, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries select the same columns (category and summed allocated_amount) from the Budget table where year is 2023, grouped by category. The only difference is the alias name (total_allocated) in the generated query, which doesn't affect the semantic meaning of the result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the total allocated budget per category for 2023 using SUM and GROUP BY. The reference query is technically correct but lacks an explicit alias for the aggregated column. The generated query adds clarity with the AS keyword (total_allocated), which improves readability without altering functionality. While both fulfill the business intent, the generated version is more elegant and practical for downstream use cases like reporting or API responses where column names matter.", "overall_assessment": "differently_correct"}}
{"example_id": 4328, "sql_complexity": "aggregation", "prompt": "What is the average cargo handling time in hours for each port?", "context": "CREATE TABLE cargo_handling (id INT, port_id INT, time_in_hours DECIMAL(5,2)); INSERT INTO cargo_handling (id, port_id, time_in_hours) VALUES (1, 1, 20.5), (2, 1, 22.3), (3, 2, 18.7);", "reference_sql": "SELECT port_id, AVG(time_in_hours) FROM cargo_handling GROUP BY port_id;", "generated_sql": "SELECT \n    port_id,\n    AVG(time_in_hours) AS average_handling_time\nFROM \n    cargo_handling\nGROUP BY \n    port_id;", "raw_model_output": "To calculate the average cargo handling time in hours for each port, you can use the `AVG` aggregate function along with a `GROUP BY` clause to group the results by `port_id`. Here's the SQL statement that accomplishes this:\n\n```sql\nSELECT \n    port_id,\n    AVG(time_in_hours) AS average_handling_time\nFROM \n    cargo_handling\nGROUP BY \n    port_id;\n```\n\nThis query will return each unique `port_id` along with its corresponding average handling time in hours.", "latency_sec": 2.7833261489868164, "total_duration_sec": 2.778232113, "load_duration_sec": 0.01988851, "tokens_prompt": 155, "prompt_eval_sec": 0.022127728, "tokens_completion": 106, "completion_eval_sec": 2.735308008, "tokens_total": 261, "tokens_per_sec": 93.77269713612577, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries group by port_id and calculate the average time_in_hours. The only difference is the column alias (AVG(time_in_hours) vs. AVG(time_in_hours) AS average_handling_time), which does not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the average cargo handling time per port using GROUP BY and AVG(). The generated query improves upon the reference by adding an explicit alias (average_handling_time) for the calculated column, which enhances readability and clearly communicates the meaning of the aggregated value. While the reference query is technically valid, the generated version is more elegant and semantically explicit without altering the computational logic. Both satisfy the business requirement of determining average handling times per port.", "overall_assessment": "correct"}}
{"example_id": 4915, "sql_complexity": "window functions", "prompt": "Calculate the percentage of total Europium production for each country.", "context": "CREATE TABLE europium_production (country VARCHAR(50), quantity INT);", "reference_sql": "SELECT country, quantity * 100.0 / SUM(quantity) OVER (PARTITION BY NULL) AS percentage FROM europium_production;", "generated_sql": "SELECT \n    country,\n    (quantity / (SELECT SUM(quantity) FROM europium_production)) * 100 AS production_percentage\nFROM \n    europium_production;", "raw_model_output": "To calculate the percentage of total Europium production for each country, you can use a subquery to first determine the total production across all countries. Then, compute the percentage for each country by dividing its production quantity by the total and multiplying by 100. Here's how you can write this SQL query:\n\n```sql\nSELECT \n    country,\n    (quantity / (SELECT SUM(quantity) FROM europium_production)) * 100 AS production_percentage\nFROM \n    europium_production;\n```\n\nThis query does the following:\n- Selects each `country` and its corresponding `quantity`.\n- Uses a subquery to calculate the total quantity of Europium produced across all countries.\n- Computes the percentage by dividing each country's quantity by the total quantity and multiplying by 100 to convert it into a percentage.", "latency_sec": 4.19089674949646, "total_duration_sec": 4.184907848, "load_duration_sec": 0.01968458, "tokens_prompt": 98, "prompt_eval_sec": 0.012621273, "tokens_completion": 163, "completion_eval_sec": 4.151798871, "tokens_total": 261, "tokens_per_sec": 62.277840662946275, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the percentage of each country's production relative to the total. The reference uses a window function SUM(quantity) OVER (PARTITION BY NULL) which computes the total across all rows, while the generated query uses a subquery (SELECT SUM(quantity)...) to get the same total. Mathematically, quantity * 100.0 / total and (quantity / total) * 100 produce identical results. Both handle division by zero similarly (if applicable).", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries correctly calculate the percentage of total Europium production per country. The reference query uses a window function (SUM(quantity) OVER (PARTITION BY NULL)) which is more efficient and elegant for this purpose, as it avoids a correlated subquery. The generated query uses a scalar subquery to calculate the total, which also works but may be less efficient in some database systems. Both handle edge cases (e.g., zero total production) similarly, though neither explicitly addresses division by zero. The reference query's window function approach is more idiomatic for this type of calculation.", "overall_assessment": "correct"}}
{"example_id": 5030, "sql_complexity": "subqueries", "prompt": "What is the success rate of diverse-led startups (at least 1 female or underrepresented racial or ethnic group executive) in the past 3 years?", "context": "CREATE TABLE DiverseStartups(id INT, name TEXT, country TEXT, year INT, success BOOLEAN);   INSERT INTO DiverseStartups VALUES (1, 'FemTech', 'USA', 2020, true), (2, 'GreenCity', 'Canada', 2019, false), (3, 'AI-Health', 'UK', 2021, true), (4, 'SolarEnergy', 'USA', 2020, false), (5, 'DataAnalytics', 'Germany', 2019, true), (6, 'SmartGrid', 'USA', 2021, true), (7, 'CloudServices', 'India', 2020, false), (8, 'RenewableEnergy', 'USA', 2019, true);", "reference_sql": "SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FROM DiverseStartups WHERE year >= YEAR(CURRENT_DATE) - 3) AS success_rate FROM DiverseStartups WHERE year >= YEAR(CURRENT_DATE) - 3 AND success = true;", "generated_sql": "SELECT \n    (COUNT(CASE WHEN success = true THEN 1 END) * 100.0 / COUNT(*)) AS success_rate\nFROM \n    DiverseStartups\nWHERE \n    year BETWEEN 2020 AND 2022;", "raw_model_output": "To calculate the success rate of diverse-led startups over the past three years from the current year (assuming it's 2023), we need to follow these steps:\n\n1. Identify the relevant time frame: The past three years would be 2020, 2021, and 2022.\n2. Filter the records for startups founded in those years.\n3. Calculate the number of successful startups within this filtered set.\n4. Determine the total number of startups from this filtered set.\n5. Compute the success rate as the ratio of successful startups to the total number of startups.\n\nHere's how you can translate these steps into an SQL query:\n\n```sql\nSELECT \n    (COUNT(CASE WHEN success = true THEN 1 END) * 100.0 / COUNT(*)) AS success_rate\nFROM \n    DiverseStartups\nWHERE \n    year BETWEEN 2020 AND 2022;\n```\n\n### Explanation:\n- `WHERE year BETWEEN 2020 AND 2022`: Filters the startups to include only those founded in the years 2020, 2021, and 2022.\n- `COUNT(CASE WHEN success = true THEN 1 END)`: Counts the number of successful startups within this filtered set.\n- `COUNT(*)`: Counts the total number of startups within this filtered set.\n- `(COUNT(...) * 100.0 / COUNT(*)) AS success_rate`: Calculates the percentage of successful startups, converting it to a floating-point division for accuracy.\n\nThis query will give you the success rate as a percentage of diverse-led startups founded in the past three years from 2023.", "latency_sec": 8.55236005783081, "total_duration_sec": 8.547880132, "load_duration_sec": 0.020547202, "tokens_prompt": 264, "prompt_eval_sec": 0.043976036, "tokens_completion": 328, "completion_eval_sec": 8.482037921, "tokens_total": 592, "tokens_per_sec": 69.2206590925678, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their date range logic. The Reference SQL uses dynamic calculation (YEAR(CURRENT_DATE) - 3) to include startups from the last 3 years relative to the current date, while the Generated SQL uses a fixed range (2020-2022). This makes them non-equivalent when the current year is not 2023. For example, if the current year is 2022, the Reference SQL would include 2019-2022, whereas the Generated SQL only includes 2020-2022.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The reference query dynamically calculates the past 3 years using YEAR(CURRENT_DATE) - 3, ensuring accuracy regardless of the current date. The generated query uses a fixed range (2020-2022), which would only align with the past 3 years if the current year is 2023. In the sample data, the reference query includes 2019-2021 (past 3 years if current year is 2022), while the generated query excludes 2019. Both calculate success rate correctly, but the reference query better handles temporal context. The generated query's fixed range could fail in different timeframes, making it less robust for business intent.", "overall_assessment": "correct"}}
{"example_id": 4626, "sql_complexity": "aggregation", "prompt": "What was the maximum number of training hours for farmers in each country in 2020?", "context": "CREATE TABLE training (id INT, country_id INT, farmer_id INT, hours INT, date DATE);", "reference_sql": "SELECT country_id, MAX(hours) FROM training WHERE YEAR(date) = 2020 GROUP BY country_id;", "generated_sql": "SELECT \n    country_id,\n    MAX(hours) AS max_training_hours\nFROM \n    training\nWHERE \n    EXTRACT(YEAR FROM date) = 2020\nGROUP BY \n    country_id;", "raw_model_output": "To find the maximum number of training hours for farmers in each country in 2020, we need to filter the records by the year 2020 and then group them by `country_id` to calculate the maximum training hours. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    country_id,\n    MAX(hours) AS max_training_hours\nFROM \n    training\nWHERE \n    EXTRACT(YEAR FROM date) = 2020\nGROUP BY \n    country_id;\n```\n\nThis query does the following:\n- Filters records to include only those from the year 2020 using `EXTRACT(YEAR FROM date) = 2020`.\n- Groups the results by `country_id` to calculate the maximum training hours for each country.\n- Uses `MAX(hours)` to find the maximum number of training hours within each group.", "latency_sec": 4.47748875617981, "total_duration_sec": 4.470840924, "load_duration_sec": 0.014671375, "tokens_prompt": 111, "prompt_eval_sec": 0.027587946, "tokens_completion": 174, "completion_eval_sec": 4.42806322, "tokens_total": 285, "tokens_per_sec": 63.65175113095355, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select the same columns (country_id and MAX(hours)), apply the same filter condition (year 2020 extraction from date), and group by country_id. The difference is purely syntactic: the generated query adds an explicit alias for the MAX(hours) column, which does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the maximum training hours per country for 2020. The reference query uses YEAR(date) = 2020 while the generated query uses EXTRACT(YEAR FROM date) = 2020. These are functionally equivalent for filtering records from 2020, though EXTRACT is more standard SQL. The generated query adds an explicit alias (max_training_hours) which improves readability and clarity compared to the reference's implicit column name. Both satisfy the business requirement, but the generated version is more explicit and elegant.", "overall_assessment": "correct"}}
{"example_id": 2703, "sql_complexity": "set operations", "prompt": "Identify the species unique to 'MarineResearchAreaA' and 'MarineResearchAreaB'", "context": "CREATE TABLE ResearchAreaSpecies (area VARCHAR(255), species VARCHAR(255)); INSERT INTO ResearchAreaSpecies (area, species) VALUES ('MarineResearchAreaA', 'Coral'), ('MarineResearchAreaA', 'Starfish'), ('MarineResearchAreaB', 'Jellyfish');", "reference_sql": "(SELECT species FROM ResearchAreaSpecies WHERE area = 'MarineResearchAreaA' EXCEPT SELECT species FROM ResearchAreaSpecies WHERE area = 'MarineResearchAreaB') UNION (SELECT species FROM ResearchAreaSpecies WHERE area = 'MarineResearchAreaB' EXCEPT SELECT species FROM ResearchAreaSpecies WHERE area = 'MarineResearchAreaA');", "generated_sql": "SELECT \n    species,\n    area\nFROM \n    ResearchAreaSpecies\nGROUP BY \n    species, area\nHAVING \n    COUNT(DISTINCT area) = 1;", "raw_model_output": "To identify the species that are unique to each of the specified research areas, we can use a combination of `GROUP BY` and `HAVING` clauses. The goal is to find species that appear in only one of the two areas.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    species,\n    area\nFROM \n    ResearchAreaSpecies\nGROUP BY \n    species, area\nHAVING \n    COUNT(DISTINCT area) = 1;\n```\n\n### Explanation:\n- **`GROUP BY species, area`:** This groups the results by both `species` and `area`, allowing us to count occurrences of each species within each specific area.\n- **`HAVING COUNT(DISTINCT area) = 1`:** This condition filters out any species that appear in more than one area. It ensures that only those species which are unique to a single area (either 'MarineResearchAreaA' or 'MarineResearchAreaB') are selected.\n\nThis query will return the species along with their respective areas where they are uniquely found.", "latency_sec": 5.6039769649505615, "total_duration_sec": 5.598954487, "load_duration_sec": 0.01907977, "tokens_prompt": 154, "prompt_eval_sec": 0.022982346, "tokens_completion": 216, "completion_eval_sec": 5.554652196, "tokens_total": 370, "tokens_per_sec": 66.0245397713308, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns only species names (as a symmetric difference between areas), while the Generated SQL returns both species and their associated areas. The result sets have different structures (columns) and thus are not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The Reference SQL correctly identifies species unique to each area using EXCEPT and UNION, which directly addresses the requirement to find species present in one area but not the other. The Generated SQL uses GROUP BY and HAVING to find species in exactly one area, which also fulfills the business intent. However, the Generated SQL includes the 'area' column in its output, while the original question only asks for species names. This structural difference makes them technically non-equivalent. The Reference SQL is more elegant and directly aligns with the logical requirement of comparing two sets, while the Generated SQL achieves the same result through a different approach but with a less precise output structure.", "overall_assessment": "differently_correct"}}
{"example_id": 200, "sql_complexity": "window functions", "prompt": "List the top three categories of workforce development programs with the highest budget increases.", "context": "CREATE TABLE programs (program_id INT, program_name VARCHAR(50), budget DECIMAL(10, 2), category VARCHAR(50), budget_date DATE);", "reference_sql": "SELECT category, SUM(budget - LAG(budget) OVER (PARTITION BY category ORDER BY budget_date)) as total_budget_increase FROM programs GROUP BY category ORDER BY total_budget_increase DESC LIMIT 3;", "generated_sql": "WITH BudgetByYear AS (\n    SELECT \n        category,\n        EXTRACT(YEAR FROM budget_date) AS year,\n        SUM(budget) AS total_budget\n    FROM \n        programs\n    GROUP BY \n        category, \n        EXTRACT(YEAR FROM budget_date)\n),\nBudgetIncrease AS (\n    SELECT \n        current.category,\n        (current.total_budget - previous.total_budget) AS budget_increase\n    FROM \n        BudgetByYear current\n    JOIN \n        BudgetByYear previous ON current.category = previous.category\n    WHERE \n        current.year = previous.year + 1\n)\nSELECT \n    category, \n    SUM(budget_increase) AS total_budget_increase\nFROM \n    BudgetIncrease\nGROUP BY \n    category\nORDER BY \n    total_budget_increase DESC\nLIMIT 3;", "raw_model_output": "To solve this problem, we need to calculate the budget increase for each category from one year to the next and then find the top three categories with the highest increases. Here's how you can achieve that using SQL:\n\n```sql\nWITH BudgetByYear AS (\n    SELECT \n        category,\n        EXTRACT(YEAR FROM budget_date) AS year,\n        SUM(budget) AS total_budget\n    FROM \n        programs\n    GROUP BY \n        category, \n        EXTRACT(YEAR FROM budget_date)\n),\nBudgetIncrease AS (\n    SELECT \n        current.category,\n        (current.total_budget - previous.total_budget) AS budget_increase\n    FROM \n        BudgetByYear current\n    JOIN \n        BudgetByYear previous ON current.category = previous.category\n    WHERE \n        current.year = previous.year + 1\n)\nSELECT \n    category, \n    SUM(budget_increase) AS total_budget_increase\nFROM \n    BudgetIncrease\nGROUP BY \n    category\nORDER BY \n    total_budget_increase DESC\nLIMIT 3;\n```\n\n### Explanation:\n\n1. **BudgetByYear CTE**: This common table expression calculates the total budget for each category per year.\n\n2. **BudgetIncrease CTE**: This joins `BudgetByYear` with itself to compare budgets between consecutive years (current.year = previous.year + 1) and calculates the increase in budget for each category from one year to the next.\n\n3. **Final SELECT Statement**: It sums up all the yearly increases for each category, orders them by the total increase in descending order, and limits the result to the top three categories with the highest budget increases.", "latency_sec": 8.49985671043396, "total_duration_sec": 8.493319504, "load_duration_sec": 0.011881684, "tokens_prompt": 119, "prompt_eval_sec": 0.015130482, "tokens_completion": 329, "completion_eval_sec": 8.465415422, "tokens_total": 448, "tokens_per_sec": 52.70677086239109, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in how they calculate budget increases. The reference query uses LAG() on individual rows ordered by budget_date, while the generated query aggregates budgets by year first and then calculates year-over-year differences. The generated query only considers consecutive years (current.year = previous.year + 1), whereas the reference query could capture non-consecutive date differences. Additionally, the reference query sums differences across all rows, while the generated query aggregates by year before calculating increases.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in their approach to calculating budget increases. The Reference SQL uses a window function to compute differences between consecutive rows (regardless of date intervals), while the Generated SQL explicitly calculates year-over-year changes by grouping by year first. The Generated SQL better addresses the business intent by ensuring annual comparisons, which is more aligned with typical budget analysis. The Reference SQL may produce incorrect results if there are multiple entries per year or non-annual date intervals. Both queries correctly aggregate by category and prioritize top increases, but the Generated SQL's structured approach is more precise for the intended analysis.", "overall_assessment": "differently_correct"}}
{"example_id": 5131, "sql_complexity": "basic SQL", "prompt": "How many wells were drilled in the Eagle Ford Shale and Bakken Formation?", "context": "CREATE TABLE wells (id INT, region VARCHAR(255), well_type VARCHAR(255), num_drilled INT); INSERT INTO wells (id, region, well_type, num_drilled) VALUES (1, 'Eagle Ford Shale', 'Oil', 2000), (2, 'Eagle Ford Shale', 'Gas', 1500), (3, 'Bakken Formation', 'Oil', 1000), (4, 'Bakken Formation', 'Gas', 1200);", "reference_sql": "SELECT SUM(num_drilled) as total_wells FROM wells WHERE region IN ('Eagle Ford Shale', 'Bakken Formation');", "generated_sql": "SELECT SUM(num_drilled) AS total_wells_drilled\nFROM wells;", "raw_model_output": "To find out how many wells were drilled in both the Eagle Ford Shale and Bakken Formation regions combined, you can use a simple `SELECT` statement with an aggregate function to sum up the number of wells drilled. Here's the SQL query:\n\n```sql\nSELECT SUM(num_drilled) AS total_wells_drilled\nFROM wells;\n```\n\nThis query calculates the total number of wells drilled across all specified regions by summing up the values in the `num_drilled` column for each row in the `wells` table.", "latency_sec": 2.8871002197265625, "total_duration_sec": 2.882254784, "load_duration_sec": 0.012593075, "tokens_prompt": 193, "prompt_eval_sec": 0.031159824, "tokens_completion": 110, "completion_eval_sec": 2.837669682, "tokens_total": 303, "tokens_per_sec": 104.94959542093663, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters rows to only include wells in 'Eagle Ford Shale' and 'Bakken Formation' regions, while the Generated SQL sums all rows in the table without any region restrictions. Although the sample data contains only these two regions, the queries are not semantically equivalent in general because the Generated SQL would include additional regions if they existed in the table.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": false, "superiority": "reference", "explanation": "The queries are technically equivalent in this specific context because the provided data only contains wells from 'Eagle Ford Shale' and 'Bakken Formation'. However, the generated query does not explicitly filter for these regions, making it semantically less precise. While both return the same result here, the reference query directly addresses the business intent by explicitly restricting to the specified formations. The generated query would fail if additional regions existed in the table, making it less robust for general use. The reference query better fulfills the intent by explicitly aligning with the question's requirements.", "overall_assessment": "differently_correct"}}
{"example_id": 1160, "sql_complexity": "subqueries", "prompt": "What is the total revenue generated from ads on Instagram in March 2021, for users in the 'brand' category who have posted more than 10 times?", "context": "CREATE TABLE ads (ad_id INT, user_id INT, platform VARCHAR(255), ad_revenue DECIMAL(10,2), post_count INT); INSERT INTO ads (ad_id, user_id, platform, ad_revenue, post_count) VALUES (1, 1, 'Instagram', 150.50, 12), (2, 2, 'Twitter', 80.00, 15), (3, 3, 'Instagram', 120.75, 8);", "reference_sql": "SELECT SUM(ad_revenue) FROM ads WHERE platform = 'Instagram' AND MONTH(ad_date) = 3 AND YEAR(ad_date) = 2021 AND user_id IN (SELECT user_id FROM users WHERE category = 'brand' AND post_count > 10);", "generated_sql": "SELECT SUM(ad_revenue) AS total_instagram_revenue\nFROM ads\nWHERE platform = 'Instagram'\nAND post_count > 10;", "raw_model_output": "To answer this question accurately with an executable SQL statement, we need to consider several factors based on the provided schema and the requirements of the question. However, there are some limitations due to missing information:\n\n1. **Date Information**: The schema does not include any date-related columns that would allow us to filter records specifically for March 2021.\n2. **User Category**: There is no column indicating whether a user belongs to the 'brand' category.\n\nGiven these constraints, we can only address parts of the question that are supported by the existing schema:\n\n- We can calculate the total revenue generated from ads on Instagram.\n- We can filter for users who have posted more than 10 times.\n\nHere's how you could write an SQL statement based on the available data:\n\n```sql\nSELECT SUM(ad_revenue) AS total_instagram_revenue\nFROM ads\nWHERE platform = 'Instagram'\nAND post_count > 10;\n```\n\nThis query calculates the total ad revenue from Instagram for users who have posted more than 10 times. However, it does not filter by date or user category due to missing schema information. If additional columns were available in the database schema (e.g., a `date` column and a `user_category` column), we could modify the query accordingly.", "latency_sec": 6.744164228439331, "total_duration_sec": 6.737539168, "load_duration_sec": 0.018962686, "tokens_prompt": 207, "prompt_eval_sec": 0.034410184, "tokens_completion": 259, "completion_eval_sec": 6.683096007, "tokens_total": 466, "tokens_per_sec": 69.09677525866496, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL includes additional conditions: filtering by ad_date (month/year), and restricting user_id to those in the 'users' table with category 'brand' and post_count > 10. The Generated SQL omits these conditions, instead using ads.post_count > 10 directly. The date filtering and user category subquery in the Reference SQL would significantly affect the result set compared to the Generated SQL.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL attempts to address all requirements (Instagram platform, March 2021 date, brand category, and post count >10) but references a non-existent 'users' table. The Generated SQL omits critical filters (date, category) and incorrectly uses 'post_count' from the ads table instead of a user category. While both queries have flaws, the Reference SQL at least includes the date filter and acknowledges the need for user categorization, making it technically superior despite the schema inconsistency.", "overall_assessment": "differently_correct"}}
{"example_id": 4708, "sql_complexity": "subqueries", "prompt": "What is the maximum number of high-level threats reported by a single agency in a month?", "context": "CREATE TABLE Threat_Intelligence (Threat_ID INT, Threat_Type VARCHAR(50), Threat_Level VARCHAR(50), Reported_Date DATE, Reporting_Agency VARCHAR(50)); CREATE VIEW High_Level_Threats AS SELECT Threat_Type, Threat_Level, Reported_Date FROM Threat_Intelligence WHERE Threat_Level = 'High';", "reference_sql": "SELECT Reporting_Agency, MAX(Number_of_High_Level_Threats) as Max_High_Level_Threats_in_a_Month FROM (SELECT Reporting_Agency, TO_CHAR(Reported_Date, 'YYYY-MM') as Month, COUNT(*) as Number_of_High_Level_Threats FROM High_Level_Threats GROUP BY Reporting_Agency, Month) GROUP BY Reporting_Agency;", "generated_sql": "SELECT MAX(Threat_Count) AS Max_High_Level_Threats_In_Month\nFROM (\n    SELECT Reporting_Agency, \n           YEAR(Reported_Date) AS Year, \n           MONTH(Reported_Date) AS Month, \n           COUNT(*) AS Threat_Count\n    FROM Threat_Intelligence\n    WHERE Threat_Level = 'High'\n    GROUP BY Reporting_Agency, YEAR(Reported_Date), MONTH(Reported_Date)\n) AS Monthly_Threats;", "raw_model_output": "To find the maximum number of high-level threats reported by a single agency in a month, we need to count the number of high-level threats for each agency and each month. Then, we will determine the maximum count from these results.\n\nHere's the SQL statement that accomplishes this:\n\n```sql\nSELECT MAX(Threat_Count) AS Max_High_Level_Threats_In_Month\nFROM (\n    SELECT Reporting_Agency, \n           YEAR(Reported_Date) AS Year, \n           MONTH(Reported_Date) AS Month, \n           COUNT(*) AS Threat_Count\n    FROM Threat_Intelligence\n    WHERE Threat_Level = 'High'\n    GROUP BY Reporting_Agency, YEAR(Reported_Date), MONTH(Reported_Date)\n) AS Monthly_Threats;\n```\n\n### Explanation:\n- We filter the `Threat_Intelligence` table to include only rows where `Threat_Level` is `'High'`.\n- We group these filtered results by `Reporting_Agency`, year, and month of the `Reported_Date`.\n- For each group, we count the number of high-level threats (`COUNT(*) AS Threat_Count`).\n- Finally, from these grouped counts, we select the maximum value using `MAX(Threat_Count)`. This gives us the highest number of high-level threats reported by any single agency in a month.", "latency_sec": 7.12582802772522, "total_duration_sec": 7.121354919, "load_duration_sec": 0.019214199, "tokens_prompt": 153, "prompt_eval_sec": 0.020821112, "tokens_completion": 276, "completion_eval_sec": 7.080569918, "tokens_total": 429, "tokens_per_sec": 60.2035297976381, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL groups by Reporting_Agency and calculates the maximum monthly count per agency, while the Generated SQL lacks grouping by Reporting_Agency in the outer query, resulting in a single maximum value across all agencies. Additionally, the Generated SQL uses YEAR/MONTH functions instead of TO_CHAR('YYYY-MM'), which may affect grouping precision.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL groups by Reporting_Agency and calculates MAX(Number_of_High_Level_Threats) per agency, returning multiple rows with each agency's maximum monthly count. This does not answer the original question, which seeks the single maximum value across all agencies and months. The Generated SQL correctly aggregates all monthly counts (across agencies) in a subquery and then applies MAX() to find the absolute maximum, aligning with the business intent. The Reference also has a logical flaw: it uses a view (High_Level_Threats) that excludes Threat_Type, which is unnecessary for the question. The Generated SQL is more efficient, avoids redundant abstractions, and directly addresses the requirement.", "overall_assessment": "incorrect"}}
{"example_id": 5608, "sql_complexity": "set operations", "prompt": "List the suppliers that provide materials for both product A and product C.", "context": "CREATE TABLE products (product_id INT, product_name TEXT); CREATE TABLE materials (material_id INT, material_name TEXT, product_id INT, supplier_id INT); INSERT INTO products (product_id, product_name) VALUES (1, 'Product A'), (2, 'Product B'), (3, 'Product C'); INSERT INTO materials (material_id, material_name, product_id, supplier_id) VALUES (1, 'Material 1', 1, 101), (2, 'Material 2', 1, 102), (3, 'Material 3', 2, 103), (4, 'Material 4', 3, 101), (5, 'Material 5', 3, 102);", "reference_sql": "SELECT supplier_id FROM materials WHERE product_id = 1 INTERSECT SELECT supplier_id FROM materials WHERE product_id = 3;", "generated_sql": "SELECT DISTINCT m1.supplier_id\nFROM materials m1\nJOIN materials m2 ON m1.supplier_id = m2.supplier_id\nWHERE m1.product_id = (SELECT product_id FROM products WHERE product_name = 'Product A')\n  AND m2.product_id = (SELECT product_id FROM products WHERE product_name = 'Product C');", "raw_model_output": "To solve this problem, we need to identify suppliers who provide materials for both \"Product A\" and \"Product C\". We can achieve this by performing a self-join on the `materials` table based on the `supplier_id`, ensuring that each supplier provides materials for both products. Here's how you can construct the SQL query:\n\n```sql\nSELECT DISTINCT m1.supplier_id\nFROM materials m1\nJOIN materials m2 ON m1.supplier_id = m2.supplier_id\nWHERE m1.product_id = (SELECT product_id FROM products WHERE product_name = 'Product A')\n  AND m2.product_id = (SELECT product_id FROM products WHERE product_name = 'Product C');\n```\n\n### Explanation:\n\n1. **Subqueries for Product IDs**: \n   - We use subqueries to find the `product_id` for \"Product A\" and \"Product C\". This ensures that we are working with the correct identifiers in the `materials` table.\n\n2. **Self-Join on Supplier ID**:\n   - We perform a self-join on the `materials` table using `m1.supplier_id = m2.supplier_id`. This join allows us to compare rows within the same table where the supplier is common.\n\n3. **Filtering Conditions**:\n   - The first condition in the WHERE clause ensures that `m1.product_id` corresponds to \"Product A\".\n   - The second condition ensures that `m2.product_id` corresponds to \"Product C\".\n\n4. **Distinct Supplier IDs**:\n   - We use `SELECT DISTINCT m1.supplier_id` to ensure that each supplier is listed only once, even if they provide multiple materials for the products.\n\nThis query will return a list of unique supplier IDs that supply materials for both \"Product A\" and \"Product C\".", "latency_sec": 9.424933195114136, "total_duration_sec": 9.418360236, "load_duration_sec": 0.01103522, "tokens_prompt": 237, "prompt_eval_sec": 0.039040748, "tokens_completion": 368, "completion_eval_sec": 9.367615847, "tokens_total": 605, "tokens_per_sec": 64.19143642457122, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve supplier_ids that are common between product_id 1 (Product A) and product_id 3 (Product C). The Reference SQL uses INTERSECT to find the intersection of supplier_ids from the two product_id conditions, while the Generated SQL uses a JOIN on supplier_id with WHERE clauses to achieve the same result. Both ensure distinct supplier_ids, producing identical output.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries correctly identify suppliers providing materials for both Product A and Product C. The reference query uses INTERSECT, which is semantically precise for finding common supplier_ids between two sets. The generated query achieves the same result through a self-join with DISTINCT, which is logically equivalent but less efficient. While both are technically correct, the reference query is more elegant and optimized for this specific use case.", "overall_assessment": "correct"}}
{"example_id": 1506, "sql_complexity": "basic SQL", "prompt": "How many habitats are in the 'animal_habitats' table?", "context": "CREATE TABLE animal_habitats (id INT PRIMARY KEY, habitat_name VARCHAR, num_animals INT);", "reference_sql": "SELECT COUNT(*) FROM animal_habitats;", "generated_sql": "SELECT COUNT(*) AS total_habitats FROM animal_habitats;", "raw_model_output": "To determine how many habitats are listed in the `animal_habitats` table, you need to count the number of rows present. Each row represents a habitat. The SQL statement for this query is:\n\n```sql\nSELECT COUNT(*) AS total_habitats FROM animal_habitats;\n```\n\nThis statement uses the `COUNT(*)` function to count all rows in the `animal_habitats` table, and it aliases the result as `total_habitats`.", "latency_sec": 2.3710720539093018, "total_duration_sec": 2.36477711, "load_duration_sec": 0.0173403, "tokens_prompt": 107, "prompt_eval_sec": 0.013703087, "tokens_completion": 96, "completion_eval_sec": 2.332972163, "tokens_total": 203, "tokens_per_sec": 85.61528092969762, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries return the same numeric result (total row count from the animal_habitats table). The generated query adds an alias 'total_habitats' to the COUNT(*) column, but this does not change the semantic value of the result. The core operation of counting all rows remains identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly count all rows in the 'animal_habitats' table. The reference query uses the minimal syntax (COUNT(*)) while the generated query adds an alias (total_habitats) for clarity. Semantically, they produce identical results. The business intent of counting habitats is fulfilled equally by both. The generated query's alias improves readability but isn't required for correctness. Neither query is more efficient than the other.", "overall_assessment": "correct"}}
{"example_id": 3117, "sql_complexity": "aggregation", "prompt": "What is the percentage of the population that has access to clean water in each continent?", "context": "CREATE TABLE water_data (id INT, country VARCHAR(50), continent CHAR(2), access_to_clean_water BOOLEAN); INSERT INTO water_data VALUES (1, 'Canada', 'NA', true), (2, 'Mexico', 'NA', false), (3, 'Brazil', 'SA', true), (4, 'Russia', 'EU', true);", "reference_sql": "SELECT continent, COUNT(*) FILTER (WHERE access_to_clean_water) * 100.0 / COUNT(*) AS percentage FROM water_data GROUP BY continent;", "generated_sql": "SELECT \n    continent,\n    ROUND(\n        (SUM(CASE WHEN access_to_clean_water THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), \n        2\n    ) AS percentage_access_to_clean_water\nFROM \n    water_data\nGROUP BY \n    continent;", "raw_model_output": "To calculate the percentage of the population with access to clean water for each continent based on the provided schema and data, we need to make some assumptions since the table does not contain population data. We'll assume that each entry represents an equal portion of the population for simplicity.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT \n    continent,\n    ROUND(\n        (SUM(CASE WHEN access_to_clean_water THEN 1 ELSE 0 END) * 100.0 / COUNT(*)), \n        2\n    ) AS percentage_access_to_clean_water\nFROM \n    water_data\nGROUP BY \n    continent;\n```\n\n### Explanation:\n\n- **SELECT**: We select the `continent` and calculate the percentage of entries with access to clean water.\n  \n- **SUM(CASE WHEN access_to_clean_water THEN 1 ELSE 0 END)**: This counts how many rows have `access_to_clean_water` set to true for each continent.\n\n- **COUNT(*)**: This gives the total number of rows (entries) per continent.\n\n- **ROUND(..., 2)**: Rounds the result to two decimal places for readability.\n\n- **GROUP BY continent**: Groups the results by continent so that we calculate the percentage separately for each one.", "latency_sec": 6.295660734176636, "total_duration_sec": 6.291658816, "load_duration_sec": 0.015815761, "tokens_prompt": 162, "prompt_eval_sec": 0.022182152, "tokens_completion": 254, "completion_eval_sec": 6.2526837, "tokens_total": 416, "tokens_per_sec": 66.07725822036464, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in column name and the use of ROUND, which affects the output precision. The Reference SQL uses COUNT(*) FILTER and no rounding, while the Generated SQL uses SUM(CASE...) and rounds to 2 decimal places. Additionally, the column names differ ('percentage' vs 'percentage_access_to_clean_water').", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent due to the ROUND function in the generated query, which introduces decimal precision rounding not present in the reference. Both calculate the correct percentage by continent, but the generated query explicitly formats the result to two decimal places, making it more user-friendly for percentage representation. The reference uses PostgreSQL-specific FILTER syntax, while the generated query uses standard SQL. Both fulfill the business intent of calculating access percentages, but the generated query's rounding aligns better with typical percentage reporting conventions.", "overall_assessment": "differently_correct"}}
{"example_id": 3542, "sql_complexity": "window functions", "prompt": "What is the average yield of crops for each country, ranked by average yield?", "context": "CREATE TABLE farming (id INT, name TEXT, country TEXT, crop TEXT, yield INT); INSERT INTO farming VALUES (1, 'Smith Farm', 'USA', 'Corn', 120), (2, 'Brown Farm', 'Canada', 'Soybeans', 45), (3, 'Jones Farm', 'Mexico', 'Wheat', 80);", "reference_sql": "SELECT country, AVG(yield) as avg_yield, ROW_NUMBER() OVER (ORDER BY AVG(yield) DESC) as rank FROM farming GROUP BY country;", "generated_sql": "SELECT \n    country,\n    AVG(yield) AS average_yield\nFROM \n    farming\nGROUP BY \n    country\nORDER BY \n    average_yield DESC;", "raw_model_output": "To find the average yield of crops for each country and rank them by this average yield, you can use the following SQL query:\n\n```sql\nSELECT \n    country,\n    AVG(yield) AS average_yield\nFROM \n    farming\nGROUP BY \n    country\nORDER BY \n    average_yield DESC;\n```\n\nThis query performs the following operations:\n- Selects the `country` and calculates the average `yield` for each country using the `AVG()` aggregate function.\n- Groups the results by `country` to ensure that the average is calculated separately for each country.\n- Orders the results in descending order based on the computed `average_yield`.", "latency_sec": 3.275831699371338, "total_duration_sec": 3.269112232, "load_duration_sec": 0.016012332, "tokens_prompt": 162, "prompt_eval_sec": 0.022946227, "tokens_completion": 133, "completion_eval_sec": 3.228648279, "tokens_total": 295, "tokens_per_sec": 90.05346643925975, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes a ROW_NUMBER() column for ranking, while the Generated SQL only returns country and average_yield without ranking. The Generated SQL's ORDER BY achieves similar sorting but lacks the rank column, making the result sets structurally different.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL includes a ranking column using ROW_NUMBER() which directly addresses the 'ranked by average yield' requirement. The Generated SQL correctly calculates averages and sorts results but lacks an explicit ranking mechanism. While both queries compute average yields accurately, the Reference SQL better fulfills the business intent by explicitly providing ranks. The Generated SQL's ORDER BY achieves sorting but doesn't create a true rank column. Technically, the Reference SQL is valid but could be optimized by using the alias 'avg_yield' in the window function (though it works as written).", "overall_assessment": "differently_correct"}}
{"example_id": 2274, "sql_complexity": "subqueries", "prompt": "Add a new crop 'amaranth' to farm 'Nourishing Harvest' with yield 50 in 2023", "context": "CREATE TABLE farms (id INT, name TEXT, location TEXT, size FLOAT); INSERT INTO farms (id, name, location, size) VALUES (1, 'Nourishing Harvest', 'Mexico', 120.0); CREATE TABLE crops (id INT, farm_id INT, crop TEXT, yield INT, year INT);", "reference_sql": "INSERT INTO crops (id, farm_id, crop, yield, year) VALUES (5, (SELECT id FROM farms WHERE name = 'Nourishing Harvest'), 'amaranth', 50, 2023);", "generated_sql": "INSERT INTO crops (farm_id, crop, yield, year)\nSELECT id, 'amaranth', 50, 2023\nFROM farms\nWHERE name = 'Nourishing Harvest';", "raw_model_output": "To add a new crop entry for the farm \"Nourishing Harvest\" with the specified details, we first need to determine the `farm_id` associated with this farm. We can achieve this by querying the `farms` table to find the `id` of the farm named \"Nourishing Harvest\". Once we have the `farm_id`, we can insert a new record into the `crops` table.\n\nHere's how you can do it in SQL:\n\n```sql\nINSERT INTO crops (farm_id, crop, yield, year)\nSELECT id, 'amaranth', 50, 2023\nFROM farms\nWHERE name = 'Nourishing Harvest';\n```\n\nThis query first selects the `id` of the farm with the name \"Nourishing Harvest\" from the `farms` table and then uses that `id` to insert a new record into the `crops` table with the specified crop details.", "latency_sec": 4.7493579387664795, "total_duration_sec": 4.7447703, "load_duration_sec": 0.012263189, "tokens_prompt": 163, "prompt_eval_sec": 0.024487058, "tokens_completion": 192, "completion_eval_sec": 4.707199411, "tokens_total": 355, "tokens_per_sec": 74.74694570866602, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL explicitly sets the 'id' column to 5, while the Generated SQL omits the 'id' column entirely. The Generated SQL would insert a row with whatever value the database assigns to 'id' (e.g., auto-increment), whereas the Reference SQL hardcodes it to 5. This difference in column assignment makes them non-equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly add 'amaranth' to 'Nourishing Harvest' with yield 50 in 2023. The reference query explicitly specifies the id column and uses a subquery to get farm_id, while the generated query uses a SELECT statement to dynamically fetch the farm_id. Both produce identical results assuming the farm name is unique. The generated query is more elegant as it avoids hardcoding the id value and leverages standard INSERT-SELECT syntax, which is more maintainable and scalable. However, both technically fulfill the business intent.", "overall_assessment": "correct"}}
{"example_id": 3705, "sql_complexity": "subqueries", "prompt": "What is the percentage of unions with collective bargaining agreements in the Midwest region?", "context": "CREATE TABLE collective_bargaining (bargaining_id INT, union_name VARCHAR(50), contract_start_date DATE, contract_end_date DATE, region VARCHAR(50));CREATE VIEW union_region AS SELECT DISTINCT union_name, region FROM collective_bargaining;", "reference_sql": "SELECT COUNT(*) * 100.0 / (SELECT COUNT(*) FROM union_region) as percentage FROM union_region ur WHERE ur.region = 'Midwest' AND EXISTS (SELECT 1 FROM collective_bargaining cb WHERE cb.union_name = ur.union_name);", "generated_sql": "SELECT \n    (COUNT(DISTINCT CASE WHEN cr.region = 'Midwest' THEN cr.union_name END) * 100.0 / COUNT(DISTINCT cr.union_name)) AS percentage_midwest_unions\nFROM \n    union_region cr;", "raw_model_output": "To calculate the percentage of unions with collective bargaining agreements specifically in the Midwest region, we can use a combination of subqueries and aggregate functions. Here's how you can construct the SQL statement:\n\n```sql\nSELECT \n    (COUNT(DISTINCT CASE WHEN cr.region = 'Midwest' THEN cr.union_name END) * 100.0 / COUNT(DISTINCT cr.union_name)) AS percentage_midwest_unions\nFROM \n    union_region cr;\n```\n\n### Explanation:\n- **`union_region` View**: This view provides a distinct list of `union_name` and their corresponding `region`.\n- **Subquery Logic**:\n  - We use `COUNT(DISTINCT CASE WHEN cr.region = 'Midwest' THEN cr.union_name END)` to count the number of unique unions that are in the Midwest region.\n  - We divide this by `COUNT(DISTINCT cr.union_name)`, which gives us the total number of unique unions across all regions.\n- **Percentage Calculation**: Multiply by `100.0` to convert the ratio into a percentage.\n\nThis query will return the percentage of unions with agreements specifically in the Midwest region relative to all unions listed in the view.", "latency_sec": 6.000684022903442, "total_duration_sec": 5.995812258, "load_duration_sec": 0.017164393, "tokens_prompt": 138, "prompt_eval_sec": 0.019875691, "tokens_completion": 241, "completion_eval_sec": 5.9575575, "tokens_total": 379, "tokens_per_sec": 63.15946624641971, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the percentage of (union_name, region) pairs in the Midwest relative to all (union_name, region) pairs, while the Generated SQL calculates the percentage of distinct union_names in the Midwest relative to all distinct union_names. The denominators differ: the Reference uses COUNT(*) (total pairs) and the Generated uses COUNT(DISTINCT union_name) (total unique unions). This leads to different results when a union appears in multiple regions.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries calculate the percentage of unions with collective bargaining agreements (CBAs) in the Midwest region. The reference query uses a subquery and EXISTS clause, which is redundant since union_region already contains only unions with CBAs. The generated query simplifies this by directly counting distinct unions in the Midwest and dividing by total distinct unions in union_region. Both produce identical results, but the generated query is more efficient and elegant by avoiding unnecessary subqueries and conditions.", "overall_assessment": "correct"}}
{"example_id": 240, "sql_complexity": "aggregation", "prompt": "What is the average capacity of renewable energy projects for each country?", "context": "CREATE TABLE projects (name TEXT, type TEXT, capacity INTEGER, country TEXT); INSERT INTO projects (name, type, capacity, country) VALUES ('Project 1', 'Wind', 100, 'USA'), ('Project 2', 'Solar', 200, 'Germany'), ('Project 3', 'Wind', 300, 'France');", "reference_sql": "SELECT country, AVG(capacity) FROM projects GROUP BY country", "generated_sql": "SELECT \n    country,\n    AVG(capacity) AS average_capacity\nFROM \n    projects\nGROUP BY \n    country;", "raw_model_output": "To find the average capacity of renewable energy projects for each country, we need to consider all projects in the `projects` table and calculate the average capacity grouped by the `country`. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    country,\n    AVG(capacity) AS average_capacity\nFROM \n    projects\nGROUP BY \n    country;\n```\n\nThis query selects the `country` column and calculates the average of the `capacity` for each group of rows that have the same `country`. The `AVG()` function computes the average, and `GROUP BY` ensures that this calculation is done separately for each country.", "latency_sec": 3.2929680347442627, "total_duration_sec": 3.286334679, "load_duration_sec": 0.011137224, "tokens_prompt": 156, "prompt_eval_sec": 0.020814123, "tokens_completion": 132, "completion_eval_sec": 3.253619824, "tokens_total": 288, "tokens_per_sec": 87.45909372982011, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries group projects by country and calculate the average capacity per country. The generated query adds an explicit column alias (average_capacity) which does not affect the semantic result, only the column name in the output.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries are technically equivalent as they produce identical results by calculating the average capacity per country. The generated query improves upon the reference by adding an explicit column alias ('average_capacity'), enhancing readability and clarity without altering functionality. The business intent of calculating average renewable energy project capacity per country is fully addressed by both queries. The generated version is more elegant due to the alias, which makes the output more self-explanatory.", "overall_assessment": "correct"}}
{"example_id": 2132, "sql_complexity": "set operations", "prompt": "What is the average caseload per attorney in community legal clinics in California, and how does it compare to the state average?", "context": "CREATE TABLE cali_community_legal_clinics(id INT, attorney_count INT, cases_handled INT, state VARCHAR(255));", "reference_sql": "SELECT state, AVG(cases_handled/attorney_count) AS avg_caseload FROM cali_community_legal_clinics WHERE state = 'California' GROUP BY state UNION ALL SELECT 'California', AVG(cases_handled/attorney_count) FROM cali_community_legal_clinics WHERE state = 'California';", "generated_sql": "WITH ClinicAverages AS (\n    SELECT \n        id,\n        CASE \n            WHEN attorney_count > 0 THEN cases_handled / CAST(attorney_count AS FLOAT)\n            ELSE 0\n        END AS avg_caseload_per_attorney\n    FROM \n        cali_community_legal_clinics\n)\n\nSELECT \n    AVG(avg_caseload_per_attorney) AS state_average_caseload_per_attorney,\n    (SELECT AVG(avg_caseload_per_attorney) FROM ClinicAverages) AS overall_state_average\nFROM \n    ClinicAverages;", "raw_model_output": "To solve this problem, we need to calculate two averages:\n\n1. The average caseload per attorney for each clinic.\n2. The overall average of these averages across all clinics.\n\nHere's the SQL query that accomplishes this:\n\n```sql\nWITH ClinicAverages AS (\n    SELECT \n        id,\n        CASE \n            WHEN attorney_count > 0 THEN cases_handled / CAST(attorney_count AS FLOAT)\n            ELSE 0\n        END AS avg_caseload_per_attorney\n    FROM \n        cali_community_legal_clinics\n)\n\nSELECT \n    AVG(avg_caseload_per_attorney) AS state_average_caseload_per_attorney,\n    (SELECT AVG(avg_caseload_per_attorney) FROM ClinicAverages) AS overall_state_average\nFROM \n    ClinicAverages;\n```\n\n### Explanation:\n\n- **CTE `ClinicAverages`:** This Common Table Expression calculates the average caseload per attorney for each clinic. It uses a `CASE` statement to handle divisions by zero, setting the average to 0 if there are no attorneys.\n\n- **Main Query:** \n  - The first part of the main query calculates the average of these individual averages (`state_average_caseload_per_attorney`) across all clinics.\n  - The second part (subquery) retrieves this same overall state average for comparison. \n\nThis approach ensures that we get both the per-clinic averages and the overall state average in a single query execution.", "latency_sec": 7.311500072479248, "total_duration_sec": 7.306793328, "load_duration_sec": 0.016297581, "tokens_prompt": 123, "prompt_eval_sec": 0.01651959, "tokens_completion": 298, "completion_eval_sec": 7.273008882, "tokens_total": 421, "tokens_per_sec": 57.580523261520476, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in structure and logic. The Reference SQL returns two rows for California with the same average caseload, while the Generated SQL returns a single row with two columns (state_average and overall_state_average). Additionally, the Generated SQL handles division by zero explicitly, whereas the Reference SQL would fail on division by zero. The output formats and calculation approaches (per-clinic vs. overall) also differ.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference SQL attempts to calculate California's average caseload and redundantly repeats it, while the generated SQL lacks proper filtering and misrepresents the comparison. The reference query correctly isolates California data but has a logical flaw in its UNION ALL structure. The generated SQL fails to filter for California and incorrectly computes the same value twice. Neither query properly addresses the comparison to the 'state average' (which should be California's own average if the table contains only California data). The reference query is closer to the intent but still flawed.", "overall_assessment": "differently_correct"}}
{"example_id": 3276, "sql_complexity": "basic SQL", "prompt": "What is the total energy consumption of the Chemical Plant B in the last quarter?", "context": "CREATE TABLE EnergyConsumption (EnergyID INT, Plant VARCHAR(255), EnergyQuantity DECIMAL(5,2), Timestamp DATETIME);", "reference_sql": "SELECT SUM(EnergyQuantity) FROM EnergyConsumption WHERE Plant = 'Chemical Plant B' AND Timestamp BETWEEN DATE_SUB(CURRENT_DATE(), INTERVAL 3 MONTH) AND CURRENT_DATE();", "generated_sql": "SELECT SUM(EnergyQuantity) AS TotalEnergyConsumption\nFROM EnergyConsumption\nWHERE Plant = 'Chemical Plant B'\n  AND Timestamp >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n  AND Timestamp < DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()), 0);", "raw_model_output": "To calculate the total energy consumption for Chemical Plant B in the last quarter, we need to determine the date range that defines \"the last quarter\" relative to the current date. In SQL, this can be achieved using functions like `DATEADD` and `QUARTER`. Here's how you can construct the query:\n\n```sql\nSELECT SUM(EnergyQuantity) AS TotalEnergyConsumption\nFROM EnergyConsumption\nWHERE Plant = 'Chemical Plant B'\n  AND Timestamp >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n  AND Timestamp < DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()), 0);\n```\n\n### Explanation:\n\n- `SUM(EnergyQuantity) AS TotalEnergyConsumption`: This calculates the total energy consumption for the specified conditions.\n  \n- `WHERE Plant = 'Chemical Plant B'`: Filters records to include only those from Chemical Plant B.\n\n- `Timestamp >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)`: \n  - `DATEDIFF(quarter, 0, GETDATE())` calculates the number of quarters between a base date (usually '1900-01-01') and the current date.\n  - Subtracting 1 gives us the start of the last quarter.\n  - `DATEADD(quarter, ..., 0)` adds this difference to the base date to get the starting point of the last quarter.\n\n- `Timestamp < DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()), 0)`: \n  - This calculates the start of the current quarter.\n  - The condition ensures that we only include timestamps from the last quarter up to but not including the start of the current quarter. \n\nThis query assumes you are using a SQL Server database due to the use of `GETDATE()`, `DATEADD()`, and `DATEDIFF()` functions. If you're using another RDBMS, equivalent date functions should be used (e.g., `CURRENT_DATE` in PostgreSQL or MySQL).", "latency_sec": 10.819026947021484, "total_duration_sec": 10.812204468, "load_duration_sec": 0.012956892, "tokens_prompt": 116, "prompt_eval_sec": 0.015540006, "tokens_completion": 436, "completion_eval_sec": 10.783027593, "tokens_total": 552, "tokens_per_sec": 51.02122424715538, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query selects data from the last 3 months (exact 90-day window), while the generated query selects data from the previous quarter (calendar quarter). These ranges may not align exactly, especially when the current date is not at the start of a quarter. For example, if today is April 5th, the reference includes Jan 5th - Apr 5th, while the generated query includes Jan 1st - Mar 31st. The date calculations use different logic (3-month interval vs. quarter boundaries) leading to different result sets.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in date calculation logic and database dialect. The reference uses MySQL functions (DATE_SUB, CURRENT_DATE) to capture the last 3 months, while the generated query uses SQL Server functions (DATEADD, DATEDIFF, GETDATE()) to capture the previous full quarter. Although both target 'last quarter,' the generated query more precisely defines a calendar quarter (e.g., April-June 2023) by calculating the start of the previous quarter, whereas the reference includes a 3-month window that may overlap with the current quarter. The generated query also avoids potential edge cases with BETWEEN by using explicit range boundaries. However, the queries are not technically equivalent due to dialect differences. The generated query better fulfills the business intent of capturing the full previous quarter.", "overall_assessment": "differently_correct"}}
{"example_id": 3074, "sql_complexity": "multiple_joins", "prompt": "Find the top 5 players with the highest scores in the 'historical_tournaments' view, including their scores and the names of the tournaments they participated in.", "context": "CREATE VIEW historical_tournaments AS SELECT tournaments.tournament_name, players.player_name, players.score FROM tournaments JOIN players_scores ON tournaments.tournament_id = players_scores.tournament_id JOIN players ON players_scores.player_id = players.player_id;  CREATE TABLE tournaments (tournament_id INT, tournament_name TEXT);  CREATE TABLE players_scores (player_id INT, tournament_id INT, score INT);  CREATE TABLE players (player_id INT, player_name TEXT);", "reference_sql": "SELECT players.player_name, MAX(players_scores.score) as high_score, tournaments.tournament_name FROM historical_tournaments JOIN players ON historical_tournaments.player_id = players.player_id JOIN players_scores ON historical_tournaments.player_id = players_scores.player_id JOIN tournaments ON players_scores.tournament_id = tournaments.tournament_id GROUP BY players.player_id, tournaments.tournament_name ORDER BY high_score DESC LIMIT 5;", "generated_sql": "SELECT tournament_name, player_name, score\nFROM historical_tournaments\nORDER BY score DESC\nLIMIT 5;", "raw_model_output": "To find the top 5 players with the highest scores from the `historical_tournaments` view, we need to select the relevant columns (`tournament_name`, `player_name`, and `score`) and order them by score in descending order. We will then limit the results to the top 5 entries.\n\nHere's the SQL statement:\n\n```sql\nSELECT tournament_name, player_name, score\nFROM historical_tournaments\nORDER BY score DESC\nLIMIT 5;\n```\n\nThis query retrieves the desired information from the `historical_tournaments` view and sorts it by scores in descending order, ensuring that only the top 5 players are selected.", "latency_sec": 3.3439440727233887, "total_duration_sec": 3.338471827, "load_duration_sec": 0.020556804, "tokens_prompt": 194, "prompt_eval_sec": 0.031204632, "tokens_completion": 132, "completion_eval_sec": 3.285872147, "tokens_total": 326, "tokens_per_sec": 97.48966875947113, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL calculates the maximum score per player per tournament using GROUP BY and MAX(), while the Generated SQL simply retrieves the top 5 scores from the view without aggregation. The Reference SQL's output includes aggregated high scores and groups by player/tournament, whereas the Generated SQL returns raw score entries without grouping or aggregation.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is technically flawed: it groups by tournament_name and player_id, which would return per-tournament max scores rather than each player's overall highest score. It also redundantly joins tables already included in the view. The Generated SQL is simpler but fails to aggregate player scores across tournaments, potentially returning multiple entries per player and not ensuring the highest score per player. Neither query fully addresses the intent of identifying top players with their highest scores and associated tournaments. However, the Generated SQL is more straightforward and closer to the raw data, while the Reference SQL introduces unnecessary complexity and logical errors.", "overall_assessment": "differently_correct"}}
{"example_id": 2219, "sql_complexity": "window functions", "prompt": "What is the average population of cities with a UNESCO World Heritage designation, ordered by designation date?", "context": "CREATE TABLE cities (name VARCHAR(255), population INT, designation_date DATE); INSERT INTO cities (name, population, designation_date) VALUES ('Paris', 2141000, '1991-09-16'); INSERT INTO cities (name, population, designation_date) VALUES ('Rio de Janeiro', 6727000, '2012-07-01');", "reference_sql": "SELECT AVG(population) FROM (SELECT population, ROW_NUMBER() OVER (ORDER BY designation_date) rn FROM cities WHERE name IN (SELECT name FROM heritagesites)) t WHERE rn % 2 = 1;", "generated_sql": "SELECT AVG(population) AS average_population\nFROM cities\nORDER BY designation_date;", "raw_model_output": "To answer this question, we need to make some assumptions based on the context provided. The schema only includes a `cities` table without any explicit reference to UNESCO World Heritage designations. Therefore, I'll assume that all cities in the table have such a designation for the purpose of calculating the average population.\n\nHere's how you can write an SQL query to find the average population of these cities, ordered by their designation date:\n\n```sql\nSELECT AVG(population) AS average_population\nFROM cities\nORDER BY designation_date;\n```\n\n### Explanation:\n- `AVG(population)` calculates the average population of all cities in the table.\n- `AS average_population` gives a name to the calculated column for clarity.\n- `ORDER BY designation_date` sorts the result by the date when each city was designated, although it doesn't affect the calculation of the average itself. This part is included because the question asks for ordering by designation date.\n\nNote: Since there's no filtering condition based on UNESCO World Heritage status (as it's not present in the schema), all cities are considered to have such a designation. If additional criteria were provided, we would include a `WHERE` clause to filter accordingly.", "latency_sec": 6.028440952301025, "total_duration_sec": 6.023546895, "load_duration_sec": 0.011689647, "tokens_prompt": 165, "prompt_eval_sec": 0.022356596, "tokens_completion": 242, "completion_eval_sec": 5.988818947, "tokens_total": 407, "tokens_per_sec": 67.51330953065903, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the average of populations from cities in heritagesites, selecting only odd-numbered rows ordered by designation_date. The Generated SQL simply averages all cities' populations without filtering or row selection. The Reference SQL's subquery depends on a non-existent heritagesites table and applies row-number filtering, while the Generated SQL lacks these components. Additionally, the Generated SQL's ORDER BY has no effect on the aggregate result.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference SQL is invalid due to referencing a non-existent 'heritagesites' table, making it technically incorrect. The generated SQL is syntactically valid but fails to filter cities with UNESCO designations (assuming designation_date indicates eligibility). The original question requires filtering for designated cities, which neither query properly addresses. However, the generated SQL at least calculates the average population correctly, while the reference SQL would fail entirely.", "overall_assessment": "incorrect"}}
{"example_id": 3786, "sql_complexity": "aggregation", "prompt": "Display the names and average co-owner percentages for all properties in the 'property_coownership' table where the co-owner percentage is greater than 60.", "context": "CREATE TABLE property_coownership (property_id INT, owner VARCHAR(255), percentage INT); INSERT INTO property_coownership (property_id, owner, percentage) VALUES (1, 'Mohammed', 70), (1, 'Fatima', 30), (2, 'Jamal', 65), (2, 'Aisha', 35), (3, 'Ali', 75), (3, 'Khadija', 25);", "reference_sql": "SELECT owner, AVG(percentage) FROM property_coownership WHERE percentage > 60 GROUP BY owner;", "generated_sql": "SELECT \n    p.property_id,\n    AVG(p.percentage) AS avg_percentage\nFROM \n    property_coownership p\nWHERE \n    p.property_id IN (\n        SELECT DISTINCT pc.property_id\n        FROM property_coownership pc\n        WHERE pc.percentage > 60\n    )\nGROUP BY \n    p.property_id;", "raw_model_output": "To solve this problem, we need to calculate the average percentage of co-owners for each property where at least one co-owner has a percentage greater than 60. We will then display the names of these properties along with their calculated average percentages.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT \n    p.property_id,\n    AVG(p.percentage) AS avg_percentage\nFROM \n    property_coownership p\nWHERE \n    p.property_id IN (\n        SELECT DISTINCT pc.property_id\n        FROM property_coownership pc\n        WHERE pc.percentage > 60\n    )\nGROUP BY \n    p.property_id;\n```\n\n### Explanation:\n\n1. **Subquery**: We first identify the `property_id`s where at least one co-owner has a percentage greater than 60 using a subquery:\n   ```sql\n   SELECT DISTINCT pc.property_id\n   FROM property_coownership pc\n   WHERE pc.percentage > 60\n   ```\n   This subquery returns distinct `property_id`s that meet the condition.\n\n2. **Main Query**: We then use this list of `property_id`s to filter our main query:\n   ```sql\n   SELECT \n       p.property_id,\n       AVG(p.percentage) AS avg_percentage\n   FROM \n       property_coownership p\n   WHERE \n       p.property_id IN (/* subquery result */)\n   GROUP BY \n       p.property_id;\n   ```\n   - We select the `property_id` and calculate the average percentage (`AVG(p.percentage)`) for each of these properties.\n   - The `GROUP BY p.property_id` clause ensures that we compute the average for each property separately.\n\nThis query will give you the desired output: the names (as `property_id`s) and average percentages for all properties where at least one co-owner has a percentage greater than 60.", "latency_sec": 9.390589952468872, "total_duration_sec": 9.384795413, "load_duration_sec": 0.019171964, "tokens_prompt": 194, "prompt_eval_sec": 0.033268946, "tokens_completion": 377, "completion_eval_sec": 9.330740451, "tokens_total": 571, "tokens_per_sec": 60.80555139668077, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL groups by 'owner' and calculates the average percentage for owners with individual entries >60, while the Generated SQL groups by 'property_id' and averages all percentages for properties where *any* entry exceeds 60. The output structure (owner vs. property_id) and calculation logic differ, leading to distinct results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL selects owners and their individual percentages (grouped by owner) where their own percentage exceeds 60, which misinterprets the question's intent. The Generated SQL correctly identifies properties with at least one co-owner >60% and calculates the average percentage for all co-owners of those properties. However, neither query fully addresses the 'names' requirement (Reference returns owner names, Generated returns property IDs). The Generated query better aligns with the business intent of analyzing properties with high co-owner percentages, even though it lacks owner names. The Reference query's grouping by owner is semantically incorrect for the question's phrasing.", "overall_assessment": "differently_correct"}}
{"example_id": 2357, "sql_complexity": "basic SQL", "prompt": "What is the total amount of climate finance invested in renewable energy projects by public and private sectors in Africa?", "context": "CREATE TABLE renewable_energy_projects (project_id INT, sector TEXT, investor_type TEXT, region TEXT, amount FLOAT); INSERT INTO renewable_energy_projects (project_id, sector, investor_type, region, amount) VALUES (1, 'Renewable Energy', 'Public', 'Africa', 5000000); INSERT INTO renewable_energy_projects (project_id, sector, investor_type, region, amount) VALUES (2, 'Renewable Energy', 'Private', 'Africa', 7000000);", "reference_sql": "SELECT SUM(amount) FROM renewable_energy_projects WHERE sector = 'Renewable Energy' AND region = 'Africa';", "generated_sql": "SELECT SUM(amount) AS total_investment\nFROM renewable_energy_projects\nWHERE sector = 'Renewable Energy'\n  AND region = 'Africa';", "raw_model_output": "To find the total amount of climate finance invested in renewable energy projects by both public and private sectors specifically in Africa, you can use the following SQL query:\n\n```sql\nSELECT SUM(amount) AS total_investment\nFROM renewable_energy_projects\nWHERE sector = 'Renewable Energy'\n  AND region = 'Africa';\n```\n\nThis query sums up the `amount` column for all entries where the `sector` is \"Renewable Energy\" and the `region` is \"Africa\", effectively capturing investments from both public and private sectors in that region.", "latency_sec": 2.847513198852539, "total_duration_sec": 2.840874327, "load_duration_sec": 0.012956511, "tokens_prompt": 194, "prompt_eval_sec": 0.031947562, "tokens_completion": 113, "completion_eval_sec": 2.794842176, "tokens_total": 307, "tokens_per_sec": 107.81337207627752, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. The generated query adds an alias (total_investment) to the SUM(amount) column, but this does not affect the actual result set. Both queries calculate the same sum for projects in the 'Renewable Energy' sector located in 'Africa'.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": false, "superiority": "equal", "explanation": "The queries are technically equivalent as they both calculate the sum of amounts for 'Renewable Energy' projects in Africa. However, they fail to fulfill the business intent because the original question explicitly asks for investments by both public and private sectors, but the queries do not filter on the 'investor_type' column. While the sample data only contains public and private entries, the queries would include all investor types if additional data existed, leading to potential inaccuracies. The generated query improves readability with an alias, but neither query addresses the full scope of the question.", "overall_assessment": "differently_correct"}}
{"example_id": 1009, "sql_complexity": "multiple_joins", "prompt": "Find the number of IoT sensors installed in each farm that use Sprinkler irrigation.", "context": "CREATE TABLE IoT_Sensors (id INT, sensor_type VARCHAR(50), Farm_id INT); INSERT INTO IoT_Sensors (id, sensor_type, Farm_id) VALUES (1, 'Soil Moisture', 1), (2, 'Temperature', 1), (3, 'Humidity', 2); CREATE TABLE Irrigation (id INT, Farm_id INT, irrigation_type VARCHAR(50), duration INT); INSERT INTO Irrigation (id, Farm_id, irrigation_type, duration) VALUES (1, 1, 'Sprinkler', 30), (2, 2, 'Drip', 45);", "reference_sql": "SELECT f.id, COUNT(s.id) FROM Farmers f JOIN Irrigation i ON f.id = i.Farm_id JOIN IoT_Sensors s ON f.id = s.Farm_id WHERE i.irrigation_type = 'Sprinkler' GROUP BY f.id;", "generated_sql": "SELECT \n    i.Farm_id, \n    COUNT(i.id) AS sensor_count\nFROM \n    IoT_Sensors i\nJOIN \n    Irrigation ir ON i.Farm_id = ir.Farm_id\nWHERE \n    ir.irrigation_type = 'Sprinkler'\nGROUP BY \n    i.Farm_id;", "raw_model_output": "To solve this problem, we need to find the number of IoT sensors installed on farms that use \"Sprinkler\" as their irrigation type. We will achieve this by joining the `IoT_Sensors` and `Irrigation` tables based on the `Farm_id`, filtering for those entries where the `irrigation_type` is 'Sprinkler', and then counting the number of sensors per farm.\n\nHere's the SQL query to accomplish that:\n\n```sql\nSELECT \n    i.Farm_id, \n    COUNT(i.id) AS sensor_count\nFROM \n    IoT_Sensors i\nJOIN \n    Irrigation ir ON i.Farm_id = ir.Farm_id\nWHERE \n    ir.irrigation_type = 'Sprinkler'\nGROUP BY \n    i.Farm_id;\n```\n\n### Explanation:\n\n- **SELECT Clause**: We select `Farm_id` from the `IoT_Sensors` table and count the number of sensors (`COUNT(i.id)`) for each farm.\n  \n- **FROM Clause**: We specify the `IoT_Sensors` table as our primary source of data.\n\n- **JOIN Clause**: We perform an inner join with the `Irrigation` table on the `Farm_id` column to combine related records from both tables.\n\n- **WHERE Clause**: We filter the results to include only those farms where the `irrigation_type` is 'Sprinkler'.\n\n- **GROUP BY Clause**: We group the results by `Farm_id` to get a count of sensors for each farm that uses Sprinkler irrigation.", "latency_sec": 7.9869561195373535, "total_duration_sec": 7.981191783, "load_duration_sec": 0.021965196, "tokens_prompt": 218, "prompt_eval_sec": 0.034528752, "tokens_completion": 319, "completion_eval_sec": 7.923677029, "tokens_total": 537, "tokens_per_sec": 67.23462505151535, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count the number of IoT_Sensors per Farm_id where there's a corresponding Irrigation entry with 'Sprinkler' type. The Reference SQL uses Farmers as the primary table and counts IoT_Sensors, while the Generated SQL starts with IoT_Sensors and counts its own IDs. However, since the joins and grouping conditions are equivalent, and the final result sets (Farm_id and count) are identical, the queries produce the same output.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query incorrectly references a 'Farmers' table that does not exist in the provided schema, making it invalid. The generated query correctly uses the available tables (IoT_Sensors and Irrigation) and properly joins on Farm_id. Both queries aim to count IoT sensors per farm with Sprinkler irrigation, but the generated query avoids the invalid Farmers table. However, the generated query may overcount sensors if a farm has multiple Sprinkler irrigation entries (since it counts sensor-irrigation pairs rather than distinct sensors). Despite this, it better aligns with the schema and business intent.", "overall_assessment": "differently_correct"}}
{"example_id": 4217, "sql_complexity": "subqueries", "prompt": "Show consumer preference data for foundations, excluding products from the USA.", "context": "CREATE TABLE cosmetics (product_id INT, product_name VARCHAR(100), product_type VARCHAR(50), is_cruelty_free BOOLEAN, consumer_preference_score INT); INSERT INTO cosmetics (product_id, product_name, product_type, is_cruelty_free, consumer_preference_score) VALUES (1, 'Lipstick A', 'Lipstick', TRUE, 80), (2, 'Foundation B', 'Foundation', FALSE, 90), (3, 'Mascara C', 'Mascara', TRUE, 85), (4, 'Eyeshadow D', 'Eyeshadow', TRUE, 70), (5, 'Blush E', 'Blush', FALSE, 95); CREATE TABLE ingredient_sourcing (ingredient_id INT, ingredient_name VARCHAR(100), sourcing_country VARCHAR(50), is_organic BOOLEAN); INSERT INTO ingredient_sourcing (ingredient_id, ingredient_name, sourcing_country, is_organic) VALUES (1, 'Rosehip Oil', 'Chile', TRUE), (2, 'Shea Butter', 'Ghana', TRUE), (3, 'Jojoba Oil', 'India', TRUE), (4, 'Coconut Oil', 'Philippines', FALSE), (5, 'Aloe Vera', 'USA', TRUE);", "reference_sql": "SELECT * FROM cosmetics WHERE product_type = 'Foundation' AND product_id NOT IN (SELECT cosmetics.product_id FROM cosmetics INNER JOIN ingredient_sourcing ON cosmetics.product_id = ingredient_sourcing.ingredient_id WHERE ingredient_sourcing.sourcing_country = 'USA');", "generated_sql": "SELECT product_name, consumer_preference_score\nFROM cosmetics\nWHERE product_type = 'Foundation';", "raw_model_output": "To solve this problem, we need to extract information about foundation products from the `cosmetics` table and ensure that none of their ingredients are sourced from the USA. However, since there is no direct relationship between the `cosmetics` and `ingredient_sourcing` tables in the provided schema, we cannot directly filter out foundations based on ingredient sourcing countries.\n\nGiven this limitation, we can only provide consumer preference data for foundation products without considering the ingredient sourcing country constraint. Here's how you can write an SQL query to retrieve the required information:\n\n```sql\nSELECT product_name, consumer_preference_score\nFROM cosmetics\nWHERE product_type = 'Foundation';\n```\n\nThis query selects the `product_name` and `consumer_preference_score` from the `cosmetics` table where the `product_type` is 'Foundation'. Since there's no way to filter based on ingredient sourcing countries with the current schema, we cannot exclude products based on ingredients sourced from the USA.", "latency_sec": 4.954268932342529, "total_duration_sec": 4.947013671, "load_duration_sec": 0.020212716, "tokens_prompt": 348, "prompt_eval_sec": 0.069888668, "tokens_completion": 192, "completion_eval_sec": 4.855881769, "tokens_total": 540, "tokens_per_sec": 108.99690900402364, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters 'Foundation' products excluding those with ingredients sourced from the USA (via a subquery joining cosmetics.product_id and ingredient_sourcing.ingredient_id). The Generated SQL simply selects all 'Foundation' products without any filtering. The additional NOT IN condition in the Reference SQL makes it semantically different from the Generated SQL.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL contains a critical technical error: it incorrectly joins cosmetics.product_id (product identifier) with ingredient_sourcing.ingredient_id (ingredient identifier), which are unrelated columns. This makes the query logically invalid. The Generated SQL is technically correct (no syntax errors) but fails to address the exclusion requirement. While the Generated SQL returns foundation products, it does not filter out products sourced from the USA, which is the core business intent. The Reference SQL attempts to fulfill the intent but is technically flawed. Since the Generated SQL is syntactically valid and the Reference SQL is not, the Generated SQL is technically superior, though neither fully meets the business requirement.", "overall_assessment": "incorrect"}}
{"example_id": 5620, "sql_complexity": "basic SQL", "prompt": "What is the recycling rate of plastic in the residential sector in the state of New York?", "context": "CREATE TABLE recycling_rates_city (sector VARCHAR(20), city VARCHAR(20), material VARCHAR(20), recycling_rate DECIMAL(5,2)); INSERT INTO recycling_rates_city (sector, city, material, recycling_rate) VALUES ('residential', 'New York City', 'plastic', 0.25), ('commercial', 'New York City', 'plastic', 0.30), ('residential', 'New York City', 'paper', 0.45), ('commercial', 'New York City', 'paper', 0.50), ('residential', 'Los Angeles', 'plastic', 0.20), ('commercial', 'Los Angeles', 'plastic', 0.35), ('residential', 'Los Angeles', 'paper', 0.40), ('commercial', 'Los Angeles', 'paper', 0.50);", "reference_sql": "SELECT recycling_rate FROM recycling_rates_city WHERE sector = 'residential' AND material = 'plastic' AND city = 'New York City';", "generated_sql": "SELECT recycling_rate \nFROM recycling_rates_city \nWHERE city = 'New York City' \n  AND material = 'plastic' \n  AND sector = 'residential';", "raw_model_output": "To find the recycling rate of plastic in the residential sector specifically for New York City (since the schema does not include a \"state\" column, we assume that cities are directly referenced), you can use the following SQL query:\n\n```sql\nSELECT recycling_rate \nFROM recycling_rates_city \nWHERE city = 'New York City' \n  AND material = 'plastic' \n  AND sector = 'residential';\n```\n\nThis query filters the `recycling_rates_city` table to select only those rows where the `city` is \"New York City\", the `material` is \"plastic\", and the `sector` is \"residential\". It then retrieves the `recycling_rate` for these filtered records.", "latency_sec": 3.748368740081787, "total_duration_sec": 3.74174372, "load_duration_sec": 0.023740583, "tokens_prompt": 268, "prompt_eval_sec": 0.046819933, "tokens_completion": 146, "completion_eval_sec": 3.66852543, "tokens_total": 414, "tokens_per_sec": 110.44804519177768, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select the same column (recycling_rate) from the same table (recycling_rates_city) and apply identical WHERE conditions (sector = 'residential', material = 'plastic', city = 'New York City'). The order of conditions in the WHERE clause does not affect the result since all are equality checks and the logical AND operator is commutative.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are syntactically correct and semantically equivalent. They both retrieve the recycling_rate from the recycling_rates_city table where sector = 'residential', material = 'plastic', and city = 'New York City'. The order of conditions in the WHERE clause does not affect the result. Both queries correctly address the business question by filtering exactly the required parameters. The generated query's condition order (city \u2192 material \u2192 sector) might be slightly more intuitive for some readers, but there is no functional difference. Neither query is more efficient than the other in this context.", "overall_assessment": "correct"}}
{"example_id": 3151, "sql_complexity": "basic SQL", "prompt": "List all biotech startups that received funding in 2022 and their respective funding amounts.", "context": "CREATE TABLE biotech_startups (name TEXT, funding FLOAT, date DATE); INSERT INTO biotech_startups (name, funding, date) VALUES ('StartupA', 3500000, '2022-02-28'); INSERT INTO biotech_startups (name, funding, date) VALUES ('StartupB', 4500000, '2022-07-12');", "reference_sql": "SELECT name, funding FROM biotech_startups WHERE date BETWEEN '2022-01-01' AND '2022-12-31';", "generated_sql": "SELECT name, funding \nFROM biotech_startups \nWHERE EXTRACT(YEAR FROM date) = 2022;", "raw_model_output": "```sql\nSELECT name, funding \nFROM biotech_startups \nWHERE EXTRACT(YEAR FROM date) = 2022;\n```", "latency_sec": 0.7720251083374023, "total_duration_sec": 0.767197285, "load_duration_sec": 0.020788607, "tokens_prompt": 168, "prompt_eval_sec": 0.022608326, "tokens_completion": 29, "completion_eval_sec": 0.72265149, "tokens_total": 197, "tokens_per_sec": 255.17304796504627, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select records where the date falls within 2022. The reference query uses BETWEEN '2022-01-01' AND '2022-12-31' which includes all dates in that year. The generated query uses EXTRACT(YEAR FROM date) = 2022 which also captures all dates in 2022. Since the date column is of DATE type (no time component), both approaches yield identical results for the given schema.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly retrieve biotech startups funded in 2022. The reference query uses `BETWEEN '2022-01-01' AND '2022-12-31'` to capture all dates in 2022, while the generated query uses `EXTRACT(YEAR FROM date) = 2022` to explicitly check the year. Since the `date` column is of type `DATE`, both approaches yield identical results. However, `EXTRACT` might be less efficient on large datasets if no index exists on the `date` column, while `BETWEEN` could leverage indexes more effectively. Neither query has a clear advantage in business intent fulfillment as both address the requirement directly.", "overall_assessment": "correct"}}
{"example_id": 2136, "sql_complexity": "window functions", "prompt": "What is the total military equipment sales revenue for each sales representative by fiscal year?", "context": "CREATE TABLE SalesReps (SalesRepID INT, SalesRepName VARCHAR(50), FiscalYear INT, Revenue DECIMAL(10,2)); INSERT INTO SalesReps (SalesRepID, SalesRepName, FiscalYear, Revenue) VALUES (1, 'John Doe', 2020, 150000.00), (2, 'Jane Smith', 2020, 200000.00), (1, 'John Doe', 2021, 180000.00), (2, 'Jane Smith', 2021, 250000.00);", "reference_sql": "SELECT SalesRepName, FiscalYear, SUM(Revenue) OVER (PARTITION BY SalesRepName ORDER BY FiscalYear) AS TotalRevenue FROM SalesReps;", "generated_sql": "SELECT \n    SalesRepName,\n    FiscalYear,\n    SUM(Revenue) AS TotalRevenue\nFROM \n    SalesReps\nGROUP BY \n    SalesRepName, \n    FiscalYear;", "raw_model_output": "To address the question of calculating the total sales revenue for each sales representative by fiscal year from the provided `SalesReps` table, we need to group the data by both `SalesRepName` and `FiscalYear`. The query will sum up the `Revenue` for these groups. Here's how you can write this SQL statement:\n\n```sql\nSELECT \n    SalesRepName,\n    FiscalYear,\n    SUM(Revenue) AS TotalRevenue\nFROM \n    SalesReps\nGROUP BY \n    SalesRepName, \n    FiscalYear;\n```\n\n### Explanation:\n- **SELECT Clause**: We select `SalesRepName` and `FiscalYear` to identify each group. We also calculate the total revenue for each group using `SUM(Revenue)`, which we alias as `TotalRevenue`.\n- **FROM Clause**: Specifies the table from which to retrieve data, in this case, `SalesReps`.\n- **GROUP BY Clause**: Groups the results by `SalesRepName` and `FiscalYear` so that the sum of revenue is calculated for each unique combination of sales representative and fiscal year. \n\nThis query will provide a summary of total sales revenue for each sales representative across different fiscal years as per the data in the table.", "latency_sec": 6.400613069534302, "total_duration_sec": 6.393673466, "load_duration_sec": 0.011774981, "tokens_prompt": 206, "prompt_eval_sec": 0.03247704, "tokens_completion": 255, "completion_eval_sec": 6.348651941, "tokens_total": 461, "tokens_per_sec": 72.02435063514027, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates a running total of Revenue for each SalesRepName ordered by FiscalYear using a window function, while the Generated SQL aggregates Revenue per SalesRepName and FiscalYear. The Reference SQL shows cumulative sums (e.g., 2020: 150000, 2021: 330000 for John Doe), whereas the Generated SQL returns individual year totals (e.g., 2020: 150000, 2021: 180000). The results differ in structure and values.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query uses a window function to calculate a running total per sales representative ordered by fiscal year, which does not match the requirement for 'total revenue for each sales representative by fiscal year.' The generated query correctly groups by SalesRepName and FiscalYear, aggregating Revenue with SUM(), which directly answers the question. While both queries return similar columns, their semantic meaning differs: the reference shows cumulative sums while the generated query shows per-year totals. The generated query is both technically correct and aligned with the business intent.", "overall_assessment": "correct"}}
{"example_id": 5452, "sql_complexity": "basic SQL", "prompt": "What is the name of the farms with a size greater than 150 acres located in 'Texas'?", "context": "CREATE TABLE farms (id INT PRIMARY KEY, name VARCHAR(50), size INT, location VARCHAR(50)); INSERT INTO farms (id, name, size, location) VALUES (1, 'Smith Farms', 200, 'Texas'), (2, 'Johnson Farms', 100, 'California');", "reference_sql": "SELECT name FROM farms WHERE size > 150 AND location = 'Texas'", "generated_sql": "SELECT name \nFROM farms \nWHERE size > 150 AND location = 'Texas';", "raw_model_output": "To find the names of the farms that have a size greater than 150 acres and are located in Texas, you can use the following SQL query:\n\n```sql\nSELECT name \nFROM farms \nWHERE size > 150 AND location = 'Texas';\n```\n\nThis query selects the `name` column from the `farms` table where the `size` is greater than 150 and the `location` is 'Texas'.", "latency_sec": 2.1738550662994385, "total_duration_sec": 2.169058391, "load_duration_sec": 0.019672289, "tokens_prompt": 154, "prompt_eval_sec": 0.021110897, "tokens_completion": 87, "completion_eval_sec": 2.127167154, "tokens_total": 241, "tokens_per_sec": 110.862956659873, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries select the 'name' column from the 'farms' table with identical WHERE conditions (size > 150 AND location = 'Texas'). The only differences are formatting (line breaks and spacing) which do not affect semantic meaning.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are syntactically correct and semantically identical. They select the 'name' column from the 'farms' table where 'size' exceeds 150 and 'location' is 'Texas'. The only difference is formatting (line breaks in the generated query), which does not affect execution. Both fulfill the business intent of identifying farms meeting the specified criteria. Neither query is more efficient or elegant than the other.", "overall_assessment": "correct"}}
{"example_id": 5152, "sql_complexity": "aggregation", "prompt": "How many international tourists visited Portugal in 2020, broken down by continent?", "context": "CREATE TABLE international_tourists(tourist_id INT, country TEXT, arrival_year INT, continent TEXT);INSERT INTO international_tourists (tourist_id, country, arrival_year, continent) VALUES (1, 'Spain', 2020, 'Europe'), (2, 'France', 2020, 'Europe'), (3, 'Brazil', 2020, 'South America'), (4, 'United States', 2020, 'North America'), (5, 'China', 2020, 'Asia');", "reference_sql": "SELECT continent, COUNT(*) FROM international_tourists WHERE arrival_year = 2020 GROUP BY continent;", "generated_sql": "SELECT continent, COUNT(tourist_id) AS tourist_count\nFROM international_tourists\nWHERE country = 'Portugal' AND arrival_year = 2020\nGROUP BY continent;", "raw_model_output": "To answer the question of how many international tourists visited Portugal in 2020, broken down by continent, we need to query the `international_tourists` table. However, since there are no records for Portugal in the provided data, the result will be zero for each continent.\n\nHere's the SQL statement that would achieve this:\n\n```sql\nSELECT continent, COUNT(tourist_id) AS tourist_count\nFROM international_tourists\nWHERE country = 'Portugal' AND arrival_year = 2020\nGROUP BY continent;\n```\n\nThis query filters tourists who visited Portugal in 2020 and groups them by continent to count the number of tourists for each continent. Given the data, the result will show zero counts for all continents.", "latency_sec": 3.78769588470459, "total_duration_sec": 3.782764262, "load_duration_sec": 0.011501048, "tokens_prompt": 197, "prompt_eval_sec": 0.03272317, "tokens_completion": 151, "completion_eval_sec": 3.737681624, "tokens_total": 348, "tokens_per_sec": 91.87643638584812, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query counts all tourists in 2020 by continent, while the generated query only includes tourists from 'Portugal' (which doesn't exist in the sample data) and 2020. The generated query's WHERE clause filters for a specific country not present in the dataset, resulting in no rows returned. The reference query would return counts for all continents with tourists in 2020.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL correctly groups all 2020 tourists by continent without filtering, while the Generated SQL incorrectly filters for 'Portugal' as the tourist's country (not destination) and would return zero results given the sample data. The original question asks for tourists who visited Portugal, but the schema's 'country' column likely represents origin, not destination. Neither query fully addresses this ambiguity, but the Reference SQL at least answers the broader 'international tourists in 2020' question.", "overall_assessment": "differently_correct"}}
{"example_id": 2477, "sql_complexity": "set operations", "prompt": "What is the carbon price in Europe and Australia for the last quarter of 2020?", "context": "CREATE TABLE CarbonPrices (Country TEXT, Year INT, Quarter INT, CarbonPrice NUMBER); INSERT INTO CarbonPrices (Country, Year, Quarter, CarbonPrice) VALUES ('Europe', 2020, 4, 25), ('Australia', 2020, 4, 15); CREATE TABLE CarbonTaxes (Country TEXT, Year INT, Quarter INT, CarbonPrice NUMBER); INSERT INTO CarbonTaxes (Country, Year, Quarter, CarbonPrice) VALUES ('Europe', 2019, 4, 20), ('Australia', 2019, 4, 10);", "reference_sql": "SELECT Context.Country, Context.CarbonPrice FROM ( SELECT * FROM CarbonPrices WHERE CarbonPrices.Country IN ('Europe', 'Australia') AND CarbonPrices.Year = 2020 AND CarbonPrices.Quarter = 4 UNION SELECT * FROM CarbonTaxes WHERE CarbonTaxes.Country IN ('Europe', 'Australia') AND CarbonTaxes.Year = 2020 AND CarbonTaxes.Quarter = 4 ) AS Context;", "generated_sql": "SELECT Country, Year, Quarter, CarbonPrice \nFROM CarbonPrices \nWHERE Country IN ('Europe', 'Australia') AND Year = 2020 AND Quarter = 4\n\nUNION ALL\n\nSELECT Country, Year, Quarter, CarbonPrice \nFROM CarbonTaxes \nWHERE Country IN ('Europe', 'Australia') AND Year = 2020 AND Quarter = 4;", "raw_model_output": "To find the carbon price in Europe and Australia for the last quarter of 2020, we need to query both `CarbonPrices` and `CarbonTaxes` tables. Since the question specifically asks about the year 2020 and the last quarter (which is Quarter 4), we will filter based on these conditions.\n\nHere's the SQL statement that retrieves this information:\n\n```sql\nSELECT Country, Year, Quarter, CarbonPrice \nFROM CarbonPrices \nWHERE Country IN ('Europe', 'Australia') AND Year = 2020 AND Quarter = 4\n\nUNION ALL\n\nSELECT Country, Year, Quarter, CarbonPrice \nFROM CarbonTaxes \nWHERE Country IN ('Europe', 'Australia') AND Year = 2020 AND Quarter = 4;\n```\n\nThis query does the following:\n- Selects records from `CarbonPrices` where the country is either Europe or Australia, and the year is 2020 with quarter 4.\n- Uses `UNION ALL` to include results from `CarbonTaxes` under the same conditions. \n- The use of `UNION ALL` ensures that all matching entries are included even if they appear in both tables (though based on the provided data, there won't be duplicates for this specific query).", "latency_sec": 6.387933015823364, "total_duration_sec": 6.382753422, "load_duration_sec": 0.011519729, "tokens_prompt": 210, "prompt_eval_sec": 0.032763316, "tokens_completion": 255, "completion_eval_sec": 6.337290121, "tokens_total": 465, "tokens_per_sec": 72.79349968889184, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in selected columns. The Reference SQL selects only 'Country' and 'CarbonPrice', while the Generated SQL includes 'Country', 'Year', 'Quarter', and 'CarbonPrice'. This results in different output structures, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent because the reference SQL returns only 'Country' and 'CarbonPrice' columns, while the generated SQL includes additional 'Year' and 'Quarter' columns. Both queries correctly retrieve the carbon prices for Europe and Australia in Q4 2020 from the CarbonPrices table. However, the reference SQL explicitly filters out irrelevant data (e.g., 2019 data in CarbonTaxes) and avoids unnecessary columns, making it more aligned with the business intent. The generated SQL's use of UNION ALL is slightly less efficient than UNION (though negligible here) and includes extraneous fields. Both fulfill the intent, but the reference query is more precise.", "overall_assessment": "correct"}}
{"example_id": 4573, "sql_complexity": "subqueries", "prompt": "Find the names of all the indigenous communities in the 'Arctic_Communities' table that have a population size greater than the average population size in the 'Antarctic_Communities' table.", "context": "CREATE TABLE Arctic_Communities (name TEXT, population INTEGER); CREATE TABLE Antarctic_Communities (name TEXT, population INTEGER);", "reference_sql": "SELECT name FROM Arctic_Communities WHERE Arctic_Communities.population > (SELECT AVG(population) FROM Antarctic_Communities)", "generated_sql": "SELECT name \nFROM Arctic_Communities\nWHERE population > (\n    SELECT AVG(population) \n    FROM Antarctic_Communities\n);", "raw_model_output": "To solve this problem, we need to perform the following steps:\n\n1. Calculate the average population size from the `Antarctic_Communities` table.\n2. Use this average value to filter communities in the `Arctic_Communities` table that have a population greater than this average.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT name \nFROM Arctic_Communities\nWHERE population > (\n    SELECT AVG(population) \n    FROM Antarctic_Communities\n);\n```\n\n### Explanation:\n- The subquery `(SELECT AVG(population) FROM Antarctic_Communities)` calculates the average population of all communities in the `Antarctic_Communities` table.\n- The main query selects the names from the `Arctic_Communities` table where their population is greater than this calculated average.", "latency_sec": 3.991859197616577, "total_duration_sec": 3.985092297, "load_duration_sec": 0.011779335, "tokens_prompt": 135, "prompt_eval_sec": 0.016408524, "tokens_completion": 162, "completion_eval_sec": 3.956159673, "tokens_total": 297, "tokens_per_sec": 74.40142181801654, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select names from Arctic_Communities where population exceeds the average population of Antarctic_Communities. The Generated SQL omits the table qualifier in the WHERE clause, but since the column 'population' is unambiguous (only exists in Arctic_Communities in the main query), the semantic meaning remains identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they produce identical results by comparing Arctic_Communities' population to the average population from Antarctic_Communities. The reference query explicitly qualifies the population column with the table name, while the generated query relies on column uniqueness. Both correctly fulfill the business intent by addressing the population comparison requirement. The generated query is slightly more concise but neither demonstrates superior efficiency or elegance. The semantic equivalence is confirmed by identical subquery logic and result set structure.", "overall_assessment": "correct"}}
{"example_id": 3596, "sql_complexity": "window functions", "prompt": "What is the total revenue for each game in the \"Gaming\" category?", "context": "CREATE TABLE Games (GameID int, GameName varchar(50), Category varchar(50), Revenue decimal(10,2));", "reference_sql": "SELECT Category, SUM(Revenue) OVER(PARTITION BY Category) as TotalRevenue FROM Games;", "generated_sql": "SELECT GameName, SUM(Revenue) AS TotalRevenue\nFROM Games\nWHERE Category = 'Gaming'\nGROUP BY GameName;", "raw_model_output": "To find the total revenue for each game in the \"Gaming\" category from the `Games` table, you can use the following SQL query:\n\n```sql\nSELECT GameName, SUM(Revenue) AS TotalRevenue\nFROM Games\nWHERE Category = 'Gaming'\nGROUP BY GameName;\n```\n\nThis query performs the following operations:\n- Filters the rows where the `Category` is \"Gaming\".\n- Groups the results by `GameName`.\n- Calculates the sum of `Revenue` for each group, giving you the total revenue per game in the specified category.", "latency_sec": 2.8900668621063232, "total_duration_sec": 2.88502708, "load_duration_sec": 0.027297776, "tokens_prompt": 114, "prompt_eval_sec": 0.01844757, "tokens_completion": 117, "completion_eval_sec": 2.837068614, "tokens_total": 231, "tokens_per_sec": 79.92894663746422, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The reference query calculates the total revenue per category for each row using a window function, while the generated query filters to only 'Gaming' category, groups by GameName, and sums revenue per game. The output columns, aggregation logic, and filtering differ significantly.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL calculates the total revenue per category (not per game) using a window function, which would show the same category total for every game in 'Gaming'. The Generated SQL correctly groups by GameName and sums revenue for each individual game in the 'Gaming' category. While the Generated SQL might not handle multiple revenue entries per game (if that's the case), it aligns with the explicit request for 'each game' revenue. The Reference SQL fails to address the per-game requirement.", "overall_assessment": "differently_correct"}}
{"example_id": 5039, "sql_complexity": "subqueries", "prompt": "What is the total number of community policing events in 'City Park' in 2021?", "context": "CREATE TABLE locations (id INT, name VARCHAR(255)); CREATE TABLE community_policing (id INT, location_id INT, year INT, events INT); INSERT INTO locations (id, name) VALUES (1, 'City Park'); INSERT INTO community_policing (id, location_id, year, events) VALUES (1, 1, 2021, 5);", "reference_sql": "SELECT SUM(events) FROM community_policing WHERE location_id = (SELECT id FROM locations WHERE name = 'City Park') AND year = 2021;", "generated_sql": "SELECT SUM(cp.events) AS total_events\nFROM community_policing cp\nJOIN locations l ON cp.location_id = l.id\nWHERE l.name = 'City Park' AND cp.year = 2021;", "raw_model_output": "To find the total number of community policing events in 'City Park' for the year 2021, you need to join the `locations` and `community_policing` tables on their respective location identifiers. Then, filter by the name of the location ('City Park') and the specific year (2021). Finally, sum up the number of events.\n\nHere is the SQL query that accomplishes this:\n\n```sql\nSELECT SUM(cp.events) AS total_events\nFROM community_policing cp\nJOIN locations l ON cp.location_id = l.id\nWHERE l.name = 'City Park' AND cp.year = 2021;\n```\n\nThis query joins the `community_policing` table (`cp`) with the `locations` table (`l`) using the `location_id`. It then filters for records where the location name is 'City Park' and the year is 2021, summing up the events to get the total number of community policing events.", "latency_sec": 4.921747922897339, "total_duration_sec": 4.91726287, "load_duration_sec": 0.019301233, "tokens_prompt": 169, "prompt_eval_sec": 0.023301154, "tokens_completion": 198, "completion_eval_sec": 4.874057228, "tokens_total": 367, "tokens_per_sec": 74.56700459863335, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the sum of events for 'City Park' in 2021. The reference uses a subquery to get the location_id, while the generated query uses a JOIN. Both filter the same conditions (location name and year) and aggregate the same column (events). The result will be identical given the schema and sample data.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the total community policing events in 'City Park' for 2021. The reference query uses a subquery to get the location_id, while the generated query uses an explicit JOIN. Technically, they produce identical results given the data constraints (unique location name). However, the generated query is more readable, uses standard JOIN syntax, and avoids potential issues with subquery scalar returns. It also explicitly aliases tables, improving clarity. Both fulfill the business intent, but the generated version is more elegant and efficient.", "overall_assessment": "correct"}}
{"example_id": 2724, "sql_complexity": "basic SQL", "prompt": "What is the earliest installation date for solar panels in Italy?", "context": "CREATE TABLE solar_panels_italy (id INT, installation_date DATE); INSERT INTO solar_panels_italy (id, installation_date) VALUES (1, '2018-01-01'), (2, '2019-01-01'), (3, '2020-01-01');", "reference_sql": "SELECT MIN(installation_date) as earliest_date FROM solar_panels_italy;", "generated_sql": "SELECT MIN(installation_date) AS earliest_installation_date\nFROM solar_panels_italy;", "raw_model_output": "To find the earliest installation date for solar panels in Italy from the `solar_panels_italy` table, you can use the following SQL query:\n\n```sql\nSELECT MIN(installation_date) AS earliest_installation_date\nFROM solar_panels_italy;\n```\n\nThis query uses the `MIN()` aggregate function to determine the smallest (earliest) date in the `installation_date` column. The result is aliased as `earliest_installation_date` for clarity.", "latency_sec": 2.6165688037872314, "total_duration_sec": 2.61192618, "load_duration_sec": 0.020316403, "tokens_prompt": 148, "prompt_eval_sec": 0.01943866, "tokens_completion": 101, "completion_eval_sec": 2.571358267, "tokens_total": 249, "tokens_per_sec": 95.16279474080578, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries select the minimum installation_date from the same table. The only difference is the column alias name ('earliest_date' vs 'earliest_installation_date'), which does not affect the semantic result. The MIN() function operates on the same column and table in both queries.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly retrieve the earliest installation date using MIN(installation_date). The only difference is the column alias name ('earliest_date' vs 'earliest_installation_date'), which doesn't affect technical correctness or business intent fulfillment. The queries are semantically identical and equally efficient, as they both perform a minimalistic aggregation on the same column. The choice between aliases is purely stylistic and doesn't impact the result's accuracy or relevance to the original question.", "overall_assessment": "correct"}}
{"example_id": 2200, "sql_complexity": "single join", "prompt": "Which diversity programs are currently being participated in by employees in the HR department?", "context": "CREATE TABLE Employees (Employee_ID INT, First_Name VARCHAR(20), Last_Name VARCHAR(20), Department VARCHAR(20), Salary DECIMAL(10,2), Date_Hired DATE); CREATE TABLE Diversity_Programs (Program_ID INT, Program_Name VARCHAR(50), Participant_ID INT, Date_Started DATE, Date_Ended DATE);", "reference_sql": "SELECT dp.Program_Name FROM Diversity_Programs dp JOIN Employees e ON dp.Participant_ID = e.Employee_ID WHERE e.Department = 'HR' AND dp.Date_Ended IS NULL;", "generated_sql": "SELECT DISTINCT dp.Program_ID, dp.Program_Name\nFROM Diversity_Programs dp\nJOIN Employees e ON dp.Participant_ID = e.Employee_ID\nWHERE e.Department = 'HR'\n  AND CURRENT_DATE BETWEEN dp.Date_Started AND dp.Date_Ended;", "raw_model_output": "To find which diversity programs are currently being participated in by employees in the HR department, we need to join the `Employees` and `Diversity_Programs` tables based on employee participation. We will filter for employees who belong to the \"HR\" department and check if the current date falls between the `Date_Started` and `Date_Ended` of each program.\n\nHere is the SQL query:\n\n```sql\nSELECT DISTINCT dp.Program_ID, dp.Program_Name\nFROM Diversity_Programs dp\nJOIN Employees e ON dp.Participant_ID = e.Employee_ID\nWHERE e.Department = 'HR'\n  AND CURRENT_DATE BETWEEN dp.Date_Started AND dp.Date_Ended;\n```\n\nThis query performs the following steps:\n- Joins `Diversity_Programs` (`dp`) with `Employees` (`e`) on the condition that the `Participant_ID` in `Diversity_Programs` matches the `Employee_ID` in `Employees`.\n- Filters for employees who are part of the \"HR\" department.\n- Checks if the current date is between the `Date_Started` and `Date_Ended` to ensure the program is currently active.\n- Uses `DISTINCT` to avoid duplicate entries for programs with multiple participants from the HR department.", "latency_sec": 6.56725811958313, "total_duration_sec": 6.562464401, "load_duration_sec": 0.010454239, "tokens_prompt": 155, "prompt_eval_sec": 0.021886749, "tokens_completion": 252, "completion_eval_sec": 6.529344386, "tokens_total": 407, "tokens_per_sec": 61.9741134867766, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in two key aspects. First, the Reference SQL selects only 'Program_Name' while the Generated SQL selects 'Program_ID' and 'Program_Name' (different column sets). Second, the filtering conditions differ: the Reference checks for 'Date_Ended IS NULL' (indicating ongoing programs), while the Generated uses 'CURRENT_DATE BETWEEN Date_Started AND Date_Ended' (checking if the current date falls within the program's active period). These differences in columns and logic make the queries non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries differ in their logic for determining 'current' participation. The reference query correctly uses `Date_Ended IS NULL` to identify ongoing programs, which is a standard approach for tracking active records. The generated query uses `CURRENT_DATE BETWEEN dp.Date_Started AND dp.Date_Ended`, which would exclude programs with NULL end dates (a common scenario for ongoing programs) and requires the end date to be explicitly set. While the generated query avoids duplicates with `DISTINCT`, it fails to account for NULL end dates, making it less accurate for the business intent. The reference query directly answers the question by focusing on active programs without date range assumptions.", "overall_assessment": "correct"}}
{"example_id": 4359, "sql_complexity": "window functions", "prompt": "Which destinations have the least hotel awards?", "context": "CREATE TABLE Destinations (destination_id INT, destination_name TEXT, country TEXT, awards INT); INSERT INTO Destinations (destination_id, destination_name, country, awards) VALUES (1, 'City A', 'Germany', 3), (2, 'City B', 'Switzerland', 5), (3, 'City C', 'Norway', 2);", "reference_sql": "SELECT destination_name, country, awards, RANK() OVER (PARTITION BY country ORDER BY awards ASC) AS rank FROM Destinations;", "generated_sql": "SELECT destination_id, destination_name, country, awards\nFROM Destinations\nWHERE awards = (SELECT MIN(awards) FROM Destinations);", "raw_model_output": "To find the destinations with the least number of hotel awards from the `Destinations` table, we need to identify the minimum value in the `awards` column and then select all rows that match this minimum value. Here is the SQL statement to achieve this:\n\n```sql\nSELECT destination_id, destination_name, country, awards\nFROM Destinations\nWHERE awards = (SELECT MIN(awards) FROM Destinations);\n```\n\nThis query works as follows:\n- The subquery `(SELECT MIN(awards) FROM Destinations)` calculates the minimum number of awards among all destinations.\n- The main query selects all columns (`destination_id`, `destination_name`, `country`, and `awards`) from the `Destinations` table where the `awards` value matches this minimum value.", "latency_sec": 4.211065769195557, "total_duration_sec": 4.205473392, "load_duration_sec": 0.016480968, "tokens_prompt": 156, "prompt_eval_sec": 0.023996001, "tokens_completion": 161, "completion_eval_sec": 4.163989199, "tokens_total": 317, "tokens_per_sec": 75.27785538732081, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates ranks within country partitions based on awards, returning all destinations with their respective ranks. The Generated SQL filters to only destinations with the minimum awards globally, returning a subset of rows. The result sets differ in both content (all rows vs. subset) and structure (includes rank column vs. not).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query ranks destinations by awards within each country, which does not directly answer the question about the absolute least awards across all destinations. The generated query correctly identifies destinations with the minimum awards value using a subquery, aligning with the business intent. While both are technically valid, the generated query is more efficient and directly addresses the question without unnecessary complexity.", "overall_assessment": "correct"}}
{"example_id": 1373, "sql_complexity": "subqueries", "prompt": "What is the total value of military equipment sales to Africa in the last 12 months?", "context": "CREATE TABLE Military_Equipment_Sales(sale_id INT, sale_date DATE, equipment_type VARCHAR(50), country VARCHAR(50), sale_value DECIMAL(10,2));", "reference_sql": "SELECT SUM(sale_value) FROM Military_Equipment_Sales WHERE country IN (SELECT country FROM World_Countries WHERE continent = 'Africa') AND sale_date >= DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH);", "generated_sql": "SELECT SUM(sale_value) AS total_sales_to_africa\nFROM Military_Equipment_Sales\nWHERE country IN (\n    'Algeria', 'Angola', 'Benin', 'Botswana', 'Burkina Faso', 'Burundi',\n    'Cabo Verde', 'Cameroon', 'Central African Republic', 'Chad', 'Comoros',\n    'Democratic Republic of the Congo', 'Republic of the Congo', 'Djibouti',\n    'Egypt', 'Equatorial Guinea', 'Eritrea', 'Ethiopia', 'Gabon', 'Gambia',\n    'Ghana', 'Guinea', 'Guinea-Bissau', 'Ivory Coast', 'Kenya', 'Lesotho',\n    'Liberia', 'Libya', 'Madagascar', 'Malawi', 'Mali', 'Mauritania',\n    'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Niger', 'Nigeria',\n    'Republic of the Sudan', 'Rwanda', 'Sao Tome and Principe', 'Senegal',\n    'Seychelles', 'Sierra Leone', 'Somalia', 'South Africa', 'South Sudan',\n    'Swaziland', 'Tanzania', 'Togo', 'Tunisia', 'Uganda', 'Zambia', 'Zimbabwe'\n)\nAND sale_date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH);", "raw_model_output": "To calculate the total value of military equipment sales to African countries over the past 12 months, we need to identify which countries are considered part of Africa. Assuming you have a predefined list of African countries or can determine them based on your context, here's how you could write the SQL query:\n\n```sql\nSELECT SUM(sale_value) AS total_sales_to_africa\nFROM Military_Equipment_Sales\nWHERE country IN (\n    'Algeria', 'Angola', 'Benin', 'Botswana', 'Burkina Faso', 'Burundi',\n    'Cabo Verde', 'Cameroon', 'Central African Republic', 'Chad', 'Comoros',\n    'Democratic Republic of the Congo', 'Republic of the Congo', 'Djibouti',\n    'Egypt', 'Equatorial Guinea', 'Eritrea', 'Ethiopia', 'Gabon', 'Gambia',\n    'Ghana', 'Guinea', 'Guinea-Bissau', 'Ivory Coast', 'Kenya', 'Lesotho',\n    'Liberia', 'Libya', 'Madagascar', 'Malawi', 'Mali', 'Mauritania',\n    'Mauritius', 'Morocco', 'Mozambique', 'Namibia', 'Niger', 'Nigeria',\n    'Republic of the Sudan', 'Rwanda', 'Sao Tome and Principe', 'Senegal',\n    'Seychelles', 'Sierra Leone', 'Somalia', 'South Africa', 'South Sudan',\n    'Swaziland', 'Tanzania', 'Togo', 'Tunisia', 'Uganda', 'Zambia', 'Zimbabwe'\n)\nAND sale_date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH);\n```\n\n### Explanation:\n- **SUM(sale_value)**: This function calculates the total sales value.\n- **WHERE country IN (...)**: Filters the records to include only those where the `country` is one of the listed African countries. You should replace this list with an accurate and complete list if necessary.\n- **AND sale_date >= DATE_SUB(CURDATE(), INTERVAL 12 MONTH)**: Ensures that only sales within the last 12 months are considered, using MySQL's date functions to calculate the date range.\n\nNote: The `DATE_SUB` function is specific to MySQL. If you're using a different SQL dialect (like PostgreSQL or SQL Server), you might need to adjust this part of the query accordingly:\n\n- For **PostgreSQL**, use:\n  ```sql\n  AND sale_date >= CURRENT_DATE - INTERVAL '12 months'\n  ```\n\n- For **SQL Server**, use:\n  ```sql\n  AND sale_date >= DATEADD(MONTH, -12, GETDATE())\n  ```", "latency_sec": 15.058212757110596, "total_duration_sec": 15.053382414, "load_duration_sec": 0.011338924, "tokens_prompt": 126, "prompt_eval_sec": 0.017252963, "tokens_completion": 578, "completion_eval_sec": 15.024063411, "tokens_total": 704, "tokens_per_sec": 46.75189621474608, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses a subquery to dynamically fetch African countries from World_Countries, while the Generated SQL hardcodes a specific list of countries. Unless the World_Countries table exactly matches the hardcoded list (including identical country names and completeness), the queries may return different results. The semantic equivalence cannot be guaranteed without knowing the contents of World_Countries.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries correctly calculate the total military equipment sales to Africa in the last 12 months. The reference query uses a subquery to dynamically fetch African countries from World_Countries, ensuring accuracy if the reference data is up-to-date. The generated query hardcodes country names, which is functionally equivalent if the list is complete and accurate. However, the reference query is more maintainable and less error-prone, as it relies on a centralized reference table rather than a static list. Both handle date filtering correctly with DATE_SUB(CURRENT_DATE, INTERVAL 12 MONTH). The reference query better fulfills business intent by decoupling from hardcoded values, making it more adaptable to geographic changes.", "overall_assessment": "correct"}}
{"example_id": 904, "sql_complexity": "basic SQL", "prompt": "What is the minimum Shariah-compliant loan amount issued in the last quarter of 2021?", "context": "CREATE TABLE loans (id INT, amount DECIMAL, date DATE, loan_type VARCHAR); INSERT INTO loans (id, amount, date, loan_type) VALUES (1, 5000, '2021-09-05', 'Shariah-compliant'), (2, 7000, '2021-10-07', 'socially responsible'), (3, 9000, '2021-11-03', 'Shariah-compliant'), (4, 11000, '2021-12-31', 'Shariah-compliant');", "reference_sql": "SELECT MIN(amount) FROM loans WHERE EXTRACT(YEAR FROM date) = 2021 AND EXTRACT(QUARTER FROM date) = 4 AND loan_type = 'Shariah-compliant';", "generated_sql": "SELECT MIN(amount) AS min_shariah_compliant_loan_amount\nFROM loans\nWHERE loan_type = 'Shariah-compliant'\nAND date BETWEEN '2021-10-01' AND '2021-12-31';", "raw_model_output": "To find the minimum Shariah-compliant loan amount issued in the last quarter of 2021, we need to filter the loans based on two criteria: the `loan_type` being 'Shariah-compliant' and the `date` falling within the last quarter of 2021 (i.e., between October 1, 2021, and December 31, 2021). Then, we will find the minimum amount from these filtered results.\n\nHere is the SQL statement to achieve this:\n\n```sql\nSELECT MIN(amount) AS min_shariah_compliant_loan_amount\nFROM loans\nWHERE loan_type = 'Shariah-compliant'\nAND date BETWEEN '2021-10-01' AND '2021-12-31';\n```\n\nThis query selects the minimum `amount` from the `loans` table where the `loan_type` is 'Shariah-compliant' and the `date` falls within the specified range for the last quarter of 2021.", "latency_sec": 5.408139944076538, "total_duration_sec": 5.400161957, "load_duration_sec": 0.021820146, "tokens_prompt": 210, "prompt_eval_sec": 0.035987793, "tokens_completion": 204, "completion_eval_sec": 5.340952108, "tokens_total": 414, "tokens_per_sec": 76.55127350272224, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries filter for 'Shariah-compliant' loans in the fourth quarter of 2021. The reference query uses EXTRACT(QUARTER) = 4, which corresponds to October-December, while the generated query uses a date range from '2021-10-01' to '2021-12-31'. These conditions are equivalent for the given data, as both capture the same quarter and year. The MIN(amount) calculation will yield the same result (9000) in both cases.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly identify the minimum Shariah-compliant loan amount in Q4 2021. The reference query uses EXTRACT() to filter by year and quarter, while the generated query uses a date range. Both approaches yield the same results, but the generated query is more efficient due to direct date comparison (which can leverage indexes) and avoids potential edge cases with EXTRACT() (e.g., leap years, time zones). The generated query also has clearer date boundaries for the quarter. Both fulfill the business intent, but the generated version is more elegant and performant.", "overall_assessment": "correct"}}
{"example_id": 3299, "sql_complexity": "set operations", "prompt": "How many schools and hospitals are there in Colombia and which ones need repairs?", "context": "CREATE TABLE schools (id INT, country VARCHAR(20), name VARCHAR(50), needs_repair BOOLEAN); CREATE TABLE hospitals (id INT, country VARCHAR(20), name VARCHAR(50), needs_repair BOOLEAN);", "reference_sql": "SELECT 'Schools' as facility_type, COUNT(*) as total, SUM(needs_repair) as repairs_needed FROM schools WHERE country = 'Colombia' UNION ALL SELECT 'Hospitals' as facility_type, COUNT(*) as total, SUM(needs_repair) as repairs_needed FROM hospitals WHERE country = 'Colombia';", "generated_sql": "SELECT \n    'School' AS institution_type,\n    COUNT(*) AS total_count,\n    SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\nFROM schools\nWHERE country = 'Colombia'\n\nUNION ALL\n\nSELECT \n    'Hospital' AS institution_type,\n    COUNT(*) AS total_count,\n    SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\nFROM hospitals\nWHERE country = 'Colombia';\n\nWITH combined AS (\n    SELECT \n        institution_type, \n        total_count, \n        repair_needed_count\n    FROM (\n        SELECT \n            'School' AS institution_type,\n            COUNT(*) AS total_count,\n            SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\n        FROM schools\n        WHERE country = 'Colombia'\n\n        UNION ALL\n\n        SELECT \n            'Hospital' AS institution_type,\n            COUNT(*) AS total_count,\n            SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\n        FROM hospitals\n        WHERE country = 'Colombia'\n    ) AS subquery\n)\n\nSELECT * FROM combined;\n\nWITH schools_in_colombia AS (\n    SELECT name, needs_repair \n    FROM schools \n    WHERE country = 'Colombia'\n),\nhospitals_in_colombia AS (\n    SELECT name, needs_repair \n    FROM hospitals \n    WHERE country = 'Colombia'\n)\n\nSELECT 'School' AS institution_type, name, needs_repair\nFROM schools_in_colombia\n\nUNION ALL\n\nSELECT 'Hospital' AS institution_type, name, needs_repair\nFROM hospitals_in_colombia;", "raw_model_output": "To answer the question of how many schools and hospitals are there in Colombia and which ones need repairs, we can use a UNION to combine results from both tables. We will count the total number of each type (schools and hospitals) and list those that need repairs.\n\nHere's the SQL statement:\n\n```sql\nSELECT \n    'School' AS institution_type,\n    COUNT(*) AS total_count,\n    SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\nFROM schools\nWHERE country = 'Colombia'\n\nUNION ALL\n\nSELECT \n    'Hospital' AS institution_type,\n    COUNT(*) AS total_count,\n    SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\nFROM hospitals\nWHERE country = 'Colombia';\n\nWITH combined AS (\n    SELECT \n        institution_type, \n        total_count, \n        repair_needed_count\n    FROM (\n        SELECT \n            'School' AS institution_type,\n            COUNT(*) AS total_count,\n            SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\n        FROM schools\n        WHERE country = 'Colombia'\n\n        UNION ALL\n\n        SELECT \n            'Hospital' AS institution_type,\n            COUNT(*) AS total_count,\n            SUM(CASE WHEN needs_repair THEN 1 ELSE 0 END) AS repair_needed_count\n        FROM hospitals\n        WHERE country = 'Colombia'\n    ) AS subquery\n)\n\nSELECT * FROM combined;\n\nWITH schools_in_colombia AS (\n    SELECT name, needs_repair \n    FROM schools \n    WHERE country = 'Colombia'\n),\nhospitals_in_colombia AS (\n    SELECT name, needs_repair \n    FROM hospitals \n    WHERE country = 'Colombia'\n)\n\nSELECT 'School' AS institution_type, name, needs_repair\nFROM schools_in_colombia\n\nUNION ALL\n\nSELECT 'Hospital' AS institution_type, name, needs_repair\nFROM hospitals_in_colombia;\n```\n\nThis SQL script consists of two parts:\n\n1. The first part uses a `UNION ALL` to combine the counts and repair statuses for both schools and hospitals in Colombia.\n2. The second part lists all schools and hospitals in Colombia along with their repair status using another `UNION ALL`. \n\nThe results will provide you with the total count of each type of institution, how many need repairs, and a detailed list of which specific institutions require repairs.", "latency_sec": 13.291563034057617, "total_duration_sec": 13.28386709, "load_duration_sec": 0.010855971, "tokens_prompt": 131, "prompt_eval_sec": 0.01990704, "tokens_completion": 510, "completion_eval_sec": 13.252311723, "tokens_total": 641, "tokens_per_sec": 48.22608133878119, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL and Generated SQL are not semantically equivalent. While the first part of the Generated SQL (the two SELECTs with UNION ALL) is structurally similar to the Reference SQL, the Generated SQL includes additional queries (CTEs and a final UNION ALL selecting name/needs_repair) that return different data. The Reference SQL aggregates counts and repairs_needed, while the later parts of the Generated SQL return individual records, leading to different result structures and content.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL correctly counts total facilities and repairs needed but fails to identify specific facilities requiring repairs. The Generated SQL includes three components: 1) A count-based query equivalent to the Reference, 2) A CTE wrapper that doesn't add value, and 3) A critical query that lists individual facilities (with names) needing repairs. The third component directly addresses the 'which ones' part of the question, making the Generated SQL more comprehensive. While the Reference SQL is technically correct, the Generated SQL better fulfills the business intent by providing both aggregate data and specific facility details.", "overall_assessment": "differently_correct"}}
{"example_id": 907, "sql_complexity": "set operations", "prompt": "What is the total quantity of items with type 'E' or type 'F' in warehouse O and warehouse P?", "context": "CREATE TABLE warehouse_o(item_id INT, item_type VARCHAR(10), quantity INT);CREATE TABLE warehouse_p(item_id INT, item_type VARCHAR(10), quantity INT);INSERT INTO warehouse_o(item_id, item_type, quantity) VALUES (1, 'E', 200), (2, 'F', 300), (3, 'E', 50), (4, 'F', 400);INSERT INTO warehouse_p(item_id, item_type, quantity) VALUES (1, 'E', 150), (2, 'F', 250), (3, 'E', 40), (4, 'F', 350);", "reference_sql": "SELECT quantity FROM warehouse_o WHERE item_type IN ('E', 'F') UNION ALL SELECT quantity FROM warehouse_p WHERE item_type IN ('E', 'F');", "generated_sql": "SELECT SUM(quantity) AS total_quantity\nFROM (\n    SELECT quantity FROM warehouse_o WHERE item_type IN ('E', 'F')\n    UNION ALL\n    SELECT quantity FROM warehouse_p WHERE item_type IN ('E', 'F')\n) AS combined_warehouses;", "raw_model_output": "To find the total quantity of items with type 'E' or type 'F' across both warehouses O and P, you can use a `UNION ALL` to combine the data from both tables and then sum up the quantities for the specified item types. Here's how you can write the SQL query:\n\n```sql\nSELECT SUM(quantity) AS total_quantity\nFROM (\n    SELECT quantity FROM warehouse_o WHERE item_type IN ('E', 'F')\n    UNION ALL\n    SELECT quantity FROM warehouse_p WHERE item_type IN ('E', 'F')\n) AS combined_warehouses;\n```\n\nThis query works as follows:\n- The subquery selects quantities from `warehouse_o` where the `item_type` is either 'E' or 'F'.\n- It does the same for `warehouse_p`.\n- These results are combined using `UNION ALL`, which includes all rows (unlike `UNION`, which removes duplicates).\n- Finally, the outer query sums up all the quantities from this combined result to get the total quantity of items with type 'E' or 'F'.", "latency_sec": 5.900722980499268, "total_duration_sec": 5.89245055, "load_duration_sec": 0.012449422, "tokens_prompt": 228, "prompt_eval_sec": 0.048997267, "tokens_completion": 220, "completion_eval_sec": 5.829602017, "tokens_total": 448, "tokens_per_sec": 75.92289986846563, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns a list of individual quantities from both tables using UNION ALL, while the Generated SQL aggregates all quantities into a single sum. The first produces multiple rows of values, the second produces one row with a total, so they cannot produce the same result.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query returns individual quantities from both warehouses without aggregation, while the generated query properly sums all qualifying quantities. The original question explicitly asks for 'total quantity,' which requires aggregation. The reference query would return 8 rows of individual quantities (200, 300, 50, 400, 150, 250, 40, 350) instead of a single total value. The generated query correctly combines these values using SUM() and achieves the business intent of calculating the total.", "overall_assessment": "differently_correct"}}
{"example_id": 1400, "sql_complexity": "single join", "prompt": "What is the maximum co-ownership duration for properties in the neighborhood of 'Chinatown' in San Francisco?'", "context": "CREATE TABLE sf_neighborhoods (neighborhood_id INT, name VARCHAR(255), city VARCHAR(255)); INSERT INTO sf_neighborhoods (neighborhood_id, name, city) VALUES (1, 'Chinatown', 'San Francisco'); CREATE TABLE co_ownership (co_ownership_id INT, property_id INT, co_owner_id INT, start_date DATE, end_date DATE); INSERT INTO co_ownership (co_ownership_id, property_id, co_owner_id, start_date, end_date) VALUES (1, 1, 2, '2010-01-01', '2020-01-01'), (2, 2, 3, '2015-01-01', '2022-01-01'); CREATE TABLE properties (property_id INT, city VARCHAR(255)); INSERT INTO properties (property_id, city) VALUES (1, 'San Francisco'), (2, 'San Francisco');", "reference_sql": "SELECT MAX(DATEDIFF(end_date, start_date)) as max_duration FROM co_ownership JOIN properties ON co_ownership.property_id = properties.property_id WHERE properties.city = 'San Francisco' AND name = 'Chinatown';", "generated_sql": "SELECT MAX(DATEDIFF(end_date, start_date)) AS max_co_ownership_duration\nFROM co_ownership co\nJOIN properties p ON co.property_id = p.property_id\nJOIN sf_neighborhoods n ON p.city = n.city\nWHERE n.name = 'Chinatown' AND n.city = 'San Francisco';", "raw_model_output": "To find the maximum co-ownership duration for properties in the neighborhood of 'Chinatown' in San Francisco, we need to join the relevant tables and calculate the duration of each co-ownership. Here's how you can do it:\n\n```sql\nSELECT MAX(DATEDIFF(end_date, start_date)) AS max_co_ownership_duration\nFROM co_ownership co\nJOIN properties p ON co.property_id = p.property_id\nJOIN sf_neighborhoods n ON p.city = n.city\nWHERE n.name = 'Chinatown' AND n.city = 'San Francisco';\n```\n\n### Explanation:\n\n1. **Join the Tables**: \n   - Join `co_ownership` with `properties` on `property_id`.\n   - Join `properties` with `sf_neighborhoods` on `city`.\n\n2. **Filter by Neighborhood**:\n   - Use a `WHERE` clause to filter properties in 'Chinatown' and city 'San Francisco'.\n\n3. **Calculate Duration**:\n   - Use the `DATEDIFF` function to calculate the duration of each co-ownership period.\n\n4. **Find Maximum Duration**:\n   - Use `MAX()` to find the longest co-ownership duration among the filtered results.", "latency_sec": 6.699708938598633, "total_duration_sec": 6.693031688, "load_duration_sec": 0.016386582, "tokens_prompt": 286, "prompt_eval_sec": 0.044694086, "tokens_completion": 250, "completion_eval_sec": 6.63110166, "tokens_total": 536, "tokens_per_sec": 80.00347551099948, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL references a 'name' column not present in the joined tables (co_ownership and properties), making it invalid. The Generated SQL correctly joins with sf_neighborhoods to access the 'name' column. Additionally, the Generated SQL includes an explicit join with sf_neighborhoods and filters on both n.name and n.city, while the Reference SQL incorrectly assumes 'name' exists in the properties table.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query is technically incorrect because it references 'name' in the WHERE clause without joining the sf_neighborhoods table, which contains the 'name' column. The generated query correctly joins sf_neighborhoods with properties on city and filters by neighborhood name, fulfilling the business intent. While both calculate max duration using DATEDIFF, the reference query would fail due to undefined column 'name'. The generated query properly addresses the requirement to filter properties in 'Chinatown' by linking neighborhoods to properties.", "overall_assessment": "differently_correct"}}
{"example_id": 5248, "sql_complexity": "window functions", "prompt": "Find the top 5 games by rating", "context": "CREATE TABLE games (game_id INT PRIMARY KEY, name VARCHAR(50), genre VARCHAR(50), rating DECIMAL(3,2));", "reference_sql": "SELECT * FROM (SELECT name, rating, ROW_NUMBER() OVER (ORDER BY rating DESC) as rn FROM games) t WHERE rn <= 5;", "generated_sql": "SELECT game_id, name, genre, rating\nFROM games\nORDER BY rating DESC\nLIMIT 5;", "raw_model_output": "To find the top 5 games by rating from the `games` table, you can use an SQL query that orders the rows by the `rating` column in descending order and limits the result to 5 rows. Here is the SQL statement:\n\n```sql\nSELECT game_id, name, genre, rating\nFROM games\nORDER BY rating DESC\nLIMIT 5;\n```\n\nThis query selects all columns (`game_id`, `name`, `genre`, `rating`) from the `games` table and sorts them by the `rating` column in descending order. The `LIMIT 5` clause ensures that only the top 5 rows are returned based on the highest ratings.", "latency_sec": 3.5724971294403076, "total_duration_sec": 3.565481939, "load_duration_sec": 0.017359768, "tokens_prompt": 109, "prompt_eval_sec": 0.015639843, "tokens_completion": 138, "completion_eval_sec": 3.531862569, "tokens_total": 247, "tokens_per_sec": 69.13931377705453, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL selects only 'name' and 'rating' columns with a row number, while the Generated SQL selects all columns (game_id, name, genre, rating). Additionally, the Reference SQL uses a subquery with ROW_NUMBER() while the Generated SQL uses LIMIT, but the core difference lies in the selected columns and output structure.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query uses ROW_NUMBER() to assign ranks and filter top 5, while the generated query uses ORDER BY with LIMIT. Both would return similar results for unique ratings, but the generated query is more efficient and straightforward. The generated query also returns additional columns (game_id, genre) that provide more context for the top games, which better fulfills the business intent of identifying specific games. The reference query's use of a subquery adds unnecessary complexity. Both queries correctly address the intent, but the generated version is more practical and efficient.", "overall_assessment": "differently_correct"}}
{"example_id": 778, "sql_complexity": "single join", "prompt": "What is the maximum property price in wheelchair-accessible neighborhoods in Singapore?", "context": "CREATE TABLE Singapore_Neighborhoods (Neighborhood_Name TEXT, Wheelchair_Accessibility BOOLEAN); INSERT INTO Singapore_Neighborhoods (Neighborhood_Name, Wheelchair_Accessibility) VALUES ('Orchard', true), ('Marina Bay', true), ('Chinatown', false), ('Little India', false), ('Bugis', true); CREATE TABLE Singapore_Properties (Neighborhood_Name TEXT, Property_Price INTEGER); INSERT INTO Singapore_Properties (Neighborhood_Name, Property_Price) VALUES ('Orchard', 2000000), ('Marina Bay', 3000000), ('Chinatown', 1500000), ('Little India', 1200000), ('Bugis', 1800000);", "reference_sql": "SELECT MAX(Singapore_Properties.Property_Price) FROM Singapore_Properties INNER JOIN Singapore_Neighborhoods ON Singapore_Properties.Neighborhood_Name = Singapore_Neighborhoods.Neighborhood_Name WHERE Singapore_Neighborhoods.Wheelchair_Accessibility = true;", "generated_sql": "SELECT MAX(Property_Price) AS Max_Property_Price\nFROM Singapore_Neighborhoods n\nJOIN Singapore_Properties p ON n.Neighborhood_Name = p.Neighborhood_Name\nWHERE n.Wheelchair_Accessibility = TRUE;", "raw_model_output": "To find the maximum property price in wheelchair-accessible neighborhoods, we need to join the `Singapore_Neighborhoods` and `Singapore_Properties` tables on the `Neighborhood_Name` column. We will filter for neighborhoods where `Wheelchair_Accessibility` is true, then select the maximum `Property_Price`.\n\nHere's the SQL statement:\n\n```sql\nSELECT MAX(Property_Price) AS Max_Property_Price\nFROM Singapore_Neighborhoods n\nJOIN Singapore_Properties p ON n.Neighborhood_Name = p.Neighborhood_Name\nWHERE n.Wheelchair_Accessibility = TRUE;\n```\n\nThis query performs an inner join between the two tables on `Neighborhood_Name`, filters for neighborhoods with wheelchair accessibility, and then calculates the maximum property price among those neighborhoods.", "latency_sec": 4.201261043548584, "total_duration_sec": 4.196588674, "load_duration_sec": 0.011558918, "tokens_prompt": 235, "prompt_eval_sec": 0.036708992, "tokens_completion": 157, "completion_eval_sec": 4.14746536, "tokens_total": 392, "tokens_per_sec": 93.30531855475904, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the maximum property price from Singapore_Properties by joining with Singapore_Neighborhoods where Wheelchair_Accessibility is true. The differences in table aliases and join order do not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly compute the maximum property price in wheelchair-accessible neighborhoods by joining the two tables on Neighborhood_Name and filtering for Wheelchair_Accessibility = TRUE. The Reference SQL uses explicit table names while the Generated SQL uses aliases, but this does not affect the result. Both achieve the same logical outcome with identical syntax and semantics. The business intent is fully addressed as both queries directly answer the question about maximum prices in accessible neighborhoods.", "overall_assessment": "correct"}}
{"example_id": 3859, "sql_complexity": "aggregation", "prompt": "What is the total number of mental health parity violations by month and year?", "context": "CREATE TABLE mental_health_parity_reports (report_id INT, violation_date DATE); INSERT INTO mental_health_parity_reports (report_id, violation_date) VALUES (1, '2022-01-01'), (2, '2022-02-15'), (3, '2022-03-05'), (4, '2022-04-20'), (5, '2021-06-12'), (6, '2021-07-28');", "reference_sql": "SELECT EXTRACT(MONTH FROM violation_date) AS month, EXTRACT(YEAR FROM violation_date) AS year, COUNT(*) FROM mental_health_parity_reports GROUP BY month, year;", "generated_sql": "SELECT \n    EXTRACT(YEAR FROM violation_date) AS report_year,\n    EXTRACT(MONTH FROM violation_date) AS report_month,\n    COUNT(*) AS total_violations\nFROM \n    mental_health_parity_reports\nGROUP BY \n    report_year, \n    report_month\nORDER BY \n    report_year, \n    report_month;", "raw_model_output": "To find the total number of mental health parity violations grouped by month and year from the `mental_health_parity_reports` table, you can use the following SQL query:\n\n```sql\nSELECT \n    EXTRACT(YEAR FROM violation_date) AS report_year,\n    EXTRACT(MONTH FROM violation_date) AS report_month,\n    COUNT(*) AS total_violations\nFROM \n    mental_health_parity_reports\nGROUP BY \n    report_year, \n    report_month\nORDER BY \n    report_year, \n    report_month;\n```\n\nThis query extracts the year and month from the `violation_date` column, counts the number of violations for each combination of year and month, groups the results by these extracted values, and orders them chronologically.", "latency_sec": 4.044277191162109, "total_duration_sec": 4.039168725, "load_duration_sec": 0.01106306, "tokens_prompt": 184, "prompt_eval_sec": 0.027241939, "tokens_completion": 154, "completion_eval_sec": 4.000245141, "tokens_total": 338, "tokens_per_sec": 83.5748847132995, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries group by year and month extracted from violation_date, count violations, and return the same data. The differences are purely in column aliases (month/year vs report_month/report_year) and the generated query adds an ORDER BY clause, which does not affect the semantic result set.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly group violations by month and year, using EXTRACT functions to isolate date components. The reference query lacks an ORDER BY clause, which the generated query includes to ensure results are sorted chronologically. While the original question doesn't explicitly require ordering, the generated query's ORDER BY improves readability and aligns with typical analytical expectations. Column aliases differ but don't affect functionality. Both queries are efficient and semantically equivalent, but the generated version provides a more complete answer by organizing results in a meaningful sequence.", "overall_assessment": "correct"}}
{"example_id": 3551, "sql_complexity": "multiple_joins", "prompt": "List all artists who have performed in New York and Chicago, along with their highest-earning performance.", "context": "CREATE TABLE artist_events (artist_id INT, event_id INT, earnings DECIMAL(5,2)); CREATE TABLE artists (id INT, name VARCHAR(50)); CREATE TABLE events (id INT, city VARCHAR(20));", "reference_sql": "SELECT artists.name, MAX(artist_events.earnings) FROM artists INNER JOIN artist_events ON artists.id = artist_events.artist_id INNER JOIN events ON artist_events.event_id = events.id WHERE city IN ('New York', 'Chicago') GROUP BY artists.name;", "generated_sql": "WITH ArtistInCities AS (\n    SELECT DISTINCT ae.artist_id\n    FROM artist_events ae\n    JOIN events e ON ae.event_id = e.id\n    WHERE e.city IN ('New York', 'Chicago')\n    GROUP BY ae.artist_id\n    HAVING COUNT(DISTINCT e.city) = 2\n),\nMaxEarnings AS (\n    SELECT ae.artist_id, MAX(ae.earnings) AS max_earning\n    FROM artist_events ae\n    GROUP BY ae.artist_id\n)\nSELECT a.name, me.max_earning\nFROM ArtistInCities ac\nJOIN MaxEarnings me ON ac.artist_id = me.artist_id\nJOIN artists a ON ac.artist_id = a.id;", "raw_model_output": "To solve this problem, we need to identify artists who have performed in both New York and Chicago. Then, for each of these artists, we will find their highest-earning performance across all events they participated in. Here's how you can construct the SQL query:\n\n```sql\nWITH ArtistInCities AS (\n    SELECT DISTINCT ae.artist_id\n    FROM artist_events ae\n    JOIN events e ON ae.event_id = e.id\n    WHERE e.city IN ('New York', 'Chicago')\n    GROUP BY ae.artist_id\n    HAVING COUNT(DISTINCT e.city) = 2\n),\nMaxEarnings AS (\n    SELECT ae.artist_id, MAX(ae.earnings) AS max_earning\n    FROM artist_events ae\n    GROUP BY ae.artist_id\n)\nSELECT a.name, me.max_earning\nFROM ArtistInCities ac\nJOIN MaxEarnings me ON ac.artist_id = me.artist_id\nJOIN artists a ON ac.artist_id = a.id;\n```\n\n### Explanation:\n\n1. **ArtistInCities CTE**: \n   - We first find all `artist_id`s that have performed in both New York and Chicago.\n   - This is done by joining the `artist_events` table with the `events` table on `event_id`.\n   - We filter for events in 'New York' or 'Chicago'.\n   - We group by `artist_id` and use `HAVING COUNT(DISTINCT e.city) = 2` to ensure that only artists who have performed in both cities are selected.\n\n2. **MaxEarnings CTE**:\n   - For each artist, we calculate their highest earnings from the `artist_events` table.\n   - This is done by grouping by `artist_id` and using `MAX(ae.earnings)` to find the maximum earning for each artist.\n\n3. **Final SELECT**:\n   - We join the results of the two CTEs (`ArtistInCities` and `MaxEarnings`) on `artist_id`.\n   - We also join with the `artists` table to get the artist names.\n   - The final result includes the artist's name and their highest earning performance.", "latency_sec": 11.488935947418213, "total_duration_sec": 11.474257777, "load_duration_sec": 0.015071164, "tokens_prompt": 137, "prompt_eval_sec": 0.020333422, "tokens_completion": 440, "completion_eval_sec": 11.437754609, "tokens_total": 577, "tokens_per_sec": 50.22223142689407, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their filtering and aggregation logic. The reference query calculates MAX(earnings) for artists with events in New York/Chicago, while the generated query first filters artists with events in *both* cities (HAVING COUNT(DISTINCT city) = 2) and then takes their overall maximum earnings (from all events, not just New York/Chicago). This makes the generated query's result set a subset of the reference query's potential results, but with different conditions on both the artists and earnings considered.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is technically incorrect for the business question. It returns artists who performed in either New York or Chicago (not both) and groups by name, which could aggregate earnings across all events in both cities. The Generated SQL correctly filters artists who performed in *both* cities using HAVING COUNT(DISTINCT e.city) = 2, then joins with max earnings. While both queries return artists and their highest earnings, the Reference SQL fails to enforce the 'performed in both cities' constraint, making it semantically incorrect. The Generated SQL is more precise and aligns with the business intent.", "overall_assessment": "differently_correct"}}
{"example_id": 5168, "sql_complexity": "aggregation", "prompt": "Get the number of renewable energy projects in Australia for each project type.", "context": "CREATE TABLE renewable_projects (id INT PRIMARY KEY, project_name VARCHAR(255), project_location VARCHAR(255), project_type VARCHAR(255), capacity_mw FLOAT);", "reference_sql": "SELECT project_type, COUNT(*) FROM renewable_projects WHERE project_location = 'Australia' GROUP BY project_type;", "generated_sql": "SELECT \n    project_type,\n    COUNT(*) AS project_count\nFROM \n    renewable_projects\nWHERE \n    project_location = 'Australia'\nGROUP BY \n    project_type;", "raw_model_output": "To get the number of renewable energy projects in Australia for each project type from the `renewable_projects` table, you can use the following SQL query:\n\n```sql\nSELECT \n    project_type,\n    COUNT(*) AS project_count\nFROM \n    renewable_projects\nWHERE \n    project_location = 'Australia'\nGROUP BY \n    project_type;\n```\n\nThis query filters the projects to only include those located in Australia and then groups them by `project_type`, counting the number of projects for each type.", "latency_sec": 2.679150104522705, "total_duration_sec": 2.670854749, "load_duration_sec": 0.011737834, "tokens_prompt": 119, "prompt_eval_sec": 0.015988542, "tokens_completion": 103, "completion_eval_sec": 2.642454185, "tokens_total": 222, "tokens_per_sec": 82.86209855328343, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. The generated query adds an explicit column alias ('project_count') for clarity, but both queries select the same data: project_type and the count of projects in Australia. The WHERE and GROUP BY clauses are identical, ensuring the same result set.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly count renewable energy projects in Australia by project type. The reference query is functionally identical to the generated query, with the only difference being the optional column alias 'project_count' in the generated version. The WHERE clause correctly filters for 'Australia', and both use GROUP BY project_type. The generated query improves readability with an alias but neither version introduces errors. Both satisfy the business requirement to analyze project distribution by type.", "overall_assessment": "correct"}}
{"example_id": 4916, "sql_complexity": "aggregation", "prompt": "What is the maximum revenue generated from selling Yttrium in India in the past 3 years?", "context": "CREATE TABLE Yttrium_Sales (id INT PRIMARY KEY, year INT, country VARCHAR(20), quantity INT, price PER_KG); INSERT INTO Yttrium_Sales (id, year, country, quantity, price) VALUES (1, 2019, 'India', 120, 40), (2, 2020, 'India', 130, 45), (3, 2021, 'India', 140, 50), (4, 2019, 'China', 150, 35), (5, 2020, 'China', 160, 40), (6, 2021, 'China', 170, 45);", "reference_sql": "SELECT MAX(quantity * price) FROM Yttrium_Sales WHERE country = 'India' GROUP BY year ORDER BY year DESC LIMIT 3;", "generated_sql": "SELECT MAX(quantity * price) AS max_revenue\nFROM Yttrium_Sales\nWHERE country = 'India'\nAND year BETWEEN 2019 AND 2021;", "raw_model_output": "To calculate the maximum revenue generated from selling Yttrium in India over the past three years (2019, 2020, and 2021), we need to compute the revenue for each record by multiplying `quantity` with `price PER_KG`. Then, we filter records where the country is 'India' and the year is within the specified range. Finally, we find the maximum of these computed revenues.\n\nHere's the SQL statement:\n\n```sql\nSELECT MAX(quantity * price) AS max_revenue\nFROM Yttrium_Sales\nWHERE country = 'India'\nAND year BETWEEN 2019 AND 2021;\n```\n\nThis query calculates the revenue for each sale in India from 2019 to 2021 and then selects the maximum value among them.", "latency_sec": 4.265973091125488, "total_duration_sec": 4.260736802, "load_duration_sec": 0.014893646, "tokens_prompt": 239, "prompt_eval_sec": 0.038335833, "tokens_completion": 160, "completion_eval_sec": 4.206434558, "tokens_total": 399, "tokens_per_sec": 93.53082906923169, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns the maximum revenue (quantity * price) per year for India, grouped by year and ordered descendingly with a limit of 3. The Generated SQL calculates a single maximum revenue value across all years (2019-2021) for India without grouping. The Reference query produces multiple rows (one per year), while the Generated query returns a single value. Additionally, the Generated query's WHERE clause explicitly restricts years, but the core difference lies in aggregation and result structure.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference query is technically flawed because it groups by year and returns multiple rows (one per year), but the question asks for a single maximum value. It also incorrectly uses ORDER BY and LIMIT when the goal is to find the absolute maximum, not the top 3 years. The generated query correctly filters the 3-year window and returns a single maximum value. While both queries would return 7000 in the sample data, the generated query aligns better with the business intent of finding the highest revenue value in the specified period. The reference query's structure would fail if there were multiple sales per year or if the maximum occurred in a different year.", "overall_assessment": "differently_correct"}}
{"example_id": 812, "sql_complexity": "multiple_joins", "prompt": "What is the average salary of 'engineer' workers in each factory?", "context": "CREATE TABLE factories (factory_id INT, factory_name VARCHAR(20)); INSERT INTO factories VALUES (1, 'Factory X'), (2, 'Factory Y'), (3, 'Factory Z'); CREATE TABLE roles (role_id INT, role_name VARCHAR(20)); INSERT INTO roles VALUES (1, 'engineer'), (2, 'manager'), (3, 'assistant'); CREATE TABLE workers (worker_id INT, factory_id INT, role_id INT, salary DECIMAL(5,2)); INSERT INTO workers VALUES (1, 1, 1, 50000.00), (2, 1, 2, 70000.00), (3, 2, 1, 55000.00), (4, 2, 3, 40000.00), (5, 3, 1, 60000.00);", "reference_sql": "SELECT f.factory_name, AVG(salary) FROM workers w INNER JOIN factories f ON w.factory_id = f.factory_id INNER JOIN roles r ON w.role_id = r.role_id WHERE r.role_name = 'engineer' GROUP BY f.factory_name;", "generated_sql": "SELECT \n    f.factory_id,\n    f.factory_name,\n    AVG(w.salary) AS avg_engineer_salary\nFROM \n    workers w\nJOIN \n    roles r ON w.role_id = r.role_id\nJOIN \n    factories f ON w.factory_id = f.factory_id\nWHERE \n    r.role_name = 'engineer'\nGROUP BY \n    f.factory_id, f.factory_name;", "raw_model_output": "To find the average salary of 'engineer' workers in each factory, we need to join the `workers`, `roles`, and `factories` tables. We will filter for workers with the role name 'engineer', group by the factory, and calculate the average salary.\n\nHere's the SQL statement:\n\n```sql\nSELECT \n    f.factory_id,\n    f.factory_name,\n    AVG(w.salary) AS avg_engineer_salary\nFROM \n    workers w\nJOIN \n    roles r ON w.role_id = r.role_id\nJOIN \n    factories f ON w.factory_id = f.factory_id\nWHERE \n    r.role_name = 'engineer'\nGROUP BY \n    f.factory_id, f.factory_name;\n```\n\nThis query performs the following steps:\n- Joins `workers` with `roles` to get role names.\n- Joins `workers` with `factories` to get factory details.\n- Filters for workers whose role is 'engineer'.\n- Groups results by `factory_id` and `factory_name`.\n- Calculates the average salary of engineers in each group.", "latency_sec": 5.971658945083618, "total_duration_sec": 5.963881966, "load_duration_sec": 0.02053796, "tokens_prompt": 266, "prompt_eval_sec": 0.045127104, "tokens_completion": 222, "completion_eval_sec": 5.897283477, "tokens_total": 488, "tokens_per_sec": 81.71933536187017, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL selects only 'factory_name' and the average salary, grouping by 'factory_name'. The Generated SQL includes 'factory_id' in both the SELECT and GROUP BY clauses. While the data might overlap due to unique factory names, the output structures differ (columns and grouping keys), making them semantically distinct.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the average salary of 'engineer' workers per factory by joining the three tables and filtering on role_name = 'engineer'. The Reference SQL groups by factory_name while the Generated SQL groups by factory_id and factory_name. Since factory_name is unique in the sample data and factory_id is the primary key, both approaches produce identical results. The Generated SQL includes the factory_id in the output, which provides more explicit identification but isn't required by the question. Both queries are logically equivalent and technically correct.", "overall_assessment": "correct"}}
{"example_id": 5784, "sql_complexity": "set operations", "prompt": "List the number of users who have completed a workout of a specific type (e.g. Running) and have a membership status of 'Active'.", "context": "CREATE TABLE workouts (id INT, user_id INT, workout_type VARCHAR(20)); CREATE TABLE members (id INT, name VARCHAR(50), membership_status VARCHAR(20), state VARCHAR(20)); INSERT INTO workouts (id, user_id, workout_type) VALUES (1, 1, 'Running'), (2, 1, 'Cycling'), (3, 2, 'Running'), (4, 3, 'Cycling'), (5, 3, 'Swimming'), (6, 4, 'Running'), (7, 4, 'Swimming'); INSERT INTO members (id, name, membership_status, state) VALUES (1, 'John Doe', 'Active', 'Texas'), (2, 'Jane Doe', 'Inactive', 'California'), (3, 'Bob Smith', 'Active', 'Texas'), (4, 'Alice Johnson', 'Active', 'California');", "reference_sql": "SELECT COUNT(*) FROM (SELECT user_id FROM workouts WHERE workout_type = 'Running' INTERSECT SELECT id FROM members WHERE membership_status = 'Active') AS user_set;", "generated_sql": "SELECT COUNT(DISTINCT m.id) AS active_users_with_workout\nFROM members m\nJOIN workouts w ON m.id = w.user_id\nWHERE m.membership_status = 'Active'\nAND w.workout_type = 'Running';", "raw_model_output": "To solve this problem, we need to count the distinct users from the `members` table who have an active membership and have completed at least one workout of a specified type in the `workouts` table.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT COUNT(DISTINCT m.id) AS active_users_with_workout\nFROM members m\nJOIN workouts w ON m.id = w.user_id\nWHERE m.membership_status = 'Active'\nAND w.workout_type = 'Running';\n```\n\n### Explanation:\n- **`members m`**: We alias the `members` table as `m`.\n- **`workouts w`**: We alias the `workouts` table as `w`.\n- **`JOIN workouts w ON m.id = w.user_id`**: This joins the two tables on the condition that a member's ID matches the user ID in the workouts table.\n- **`WHERE m.membership_status = 'Active'`**: Filters members to only those with an active membership status.\n- **`AND w.workout_type = 'Running'`**: Further filters the results to include only those workouts of type 'Running'.\n- **`COUNT(DISTINCT m.id)`**: Counts distinct member IDs that meet both conditions, ensuring each user is counted only once regardless of how many workouts they have completed.\n\nYou can replace `'Running'` with any other workout type as needed.", "latency_sec": 7.675835847854614, "total_duration_sec": 7.668273625, "load_duration_sec": 0.02133842, "tokens_prompt": 287, "prompt_eval_sec": 0.051706788, "tokens_completion": 288, "completion_eval_sec": 7.591333725, "tokens_total": 575, "tokens_per_sec": 74.91040863786993, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count the number of active members who have at least one 'Running' workout. The Reference SQL uses INTERSECT to find common user_ids between active members and 'Running' workouts, while the Generated SQL uses a JOIN with COUNT(DISTINCT) to achieve the same result. Both approaches effectively compute the same set of distinct user_ids and count them.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly count users with 'Running' workouts and active memberships. The reference uses INTERSECT to find user_id/member_id overlaps, while the generated query uses a JOIN with COUNT(DISTINCT). They produce identical results because both ensure unique user counts. The generated query is more efficient due to explicit JOIN logic and avoids potential INTERSECT implementation quirks. It also better aligns with standard BI practices for readability and performance.", "overall_assessment": "correct"}}
{"example_id": 3038, "sql_complexity": "subqueries", "prompt": "What is the total assets of clients who have invested in mutual funds but not in stocks?", "context": "CREATE TABLE clients (client_id INT, name TEXT, age INT, gender TEXT, total_assets DECIMAL(10,2)); INSERT INTO clients VALUES (1, 'John Doe', 35, 'Male', 250000.00), (2, 'Jane Smith', 45, 'Female', 500000.00); CREATE TABLE investments (client_id INT, investment_type TEXT); INSERT INTO investments VALUES (1, 'Stocks'), (1, 'Bonds'), (2, 'Stocks'), (3, 'Mutual Funds');", "reference_sql": "SELECT c.total_assets FROM clients c INNER JOIN investments i ON c.client_id = i.client_id WHERE i.investment_type = 'Mutual Funds' AND c.client_id NOT IN (SELECT client_id FROM investments WHERE investment_type = 'Stocks');", "generated_sql": "SELECT SUM(c.total_assets) AS total_assets_of_clients_with_mutual_funds_only\nFROM clients c\nJOIN investments i1 ON c.client_id = i1.client_id AND i1.investment_type = 'Mutual Funds'\nLEFT JOIN investments i2 ON c.client_id = i2.client_id AND i2.investment_type = 'Stocks'\nWHERE i2.client_id IS NULL;", "raw_model_output": "To solve this problem, we need to identify clients who have investments in \"Mutual Funds\" and do not have any investments in \"Stocks\". We will then sum up their `total_assets` from the `clients` table.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT SUM(c.total_assets) AS total_assets_of_clients_with_mutual_funds_only\nFROM clients c\nJOIN investments i1 ON c.client_id = i1.client_id AND i1.investment_type = 'Mutual Funds'\nLEFT JOIN investments i2 ON c.client_id = i2.client_id AND i2.investment_type = 'Stocks'\nWHERE i2.client_id IS NULL;\n```\n\n### Explanation:\n\n- **JOIN `investments` as `i1`:** We join the `clients` table with the `investments` table to find clients who have invested in \"Mutual Funds\".\n  \n- **LEFT JOIN `investments` as `i2`:** We perform a left join on the same `investments` table again, but this time we're looking for investments of type \"Stocks\". The use of a LEFT JOIN ensures that we can identify clients who do not have any stock investments (these will have `NULL` in `i2.client_id`).\n\n- **WHERE clause:** We filter out the results to include only those clients where there is no corresponding entry in `i2`, i.e., they haven't invested in stocks (`i2.client_id IS NULL`).\n\n- **SUM(c.total_assets):** Finally, we sum up the `total_assets` of these filtered clients.", "latency_sec": 8.671325922012329, "total_duration_sec": 8.663336922, "load_duration_sec": 0.011443081, "tokens_prompt": 203, "prompt_eval_sec": 0.03268223, "tokens_completion": 330, "completion_eval_sec": 8.618522635, "tokens_total": 533, "tokens_per_sec": 61.466954972476486, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns individual client assets, while the Generated SQL aggregates them with SUM. Additionally, in the given data, the Reference SQL returns no rows (no clients with 'Mutual Funds' in the clients table), whereas the Generated SQL returns a single row with NULL (sum of zero rows). The structural difference in output (rows vs. aggregate) makes them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query retrieves individual client assets but does not aggregate them, while the generated query correctly uses SUM() to calculate total assets. Both identify clients with mutual funds and no stocks, but the generated query addresses the 'total assets' requirement. The generated query uses a LEFT JOIN/IS NULL pattern which is more efficient and explicit than NOT IN with a subquery. The reference query would return multiple rows instead of a single total value, making it incomplete for the business question.", "overall_assessment": "differently_correct"}}
{"example_id": 1078, "sql_complexity": "basic SQL", "prompt": "What is the maximum and minimum temperature difference between any two Arctic research stations?", "context": "CREATE TABLE arctic_stations (id INT, name TEXT, location TEXT, temperature DECIMAL(5,2)); INSERT INTO arctic_stations (id, name, location, temperature) VALUES (1, 'Station A', 'Greenland', 2.3), (2, 'Station B', 'Canada', -5.2);", "reference_sql": "SELECT a.name as station1, b.name as station2, MAX(ABS(a.temperature - b.temperature)) as temp_diff FROM arctic_stations a, arctic_stations b ORDER BY temp_diff DESC LIMIT 1", "generated_sql": "SELECT \n    MAX(ABS(a.temperature - b.temperature)) AS max_temperature_difference,\n    MIN(ABS(a.temperature - b.temperature)) AS min_temperature_difference\nFROM \n    arctic_stations a, arctic_stations b\nWHERE \n    a.id <> b.id;", "raw_model_output": "To find the maximum and minimum temperature difference between any two Arctic research stations, we need to compare each station's temperature with every other station's temperature. We can achieve this by performing a self-join on the `arctic_stations` table.\n\nHere is the SQL query that calculates these differences:\n\n```sql\nSELECT \n    MAX(ABS(a.temperature - b.temperature)) AS max_temperature_difference,\n    MIN(ABS(a.temperature - b.temperature)) AS min_temperature_difference\nFROM \n    arctic_stations a, arctic_stations b\nWHERE \n    a.id <> b.id;\n```\n\n### Explanation:\n- We perform a self-join on the `arctic_stations` table using aliases `a` and `b`.\n- The condition `a.id <> b.id` ensures that we are comparing different stations.\n- `ABS(a.temperature - b.temperature)` calculates the absolute difference in temperature between two stations, ensuring positive differences.\n- `MAX(...)` finds the maximum of these differences.\n- `MIN(...)` finds the minimum of these differences.", "latency_sec": 5.5357701778411865, "total_duration_sec": 5.528256763, "load_duration_sec": 0.019747712, "tokens_prompt": 158, "prompt_eval_sec": 0.021222432, "tokens_completion": 215, "completion_eval_sec": 5.485625836, "tokens_total": 373, "tokens_per_sec": 67.37996484988847, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query returns the specific pair of stations with the maximum temperature difference, including station names and the maximum difference. The generated query calculates both maximum and minimum temperature differences across all station pairs without including station names. The output structures and objectives differ, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference SQL only returns the maximum temperature difference (via MAX and ORDER BY/LIMIT) but not the minimum, while the generated SQL correctly calculates both MAX and MIN. The reference query also includes station names (which aren't required by the question) and would return multiple rows if there are ties for maximum difference. The generated query properly filters out same-station comparisons (a.id <> b.id) and directly addresses the dual requirement of max/min differences. The generated query is more efficient as it computes both values in a single pass.", "overall_assessment": "differently_correct"}}
{"example_id": 5015, "sql_complexity": "basic SQL", "prompt": "Calculate the average recycling rate", "context": "CREATE TABLE recycling_rates (id INT PRIMARY KEY, location VARCHAR(50), rate FLOAT);", "reference_sql": "SELECT AVG(rate) FROM recycling_rates;", "generated_sql": "SELECT AVG(rate) AS average_recycling_rate FROM recycling_rates;", "raw_model_output": "To calculate the average recycling rate from the `recycling_rates` table, you can use the following SQL statement:\n\n```sql\nSELECT AVG(rate) AS average_recycling_rate FROM recycling_rates;\n```\n\nThis query uses the `AVG()` aggregate function to compute the average value of the `rate` column across all rows in the `recycling_rates` table. The result is aliased as `average_recycling_rate` for clarity.", "latency_sec": 2.2724928855895996, "total_duration_sec": 2.267046364, "load_duration_sec": 0.011547479, "tokens_prompt": 96, "prompt_eval_sec": 0.012625157, "tokens_completion": 90, "completion_eval_sec": 2.242064172, "tokens_total": 186, "tokens_per_sec": 81.8484410576019, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries calculate the average of the 'rate' column from the recycling_rates table. The generated query adds an alias ('average_recycling_rate') to the result, but this does not affect the computed value. The semantic result (a single numeric average) remains identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the average recycling rate. The reference query returns the average value directly, while the generated query adds an explicit alias 'average_recycling_rate' for the result column. The alias improves readability and explicitly names the metric, which is particularly valuable for downstream reporting or analysis. The core calculation (AVG(rate)) is identical in both queries. The generated version is more elegant as it provides a clear column name without altering the computational logic.", "overall_assessment": "correct"}}
{"example_id": 1533, "sql_complexity": "subqueries", "prompt": "Which programs had the highest volunteer participation rate in the last quarter?", "context": "CREATE TABLE Programs (ProgramID INT, ProgramName TEXT, Budget DECIMAL(10,2), NumVolunteers INT); CREATE TABLE VolunteerEvents (EventID INT, ProgramID INT, EventDate DATE, NumVolunteers INT);", "reference_sql": "SELECT p.ProgramName, COUNT(v.EventID) / (SELECT COUNT(*) FROM VolunteerEvents WHERE EventDate >= DATEADD(quarter, -1, GETDATE())) * 100.0 AS VolunteerParticipationRate FROM Programs p INNER JOIN VolunteerEvents v ON p.ProgramID = v.ProgramID WHERE v.EventDate >= DATEADD(quarter, -1, GETDATE()) GROUP BY p.ProgramName ORDER BY VolunteerParticipationRate DESC;", "generated_sql": "WITH LastQuarterEvents AS (\n    SELECT \n        ProgramID,\n        SUM(NumVolunteers) AS TotalVolunteers\n    FROM \n        VolunteerEvents\n    WHERE \n        EventDate >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n        AND EventDate < DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()), 0)\n    GROUP BY \n        ProgramID\n),\nRankedPrograms AS (\n    SELECT \n        p.ProgramName,\n        l.TotalVolunteers,\n        RANK() OVER (ORDER BY l.TotalVolunteers DESC) AS VolunteerParticipationRank\n    FROM \n        LastQuarterEvents l\n    JOIN \n        Programs p ON l.ProgramID = p.ProgramID\n)\nSELECT \n    ProgramName, \n    TotalVolunteers\nFROM \n    RankedPrograms\nWHERE \n    VolunteerParticipationRank = 1;", "raw_model_output": "To determine which programs had the highest volunteer participation rate in the last quarter, we need to calculate the total number of volunteers for each program during that period and then rank them based on this count. Here's how you can write an SQL query to achieve this:\n\n```sql\nWITH LastQuarterEvents AS (\n    SELECT \n        ProgramID,\n        SUM(NumVolunteers) AS TotalVolunteers\n    FROM \n        VolunteerEvents\n    WHERE \n        EventDate >= DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()) - 1, 0)\n        AND EventDate < DATEADD(quarter, DATEDIFF(quarter, 0, GETDATE()), 0)\n    GROUP BY \n        ProgramID\n),\nRankedPrograms AS (\n    SELECT \n        p.ProgramName,\n        l.TotalVolunteers,\n        RANK() OVER (ORDER BY l.TotalVolunteers DESC) AS VolunteerParticipationRank\n    FROM \n        LastQuarterEvents l\n    JOIN \n        Programs p ON l.ProgramID = p.ProgramID\n)\nSELECT \n    ProgramName, \n    TotalVolunteers\nFROM \n    RankedPrograms\nWHERE \n    VolunteerParticipationRank = 1;\n```\n\n### Explanation:\n\n1. **LastQuarterEvents CTE**: This Common Table Expression calculates the total number of volunteers for each program in the last quarter. It uses `DATEADD` and `DATEDIFF` to determine the start and end dates of the last quarter.\n\n2. **RankedPrograms CTE**: This ranks programs based on their total volunteer participation using the `RANK()` window function, ordering by `TotalVolunteers` in descending order.\n\n3. **Final SELECT Statement**: Retrieves the program names and their corresponding total volunteers for those with the highest rank (i.e., the highest volunteer participation).\n\nNote: The date functions used (`DATEADD`, `DATEDIFF`) are specific to SQL Server. If you're using a different RDBMS, you might need to adjust these functions accordingly. For example, in PostgreSQL, you would use `date_trunc` and interval arithmetic instead.", "latency_sec": 10.851269245147705, "total_duration_sec": 10.845618199, "load_duration_sec": 0.014126337, "tokens_prompt": 132, "prompt_eval_sec": 0.019089018, "tokens_completion": 429, "completion_eval_sec": 10.811344427, "tokens_total": 561, "tokens_per_sec": 51.69902131502809, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL calculates a participation rate as a percentage of events in the last quarter, while the Generated SQL sums volunteers and ranks programs by total volunteers. The metrics (event count vs. volunteer count), calculations (percentage vs. absolute sum), and output columns differ significantly. Additionally, the date range logic in the Generated SQL uses a different approach to define the 'last quarter' compared to the Reference SQL.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The queries differ fundamentally in their approach to calculating 'volunteer participation rate'. The reference query incorrectly uses COUNT(v.EventID) / (total events) * 100, which measures event frequency rather than volunteer volume. The generated query properly sums NumVolunteers from VolunteerEvents, aligning with the business intent of measuring actual volunteer participation. The reference query also has a flawed date calculation (DATEADD(quarter, -1, GETDATE()) doesn't correctly capture the full previous quarter). The generated query uses precise quarter boundary calculations and focuses on total volunteer hours/volunteers rather than event counts. While neither query directly uses the Programs.NumVolunteers column, the generated query's approach better reflects actual participation metrics.", "overall_assessment": "differently_correct"}}
{"example_id": 4021, "sql_complexity": "subqueries", "prompt": "What is the percentage of energy efficiency improvement, per sector, compared to 2015 levels?", "context": "CREATE TABLE energy_efficiency (id INT, sector VARCHAR(50), year INT, efficiency FLOAT); INSERT INTO energy_efficiency (id, sector, year, efficiency) VALUES (1, 'Industry', 2015, 100.0), (2, 'Industry', 2020, 105.0), (3, 'Residential', 2015, 100.0), (4, 'Residential', 2020, 103.0);", "reference_sql": "SELECT sector, (SUM(efficiency) / (SELECT SUM(efficiency) FROM energy_efficiency WHERE year = 2015 AND sector = e.sector) * 100.0) - 100.0 AS improvement FROM energy_efficiency e WHERE year = 2020 GROUP BY sector;", "generated_sql": "SELECT \n    e1.sector,\n    ((e2.efficiency - e1.efficiency) / e1.efficiency) * 100 AS efficiency_improvement_percentage\nFROM \n    energy_efficiency e1\nJOIN \n    energy_efficiency e2 ON e1.sector = e2.sector AND e1.year = 2015 AND e2.year = 2020;", "raw_model_output": "To calculate the percentage of energy efficiency improvement per sector compared to 2015 levels, we need to compare the efficiency values for each sector in 2020 with those in 2015. The formula for calculating the percentage increase is:\n\n\\[\n\\text{Percentage Increase} = \\left( \\frac{\\text{Efficiency}_{2020} - \\text{Efficiency}_{2015}}{\\text{Efficiency}_{2015}} \\right) \\times 100\n\\]\n\nHere's how you can write this as an SQL query:\n\n```sql\nSELECT \n    e1.sector,\n    ((e2.efficiency - e1.efficiency) / e1.efficiency) * 100 AS efficiency_improvement_percentage\nFROM \n    energy_efficiency e1\nJOIN \n    energy_efficiency e2 ON e1.sector = e2.sector AND e1.year = 2015 AND e2.year = 2020;\n```\n\n### Explanation:\n\n- We use a self-join on the `energy_efficiency` table to compare records from different years for the same sector.\n- `e1` represents the efficiency data for the year 2015, and `e2` represents the efficiency data for the year 2020.\n- The join condition ensures that we are comparing the same sector across these two years.\n- We calculate the percentage improvement using the formula provided above.", "latency_sec": 7.383415699005127, "total_duration_sec": 7.37498904, "load_duration_sec": 0.012550126, "tokens_prompt": 188, "prompt_eval_sec": 0.023642454, "tokens_completion": 290, "completion_eval_sec": 7.338063188, "tokens_total": 478, "tokens_per_sec": 64.73968410913227, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the percentage improvement for each sector's total efficiency (sum of all entries) from 2015 to 2020, while the Generated SQL computes the percentage improvement for individual rows (not aggregated). For example, if a sector had multiple entries in 2015/2020, the Reference SQL would use summed values, but the Generated SQL would produce multiple rows with per-row calculations. The sample data coincidentally produces matching results due to single entries per sector/year, but the queries are not semantically equivalent in general.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "reference", "explanation": "Both queries calculate the percentage improvement in energy efficiency per sector compared to 2015 levels. The reference query uses a subquery to aggregate 2015 efficiency values and computes the percentage change using SUM, which ensures correctness even with multiple entries per sector/year. The generated query uses a self-join to directly compare 2015 and 2020 values, which works for the given sample data but would produce multiple rows per sector if there are multiple entries in either year. While both produce the same results for the provided data, the reference query is more robust for general cases with varying data structures.", "overall_assessment": "correct"}}
{"example_id": 1551, "sql_complexity": "single join", "prompt": "How many unique donors made donations in the healthcare industry in Q3 2022?", "context": "CREATE TABLE donations (id INT, donor_id INT, amount FLOAT, donation_date DATE); INSERT INTO donations (id, donor_id, amount, donation_date) VALUES (1, 7, 100, '2022-07-01'); INSERT INTO donations (id, donor_id, amount, donation_date) VALUES (2, 8, 200, '2022-09-15'); INSERT INTO donors (id, name, industry, first_donation_date DATE) VALUES (7, 'Charlie Davis', 'Healthcare', '2022-07-01'); INSERT INTO donors (id, name, industry, first_donation_date DATE) VALUES (8, 'Dana Wilson', 'Healthcare', '2022-09-15');", "reference_sql": "SELECT COUNT(DISTINCT donor_id) FROM donations d JOIN donors don ON d.donor_id = don.id WHERE industry = 'Healthcare' AND donation_date BETWEEN '2022-07-01' AND '2022-09-30';", "generated_sql": "SELECT COUNT(DISTINCT d.id) AS unique_healthcare_donors_q3_2022\nFROM donations dn\nJOIN donors d ON dn.donor_id = d.id\nWHERE d.industry = 'Healthcare'\n  AND dn.donation_date BETWEEN '2022-07-01' AND '2022-09-30';", "raw_model_output": "To find out how many unique donors made donations in the healthcare industry in Q3 2022, we need to join the `donations` and `donors` tables on the `donor_id` and `id` columns respectively. We will filter for donations that occurred between July 1, 2022, and September 30, 2022 (inclusive), which corresponds to Q3 of 2022. Additionally, we need to ensure that these donors are in the healthcare industry.\n\nHere is the SQL query:\n\n```sql\nSELECT COUNT(DISTINCT d.id) AS unique_healthcare_donors_q3_2022\nFROM donations dn\nJOIN donors d ON dn.donor_id = d.id\nWHERE d.industry = 'Healthcare'\n  AND dn.donation_date BETWEEN '2022-07-01' AND '2022-09-30';\n```\n\nThis query performs the following steps:\n1. Joins the `donations` table (`dn`) with the `donors` table (`d`) on the condition that `dn.donor_id = d.id`.\n2. Filters for donors in the healthcare industry using `WHERE d.industry = 'Healthcare'`.\n3. Further filters donations to those made between July 1, 2022, and September 30, 2022.\n4. Counts the distinct donor IDs from this filtered set to get the number of unique donors who meet these criteria.", "latency_sec": 7.572989225387573, "total_duration_sec": 7.563396405, "load_duration_sec": 0.011245075, "tokens_prompt": 244, "prompt_eval_sec": 0.037384169, "tokens_completion": 295, "completion_eval_sec": 7.513908427, "tokens_total": 539, "tokens_per_sec": 71.17400856626926, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count distinct donor IDs meeting the same criteria. The Reference SQL uses 'donor_id' from the donations table, while the Generated SQL uses 'd.id' from the donors table. Since the JOIN condition ensures d.id = donations.donor_id, COUNT(DISTINCT donor_id) and COUNT(DISTINCT d.id) are equivalent. The WHERE clauses, date ranges, and table aliases are functionally identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly count unique donors in the healthcare industry who made donations in Q3 2022. The reference query uses COUNT(DISTINCT donor_id) from the donations table, while the generated query uses COUNT(DISTINCT d.id) from the donors table. Since donor_id in donations corresponds to id in donors, both approaches yield identical results. The JOIN conditions, date ranges, and filtering are equivalent. The generated query adds an alias for the count, which is stylistic but does not affect functionality. Both queries are logically and syntactically correct.", "overall_assessment": "correct"}}
{"example_id": 2592, "sql_complexity": "window functions", "prompt": "What is the third highest account balance for Shariah-compliant finance customers?", "context": "CREATE TABLE shariah_compliant_finance(customer_id INT, account_balance DECIMAL(10, 2)); INSERT INTO shariah_compliant_finance VALUES (1, 5000), (2, 7000), (3, 6000), (4, 8000), (5, 9000);", "reference_sql": "SELECT account_balance FROM (SELECT account_balance, RANK() OVER (ORDER BY account_balance DESC) as rn FROM shariah_compliant_finance) t WHERE rn = 3;", "generated_sql": "SELECT DISTINCT account_balance\nFROM shariah_compliant_finance\nORDER BY account_balance DESC\nLIMIT 1 OFFSET 2;", "raw_model_output": "To find the third highest account balance in the `shariah_compliant_finance` table, you can use a subquery with the `DISTINCT` keyword to ensure unique balances are considered. Then, order these distinct balances in descending order and select the third one using an offset.\n\nHere's how you can write this SQL query:\n\n```sql\nSELECT DISTINCT account_balance\nFROM shariah_compliant_finance\nORDER BY account_balance DESC\nLIMIT 1 OFFSET 2;\n```\n\nExplanation:\n- `DISTINCT` ensures that only unique balances are considered.\n- `ORDER BY account_balance DESC` sorts the balances from highest to lowest.\n- `LIMIT 1 OFFSET 2` skips the first two highest balances and returns the third one.", "latency_sec": 3.8534958362579346, "total_duration_sec": 3.849754482, "load_duration_sec": 0.011507016, "tokens_prompt": 155, "prompt_eval_sec": 0.021187383, "tokens_completion": 153, "completion_eval_sec": 3.816361521, "tokens_total": 308, "tokens_per_sec": 79.92742514523998, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the third highest account balance. The reference query uses RANK() to assign positions and filters for rank 3, while the generated query orders descending and uses OFFSET 2 to skip the first two rows. In the given data, both approaches yield the same result (7000).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The Reference SQL uses RANK() which assigns ranks with gaps for ties, potentially returning no result if there are duplicate balances (e.g., multiple customers with the same 2nd highest balance). The Generated SQL uses LIMIT 1 OFFSET 2, which directly retrieves the third row in descending order, ensuring it always returns a value. Both return 7000 in the sample data, but the Generated SQL better handles edge cases and aligns with the business intent of finding the 'third highest' value without relying on ranking logic that may fail with duplicates. The Generated SQL is more efficient and directly addresses the question.", "overall_assessment": "differently_correct"}}
{"example_id": 3795, "sql_complexity": "single join", "prompt": "What is the total quantity of unsold garments for each manufacturer based in 'Italy' or 'Spain'?", "context": "CREATE TABLE manufacturers (id INT PRIMARY KEY, name VARCHAR(255), country VARCHAR(255)); CREATE TABLE garments (id INT PRIMARY KEY, manufacturer_id INT, quantity_manufactured INT, quantity_sold INT);", "reference_sql": "SELECT m.name, SUM(g.quantity_manufactured - g.quantity_sold) as total_unsold_quantity FROM manufacturers m JOIN garments g ON m.id = g.manufacturer_id WHERE m.country IN ('Italy', 'Spain') GROUP BY m.name;", "generated_sql": "SELECT \n    m.name AS manufacturer_name,\n    SUM(g.quantity_manufactured - g.quantity_sold) AS total_unsold_quantity\nFROM \n    manufacturers m\nJOIN \n    garments g ON m.id = g.manufacturer_id\nWHERE \n    m.country IN ('Italy', 'Spain')\nGROUP BY \n    m.name;", "raw_model_output": "To find the total quantity of unsold garments for each manufacturer based in Italy or Spain, we need to calculate the difference between `quantity_manufactured` and `quantity_sold` for each garment. Then, we'll sum these differences for each manufacturer who is located in either Italy or Spain.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    m.name AS manufacturer_name,\n    SUM(g.quantity_manufactured - g.quantity_sold) AS total_unsold_quantity\nFROM \n    manufacturers m\nJOIN \n    garments g ON m.id = g.manufacturer_id\nWHERE \n    m.country IN ('Italy', 'Spain')\nGROUP BY \n    m.name;\n```\n\n### Explanation:\n- We join the `manufacturers` table with the `garments` table on the `manufacturer_id`.\n- We filter manufacturers based in Italy or Spain using the `WHERE` clause.\n- For each manufacturer, we calculate the unsold quantity by subtracting `quantity_sold` from `quantity_manufactured`.\n- We sum these unsold quantities for each manufacturer and group the results by the manufacturer's name.", "latency_sec": 5.642335891723633, "total_duration_sec": 5.63555708, "load_duration_sec": 0.028372263, "tokens_prompt": 136, "prompt_eval_sec": 0.019878955, "tokens_completion": 223, "completion_eval_sec": 5.585499358, "tokens_total": 359, "tokens_per_sec": 63.62613054047229, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. Both perform the same operations: joining manufacturers with garments, filtering by country ('Italy' or 'Spain'), grouping by manufacturer name, and calculating the total unsold quantity as the sum of (quantity_manufactured - quantity_sold). The only difference is the column alias ('manufacturer_name' vs 'name'), which does not affect the result's semantic meaning.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries are technically correct and produce identical results. The reference and generated queries share the same structure, logic, and output data. The key difference lies in column aliases: the generated query uses 'manufacturer_name' instead of 'm.name' in the SELECT clause. This makes the generated query more readable and semantically explicit, improving clarity without altering the computational logic. Both fulfill the business intent by calculating total unsold garments for Italian/Spanish manufacturers. The generated query's enhanced column naming convention makes it more elegant and user-friendly.", "overall_assessment": "correct"}}
{"example_id": 4138, "sql_complexity": "window functions", "prompt": "How many lifelong learning courses has a student with ID '2' completed, in chronological order?", "context": "CREATE TABLE lifelong_learning (student_id INT, course_id INT, completion_date DATE); INSERT INTO lifelong_learning VALUES (2, 1001, '2015-01-01'), (2, 1002, '2016-01-01');", "reference_sql": "SELECT student_id, course_id, COUNT(course_id) OVER (PARTITION BY student_id ORDER BY completion_date) as completed_courses FROM lifelong_learning WHERE student_id = 2;", "generated_sql": "SELECT COUNT(*) AS total_courses_completed\nFROM lifelong_learning\nWHERE student_id = 2\nORDER BY completion_date;", "raw_model_output": "To determine how many lifelong learning courses the student with ID `2` has completed and to list them in chronological order based on their completion date, you can use the following SQL query:\n\n```sql\nSELECT COUNT(*) AS total_courses_completed\nFROM lifelong_learning\nWHERE student_id = 2\nORDER BY completion_date;\n```\n\nThis query performs the following actions:\n- Filters the `lifelong_learning` table to include only records where `student_id` is `2`.\n- Counts the number of such filtered records using `COUNT(*)`, which gives the total number of courses completed by this student.\n- Orders the results by `completion_date` in ascending order, although ordering does not affect the count result. The ordering is included here to satisfy the requirement of listing them chronologically.\n\nNote: Since you only need the count and not a list of individual records, if you want just the number without ordering (as it doesn't impact the count), you could omit `ORDER BY`:\n\n```sql\nSELECT COUNT(*) AS total_courses_completed\nFROM lifelong_learning\nWHERE student_id = 2;\n```\n\nHowever, including `ORDER BY` ensures that any additional requirements for listing or further processing are met.", "latency_sec": 6.165072917938232, "total_duration_sec": 6.160122974, "load_duration_sec": 0.020902649, "tokens_prompt": 143, "prompt_eval_sec": 0.01926365, "tokens_completion": 244, "completion_eval_sec": 6.118957658, "tokens_total": 387, "tokens_per_sec": 62.77298016605184, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns multiple rows with a running count of courses per student, while the Generated SQL returns a single aggregated count. The Reference SQL uses a window function to track cumulative counts per completion date, whereas the Generated SQL simply counts total rows. The output structures and semantics differ significantly.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query returns a running total per course row (e.g., 1, 2 for two courses) while the generated query returns a single count of total courses (2). The original question asks for 'how many' courses completed, which is a single numeric value. The generated query correctly returns COUNT(*) as the total number of courses. The reference query's window function provides unnecessary granularity (per-course counts) that doesn't align with the question's focus on total quantity. Both queries filter for student_id = 2, but the generated query's ORDER BY completion_date is redundant (as it only affects a single-row result) while the reference query's output structure is fundamentally different.", "overall_assessment": "correct"}}
{"example_id": 312, "sql_complexity": "aggregation", "prompt": "List the top 3 most represented ethnicities in movies produced in the USA.", "context": "CREATE TABLE movies (title VARCHAR(255), production_country VARCHAR(64), lead_actor_ethnicity VARCHAR(64));", "reference_sql": "SELECT lead_actor_ethnicity, COUNT(*) AS count FROM movies WHERE production_country = 'USA' GROUP BY lead_actor_ethnicity ORDER BY count DESC LIMIT 3;", "generated_sql": "SELECT lead_actor_ethnicity, COUNT(*) AS count\nFROM movies\nWHERE production_country = 'USA'\nGROUP BY lead_actor_ethnicity\nORDER BY count DESC\nLIMIT 3;", "raw_model_output": "To solve this problem, we need to count how many times each ethnicity appears as a `lead_actor_ethnicity` for movies that are produced in the USA. Then, we will order these counts in descending order and limit the results to the top 3 most represented ethnicities.\n\nHere is the SQL statement:\n\n```sql\nSELECT lead_actor_ethnicity, COUNT(*) AS count\nFROM movies\nWHERE production_country = 'USA'\nGROUP BY lead_actor_ethnicity\nORDER BY count DESC\nLIMIT 3;\n```\n\nExplanation:\n- We filter the `movies` table to include only those rows where `production_country` is 'USA'.\n- We group the results by `lead_actor_ethnicity`.\n- For each ethnicity, we count how many times it appears using `COUNT(*)`.\n- We order these counts in descending order with `ORDER BY count DESC`.\n- Finally, we limit the output to the top 3 most represented ethnicities using `LIMIT 3`.", "latency_sec": 4.998635768890381, "total_duration_sec": 4.993856525, "load_duration_sec": 0.014384138, "tokens_prompt": 112, "prompt_eval_sec": 0.016972436, "tokens_completion": 199, "completion_eval_sec": 4.961410581, "tokens_total": 311, "tokens_per_sec": 62.2169756667502, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The two queries are identical in structure and logic. Both select lead_actor_ethnicity and count, filter for USA production countries, group by ethnicity, order by count descending, and limit to 3 results. The only difference is formatting (whitespace/indentation), which does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "The reference and generated queries are identical in structure, logic, and syntax. Both correctly filter USA-produced movies, group by lead actor ethnicity, count occurrences, order by count descending, and limit to top 3 results. They perfectly address the business intent of identifying the most represented ethnicities in US movies. Since the queries are identical, neither is more efficient or elegant than the other.", "overall_assessment": "correct"}}
{"example_id": 4298, "sql_complexity": "single join", "prompt": "How many users joined the gym in Q1 2023?", "context": "CREATE TABLE memberships (id INT, user_id INT, join_date DATE); INSERT INTO memberships (id, user_id, join_date) VALUES (1, 5, '2023-01-15'), (2, 6, '2023-02-03'), (3, 7, '2023-03-20'), (4, 8, '2022-12-31');", "reference_sql": "SELECT COUNT(*) FROM memberships WHERE join_date BETWEEN '2023-01-01' AND '2023-03-31';", "generated_sql": "SELECT COUNT(DISTINCT user_id) AS users_joined_in_q1_2023\nFROM memberships\nWHERE join_date BETWEEN '2023-01-01' AND '2023-03-31';", "raw_model_output": "To determine how many users joined the gym in Q1 2023, we need to count the number of records in the `memberships` table where the `join_date` falls between January 1, 2023, and March 31, 2023. Here's the SQL statement that accomplishes this:\n\n```sql\nSELECT COUNT(DISTINCT user_id) AS users_joined_in_q1_2023\nFROM memberships\nWHERE join_date BETWEEN '2023-01-01' AND '2023-03-31';\n```\n\nThis query uses `COUNT(DISTINCT user_id)` to ensure that each user is counted only once, even if they have multiple entries in the table. The `BETWEEN` clause filters the records to include only those with a `join_date` within the specified range for Q1 2023.", "latency_sec": 4.456041097640991, "total_duration_sec": 4.451861933, "load_duration_sec": 0.011211052, "tokens_prompt": 169, "prompt_eval_sec": 0.023504372, "tokens_completion": 176, "completion_eval_sec": 4.416304646, "tokens_total": 345, "tokens_per_sec": 77.42298431283353, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query counts all rows matching the date range (COUNT(*)), while the generated query counts distinct user_ids. If there are multiple memberships for the same user within the date range, they would produce different results. Although the sample data shows 3 unique users matching the dates, the queries are not semantically equivalent in general.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The reference query counts all rows (including potential duplicate user entries) while the generated query explicitly counts distinct user_ids, which aligns with the business intent of counting unique users. Although both use the same date filter, the generated query addresses the implicit requirement to avoid overcounting users with multiple memberships. The reference query could overcount if the memberships table contains multiple entries per user. The generated query better fulfills the business intent of determining 'how many users' joined, not 'how many memberships' were created.", "overall_assessment": "differently_correct"}}
{"example_id": 5211, "sql_complexity": "multiple_joins", "prompt": "What is the average transaction value in the last week, split by product category and customer demographics?", "context": "CREATE TABLE transactions (transaction_id INT, customer_id INT, product_id INT, category_id INT, transaction_date DATE, amount DECIMAL(10,2)); CREATE TABLE customers (customer_id INT, age INT, gender VARCHAR(10), location VARCHAR(255)); CREATE TABLE products (product_id INT, name VARCHAR(255), category_id INT);", "reference_sql": "SELECT c.age, c.gender, p.category_id, AVG(t.amount) as avg_transaction_value FROM transactions t INNER JOIN customers c ON t.customer_id = c.customer_id INNER JOIN products p ON t.product_id = p.product_id WHERE t.transaction_date >= DATE_SUB(CURRENT_DATE, INTERVAL 1 WEEK) GROUP BY c.age, c.gender, p.category_id;", "generated_sql": "SELECT \n    p.category_id,\n    c.age,\n    c.gender,\n    AVG(t.amount) AS avg_transaction_value\nFROM \n    transactions t\nJOIN \n    customers c ON t.customer_id = c.customer_id\nJOIN \n    products p ON t.product_id = p.product_id\nWHERE \n    t.transaction_date >= CURRENT_DATE - INTERVAL '7' DAY\nGROUP BY \n    p.category_id, c.age, c.gender;", "raw_model_output": "To calculate the average transaction value in the last week, split by product category and customer demographics, we need to join the `transactions`, `customers`, and `products` tables. We will filter transactions from the last week, group them by product category and customer demographics (age and gender), and then compute the average transaction amount.\n\nHere's the SQL statement:\n\n```sql\nSELECT \n    p.category_id,\n    c.age,\n    c.gender,\n    AVG(t.amount) AS avg_transaction_value\nFROM \n    transactions t\nJOIN \n    customers c ON t.customer_id = c.customer_id\nJOIN \n    products p ON t.product_id = p.product_id\nWHERE \n    t.transaction_date >= CURRENT_DATE - INTERVAL '7' DAY\nGROUP BY \n    p.category_id, c.age, c.gender;\n```\n\n### Explanation:\n- **Joins**: We join the `transactions` table with the `customers` and `products` tables to access customer demographics and product categories.\n- **Filtering**: The `WHERE` clause filters transactions that occurred in the last 7 days using `CURRENT_DATE - INTERVAL '7' DAY`.\n- **Grouping**: We group the results by `category_id`, `age`, and `gender` to get averages for each combination of these attributes.\n- **Aggregation**: The `AVG(t.amount)` function calculates the average transaction amount for each group.", "latency_sec": 7.198556184768677, "total_duration_sec": 7.189845544, "load_duration_sec": 0.011589421, "tokens_prompt": 161, "prompt_eval_sec": 0.021139982, "tokens_completion": 284, "completion_eval_sec": 7.156342599, "tokens_total": 445, "tokens_per_sec": 61.81795190285091, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the same data by joining the same tables with identical conditions. The date filter uses equivalent expressions (DATE_SUB(...) vs. CURRENT_DATE - INTERVAL '7' DAY) to calculate the same one-week range. The SELECT column order differs but does not affect semantic equivalence. The GROUP BY clause contains the same columns in different order, which is irrelevant for grouping logic. The aggregate function and join logic are identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the average transaction value for the last week, grouped by product category and customer demographics (age/gender). The technical differences are minor: the reference uses DATE_SUB(CURRENT_DATE, INTERVAL 1 WEEK) while the generated query uses CURRENT_DATE - INTERVAL '7' DAY. These date calculations are functionally equivalent for most SQL implementations. The GROUP BY clauses and column selections are identical. Both queries properly join the required tables (transactions, customers, products) and filter by the 7-day window. The generated query has slightly more readable formatting but no functional advantage. Neither query contains errors or omissions.", "overall_assessment": "correct"}}
{"example_id": 382, "sql_complexity": "window functions", "prompt": "What is the average annual precipitation in the past 10 years for each weather station?", "context": "CREATE TABLE WeatherStation (ID INT, Name VARCHAR(100), Location VARCHAR(100), Elevation FLOAT, AnnualPrecipitation FLOAT); INSERT INTO WeatherStation (ID, Name, Location, Elevation, AnnualPrecipitation) VALUES (1, 'Station A', 'Arctic Circle', 100, 450); INSERT INTO WeatherStation (ID, Name, Location, Elevation, AnnualPrecipitation) VALUES (2, 'Station B', 'North Pole', 200, 300);", "reference_sql": "SELECT Name, AVG(AnnualPrecipitation) OVER (PARTITION BY Name ORDER BY Name ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS AvgAnnualPrecipitation FROM WeatherStation WHERE YEAR(CurrentDate) - YEAR(DateInstalled) BETWEEN 1 AND 10;", "generated_sql": "SELECT ID, Name, Location, Elevation, AnnualPrecipitation AS CurrentAnnualPrecipitation\nFROM WeatherStation;", "raw_model_output": "To answer this question with the given schema and data, we need to consider that the provided table `WeatherStation` does not contain historical data or any time-based records. It only contains static information about each weather station, including their current annual precipitation.\n\nGiven this limitation, it is impossible to calculate the average annual precipitation over the past 10 years for each weather station using the available schema and data. The SQL query would simply return the current `AnnualPrecipitation` value for each station since there are no historical records or time-series data in the table.\n\nHere's how you can write an SQL statement that returns the current annual precipitation for each weather station:\n\n```sql\nSELECT ID, Name, Location, Elevation, AnnualPrecipitation AS CurrentAnnualPrecipitation\nFROM WeatherStation;\n```\n\nThis query retrieves all available information from the `WeatherStation` table and labels the `AnnualPrecipitation` column as `CurrentAnnualPrecipitation`, indicating that it represents only the current value.", "latency_sec": 5.1917197704315186, "total_duration_sec": 5.186679112, "load_duration_sec": 0.021359313, "tokens_prompt": 192, "prompt_eval_sec": 0.031441339, "tokens_completion": 203, "completion_eval_sec": 5.132941034, "tokens_total": 395, "tokens_per_sec": 76.08268887116165, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL selects 'Name' and calculates a window function average of 'AnnualPrecipitation' with a WHERE clause referencing a non-existent 'DateInstalled' column. The Generated SQL selects all columns (ID, Name, Location, Elevation) and renames 'AnnualPrecipitation' as 'CurrentAnnualPrecipitation'. They differ in selected columns, logic (window function vs. direct selection), and the Reference SQL contains an invalid column reference.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference query contains multiple critical issues: 1) It references non-existent columns (CurrentDate, DateInstalled) in the WHERE clause 2) The window function uses 'ORDER BY Name' which is irrelevant for time-based averaging 3) The schema shows AnnualPrecipitation as a single value per station, not yearly data. The generated query is technically correct but fails to compute any average or filter by time. Neither query properly addresses the question due to schema limitations, but the generated query at least doesn't introduce erroneous logic. The reference query's window function would return the same value as AnnualPrecipitation for each row (since there's only one value per station), making it incorrect for the intended purpose.", "overall_assessment": "incorrect"}}
{"example_id": 2190, "sql_complexity": "single join", "prompt": "What is the total number of humanitarian assistance events by each country in the last 3 years?", "context": "CREATE TABLE Humanitarian_Assistance (id INT, country VARCHAR(50), year INT, events INT); CREATE TABLE Countries (id INT, name VARCHAR(50), region VARCHAR(50));", "reference_sql": "SELECT co.name, SUM(ha.events) FROM Humanitarian_Assistance ha INNER JOIN Countries co ON ha.country = co.name WHERE ha.year BETWEEN (YEAR(CURRENT_DATE) - 3) AND YEAR(CURRENT_DATE) GROUP BY co.name;", "generated_sql": "WITH RecentYears AS (\n    SELECT MAX(year) AS current_year FROM Humanitarian_Assistance\n),\nFilteredData AS (\n    SELECT ha.country, ha.year, ha.events\n    FROM Humanitarian_Assistance ha\n    JOIN RecentYears ry ON ha.year BETWEEN (ry.current_year - 2) AND ry.current_year\n)\nSELECT c.name AS country_name, SUM(fd.events) AS total_events\nFROM FilteredData fd\nJOIN Countries c ON fd.country = c.id\nGROUP BY c.name;", "raw_model_output": "To solve this problem, we need to calculate the total number of humanitarian assistance events for each country over the past three years. We'll assume that \"the last 3 years\" refers to the most recent complete year available in the data plus the two preceding years.\n\nHere's how you can construct the SQL query:\n\n1. Determine the current year based on the maximum `year` value present in the `Humanitarian_Assistance` table.\n2. Calculate the range of years for which we need to sum the events: from `(current_year - 2)` to `current_year`.\n3. Join the `Humanitarian_Assistance` and `Countries` tables using the country identifier.\n4. Group by the country name and sum the number of events.\n\nHere's the SQL query:\n\n```sql\nWITH RecentYears AS (\n    SELECT MAX(year) AS current_year FROM Humanitarian_Assistance\n),\nFilteredData AS (\n    SELECT ha.country, ha.year, ha.events\n    FROM Humanitarian_Assistance ha\n    JOIN RecentYears ry ON ha.year BETWEEN (ry.current_year - 2) AND ry.current_year\n)\nSELECT c.name AS country_name, SUM(fd.events) AS total_events\nFROM FilteredData fd\nJOIN Countries c ON fd.country = c.id\nGROUP BY c.name;\n```\n\n### Explanation:\n\n- **RecentYears CTE**: This common table expression calculates the most recent year available in the `Humanitarian_Assistance` table.\n  \n- **FilteredData CTE**: Filters the data to include only records from the last three years, using the range calculated in the `RecentYears` CTE.\n\n- **Final SELECT Statement**: Joins the filtered data with the `Countries` table to get country names and sums up the events for each country. The results are grouped by country name to provide the total number of humanitarian assistance events per country over the specified period.", "latency_sec": 9.66484522819519, "total_duration_sec": 9.658208874, "load_duration_sec": 0.012161711, "tokens_prompt": 129, "prompt_eval_sec": 0.017194252, "tokens_completion": 382, "completion_eval_sec": 9.628139517, "tokens_total": 511, "tokens_per_sec": 52.872031360550196, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in two key aspects. First, the year range: the reference uses (YEAR(CURRENT_DATE) - 3) to YEAR(CURRENT_DATE) (4 years), while the generated query uses (current_year - 2) to current_year (3 years). Second, the join condition: the reference joins on ha.country = co.name (country names), but the generated query joins on fd.country = c.id (assuming country IDs). These differences in logic and schema usage make the queries non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL and Generated SQL differ significantly in both logic and structure. The Reference SQL correctly joins Humanitarian_Assistance with Countries on country names (ha.country = co.name) and filters years using YEAR(CURRENT_DATE) - 3 to YEAR(CURRENT_DATE), though this includes 4 years (e.g., 2021-2024) instead of 3. The Generated SQL has a critical technical error: it joins FilteredData (which contains country names as VARCHAR) with Countries on fd.country = c.id (a type mismatch between VARCHAR and INT). Additionally, the Generated SQL's CTE logic is unnecessarily complex and may not accurately capture the last 3 calendar years if the latest year in the table is not the current year. While the Generated SQL attempts to handle dynamic year ranges, its join error makes it non-functional. The Reference SQL, despite its year calculation flaw, better aligns with the business intent of aggregating events by country.", "overall_assessment": "differently_correct"}}
{"example_id": 1852, "sql_complexity": "set operations", "prompt": "Compare coal production and employment rates in China and India between 2018 and 2020.", "context": "CREATE TABLE china_coal_production (year INT, production FLOAT); INSERT INTO china_coal_production (year, production) VALUES (2018, 3500.0), (2019, 3600.0), (2020, 3700.0); CREATE TABLE china_employment (year INT, employment FLOAT); INSERT INTO china_employment (year, employment) VALUES (2018, 8000000.0), (2019, 8100000.0), (2020, 8200000.0); CREATE TABLE india_coal_production (year INT, production FLOAT); INSERT INTO india_coal_production (year, production) VALUES (2018, 700.0), (2019, 750.0), (2020, 800.0); CREATE TABLE india_employment (year INT, employment FLOAT); INSERT INTO india_employment (year, employment) VALUES (2018, 1000000.0), (2019, 1050000.0), (2020, 1100000.0);", "reference_sql": "SELECT 'China' AS country, china_coal_production.production, china_employment.employment FROM china_coal_production INNER JOIN china_employment ON china_coal_production.year = china_employment.year WHERE china_coal_production.year BETWEEN 2018 AND 2020 UNION ALL SELECT 'India', india_coal_production.production, india_employment.employment FROM india_coal_production INNER JOIN india_employment ON india_coal_production.year = india_employment.year WHERE india_coal_production.year BETWEEN 2018 AND 2020;", "generated_sql": "SELECT \n    c.year,\n    c.production AS china_coal_production,\n    i.production AS india_coal_production,\n    ch.employment AS china_employment,\n    in_.employment AS india_employment\nFROM \n    china_coal_production c\nJOIN \n    india_coal_production i ON c.year = i.year\nJOIN \n    china_employment ch ON c.year = ch.year\nJOIN \n    india_employment in_ ON c.year = in_.year\nWHERE \n    c.year BETWEEN 2018 AND 2020;", "raw_model_output": "To compare coal production and employment rates in China and India between the years 2018 and 2020, we can create a query that selects relevant data from each table for these years. We will join the tables on the `year` column to align the data by year. Here's how you can structure the SQL statement:\n\n```sql\nSELECT \n    c.year,\n    c.production AS china_coal_production,\n    i.production AS india_coal_production,\n    ch.employment AS china_employment,\n    in_.employment AS india_employment\nFROM \n    china_coal_production c\nJOIN \n    india_coal_production i ON c.year = i.year\nJOIN \n    china_employment ch ON c.year = ch.year\nJOIN \n    india_employment in_ ON c.year = in_.year\nWHERE \n    c.year BETWEEN 2018 AND 2020;\n```\n\n### Explanation:\n- We select the `year` column to identify each year.\n- For coal production, we use aliases (`china_coal_production` and `india_coal_production`) for clarity when selecting from `china_coal_production` (aliased as `c`) and `india_coal_production` (aliased as `i`).\n- Similarly, for employment data, we use aliases (`china_employment` and `india_employment`) for the columns selected from `china_employment` (aliased as `ch`) and `india_employment` (aliased as `in_`).\n- We perform inner joins on the `year` column to ensure that only matching years are included in the result.\n- The `WHERE` clause restricts the results to the years 2018, 2019, and 2020.", "latency_sec": 9.181416988372803, "total_duration_sec": 9.174061799, "load_duration_sec": 0.015637681, "tokens_prompt": 310, "prompt_eval_sec": 0.049677784, "tokens_completion": 358, "completion_eval_sec": 9.107771805, "tokens_total": 668, "tokens_per_sec": 72.75565425750125, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL returns two rows per year (China and India) with columns 'country', 'production', 'employment', while the Generated SQL returns one row per year with separate columns for China and India's production/employment. The structure and number of rows differ, leading to different result sets.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent due to differing result structures. The reference query returns 6 rows (3 years \u00d7 2 countries) with separate country identifiers, while the generated query returns 3 rows (1 per year) with all data in a single row. The generated query better fulfills the business intent by directly enabling side-by-side comparison of both countries' metrics for each year. Although the reference is technically correct, its structure requires manual comparison across rows, whereas the generated query provides a more intuitive cross-tabular format. The generated query is also more efficient as it avoids UNION ALL and retrieves all data in a single query.", "overall_assessment": "differently_correct"}}
{"example_id": 2535, "sql_complexity": "subqueries", "prompt": "What is the maximum safety rating for vehicles in the vehiclesafety schema?", "context": "CREATE TABLE VehicleSafety (id INT, vehicle_id INT, safetyrating INT, PRIMARY KEY (id)); CREATE TABLE Vehicles (id INT, make VARCHAR(50), model VARCHAR(50), PRIMARY KEY (id)); CREATE TABLE LuxuryVehicles (id INT, vehicle_id INT, PRIMARY KEY (id), FOREIGN KEY (vehicle_id) REFERENCES Vehicles(id));", "reference_sql": "SELECT MAX(safetyrating) FROM vehicleSafety JOIN Vehicles ON vehicleSafety.vehicle_id = Vehicles.id WHERE EXISTS (SELECT * FROM LuxuryVehicles WHERE Vehicles.id = LuxuryVehicles.vehicle_id);", "generated_sql": "SELECT MAX(safetyrating) AS max_safety_rating FROM VehicleSafety;", "raw_model_output": "To find the maximum safety rating for vehicles in the `VehicleSafety` table, you can use a simple SQL query that selects the highest value from the `safetyrating` column. Here's how you can write this query:\n\n```sql\nSELECT MAX(safetyrating) AS max_safety_rating FROM VehicleSafety;\n```\n\nThis statement uses the `MAX()` aggregate function to find the maximum value in the `safetyrating` column of the `VehicleSafety` table. The result is aliased as `max_safety_rating` for clarity, although this aliasing is optional.", "latency_sec": 3.0328750610351562, "total_duration_sec": 3.023503401, "load_duration_sec": 0.014443305, "tokens_prompt": 157, "prompt_eval_sec": 0.021517518, "tokens_completion": 119, "completion_eval_sec": 2.986451192, "tokens_total": 276, "tokens_per_sec": 91.0027595748695, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters vehicles using an EXISTS clause with LuxuryVehicles, while the Generated SQL retrieves MAX(safetyrating) from all VehicleSafety records without any filtering. The Generated SQL lacks the luxury vehicle constraint, so it may include safety ratings from non-luxury vehicles, leading to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query incorrectly filters results by requiring vehicles to exist in LuxuryVehicles, which is not part of the original question's requirements. The generated query directly retrieves the maximum safety rating from the VehicleSafety table, which aligns with the explicit request for 'vehicles in the vehiclesafety schema.' While both queries are syntactically correct, the generated query is more direct and avoids unnecessary complexity. The reference query's additional condition changes the result set, making it technically inequivalent. The generated query better fulfills the business intent by focusing solely on the safety ratings in the specified schema.", "overall_assessment": "correct"}}
{"example_id": 2140, "sql_complexity": "aggregation", "prompt": "What was the total amount of minerals extracted in the 'north' region for each month in 2020?", "context": "CREATE TABLE extraction(id INT, location TEXT, month INT, year INT, minerals_extracted FLOAT);INSERT INTO extraction(id, location, month, year, minerals_extracted) VALUES (1, 'north', 1, 2020, 1500), (2, 'north', 2, 2020, 1800), (3, 'south', 1, 2020, 1200);", "reference_sql": "SELECT month, SUM(minerals_extracted) FROM extraction WHERE location = 'north' AND year = 2020 GROUP BY month;", "generated_sql": "SELECT month, SUM(minerals_extracted) AS total_minerals_extracted\nFROM extraction\nWHERE location = 'north' AND year = 2020\nGROUP BY month;", "raw_model_output": "To find the total amount of minerals extracted in the 'north' region for each month in 2020, you can use the following SQL query:\n\n```sql\nSELECT month, SUM(minerals_extracted) AS total_minerals_extracted\nFROM extraction\nWHERE location = 'north' AND year = 2020\nGROUP BY month;\n```\n\nThis query filters the records to include only those from the 'north' region and the year 2020. It then groups the results by month and calculates the sum of `minerals_extracted` for each group, providing the total amount extracted per month.", "latency_sec": 3.1655609607696533, "total_duration_sec": 3.160604308, "load_duration_sec": 0.011057239, "tokens_prompt": 181, "prompt_eval_sec": 0.024890106, "tokens_completion": 124, "completion_eval_sec": 3.124090073, "tokens_total": 305, "tokens_per_sec": 96.34943183208968, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. The only difference is the addition of an alias 'total_minerals_extracted' for the SUM column in the generated query, which does not affect the result set's data or structure. Both queries filter the same records, group by month, and calculate the same aggregate value.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries are technically equivalent as they produce identical results. The reference query is functionally correct but lacks an explicit alias for the aggregated column. The generated query improves readability by adding 'AS total_minerals_extracted', which explicitly names the output column. This makes the generated query more elegant and semantically clearer for business users, while both correctly address the original question by filtering 'north' region data from 2020 and grouping by month to calculate totals.", "overall_assessment": "correct"}}
{"example_id": 4779, "sql_complexity": "window functions", "prompt": "What is the average CO2 emission for the top 3 highest emitting countries since 2015?", "context": "CREATE TABLE emissions (country VARCHAR(50), year INT, co2_emission INT); INSERT INTO emissions (country, year, co2_emission) VALUES ('USA', 2015, 5373978000); INSERT INTO emissions (country, year, co2_emission) VALUES ('China', 2015, 10498600000); INSERT INTO emissions (country, year, co2_emission) VALUES ('India', 2015, 2633830000); INSERT INTO emissions (country, year, co2_emission) VALUES ('USA', 2016, 5518004000); INSERT INTO emissions (country, year, co2_emission) VALUES ('China', 2016, 10813000000); INSERT INTO emissions (country, year, co2_emission) VALUES ('India', 2016, 2799280000);", "reference_sql": "SELECT AVG(co2_emission) as avg_emission FROM (SELECT country, year, co2_emission, ROW_NUMBER() OVER (ORDER BY co2_emission DESC) as rn FROM emissions WHERE year >= 2015) t WHERE rn <= 3 GROUP BY country;", "generated_sql": "WITH TotalEmissions AS (\n    SELECT \n        country, \n        SUM(co2_emission) AS total_co2_emission\n    FROM \n        emissions\n    WHERE \n        year >= 2015\n    GROUP BY \n        country\n),\nTop3Countries AS (\n    SELECT \n        country,\n        total_co2_emission\n    FROM \n        TotalEmissions\n    ORDER BY \n        total_co2_emission DESC\n    LIMIT 3\n)\nSELECT \n    AVG(total_co2_emission) AS average_co2_emission\nFROM \n    Top3Countries;", "raw_model_output": "To find the average CO2 emission for the top 3 highest emitting countries since 2015, we need to follow these steps:\n\n1. Calculate the total emissions for each country from 2015 onwards.\n2. Identify the top 3 countries with the highest total emissions.\n3. Compute the average of their total emissions.\n\nHere's the SQL query that accomplishes this:\n\n```sql\nWITH TotalEmissions AS (\n    SELECT \n        country, \n        SUM(co2_emission) AS total_co2_emission\n    FROM \n        emissions\n    WHERE \n        year >= 2015\n    GROUP BY \n        country\n),\nTop3Countries AS (\n    SELECT \n        country,\n        total_co2_emission\n    FROM \n        TotalEmissions\n    ORDER BY \n        total_co2_emission DESC\n    LIMIT 3\n)\nSELECT \n    AVG(total_co2_emission) AS average_co2_emission\nFROM \n    Top3Countries;\n```\n\nThis query uses Common Table Expressions (CTEs) to first calculate the total emissions for each country since 2015, then selects the top 3 countries based on these totals, and finally computes the average of their emissions.", "latency_sec": 6.369147062301636, "total_duration_sec": 6.364193307, "load_duration_sec": 0.011801402, "tokens_prompt": 272, "prompt_eval_sec": 0.044393345, "tokens_completion": 247, "completion_eval_sec": 6.307091398, "tokens_total": 519, "tokens_per_sec": 81.48657817495072, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the average of the top 3 co2_emission values (by value) per country, while the Generated SQL calculates the average of the top 3 countries by total co2_emission (summed across years). The Reference SQL groups by country after selecting top 3 rows by emission value, leading to per-country averages of individual emission entries. The Generated SQL aggregates emissions per country first, then averages the top 3 total emissions. The result structures and calculation logic differ fundamentally.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL is technically flawed. It uses ROW_NUMBER() on individual rows without grouping by country, which would incorrectly identify top emissions across all years rather than per-country totals. The GROUP BY country in the outer query further distorts results by averaging emissions within countries, contradicting the goal of averaging the top 3 countries' emissions. The Generated SQL correctly aggregates emissions per country first (SUM(co2_emission)), identifies the top 3 by total emissions, and then calculates their average. This aligns with the business intent of finding the average of the *countries* with the highest cumulative emissions since 2015. The Generated SQL is more efficient, semantically correct, and directly addresses the question.", "overall_assessment": "differently_correct"}}
{"example_id": 1015, "sql_complexity": "subqueries", "prompt": "List the top 3 most expensive eco-friendly products in Europe and their suppliers.", "context": "CREATE TABLE Suppliers (supplierID INT, supplierName VARCHAR(50), country VARCHAR(50)); CREATE TABLE Products (productID INT, productName VARCHAR(50), price DECIMAL(10,2), ecoFriendly BOOLEAN, supplierID INT);", "reference_sql": "SELECT P.productName, P.price, S.supplierName FROM (SELECT * FROM Products WHERE ecoFriendly = TRUE ORDER BY price DESC LIMIT 3) P JOIN Suppliers S ON P.supplierID = S.supplierID;", "generated_sql": "SELECT \n    p.productName,\n    p.price,\n    s.supplierName\nFROM \n    Products p\nJOIN \n    Suppliers s ON p.supplierID = s.supplierID\nWHERE \n    p.ecoFriendly = TRUE AND\n    s.country = 'Europe'\nORDER BY \n    p.price DESC\nLIMIT 3;", "raw_model_output": "To solve this problem, we need to join the `Products` table with the `Suppliers` table on the `supplierID` column. We will filter for eco-friendly products (`ecoFriendly = TRUE`) that are supplied by suppliers located in Europe (`country = 'Europe'`). Then, we'll order these products by their price in descending order and limit the results to the top 3 most expensive ones.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    p.productName,\n    p.price,\n    s.supplierName\nFROM \n    Products p\nJOIN \n    Suppliers s ON p.supplierID = s.supplierID\nWHERE \n    p.ecoFriendly = TRUE AND\n    s.country = 'Europe'\nORDER BY \n    p.price DESC\nLIMIT 3;\n```\n\nThis query performs the following steps:\n1. Joins `Products` and `Suppliers` on `supplierID`.\n2. Filters for products that are eco-friendly (`ecoFriendly = TRUE`) and supplied by suppliers in Europe (`country = 'Europe'`).\n3. Orders the results by product price in descending order.\n4. Limits the output to the top 3 most expensive products.", "latency_sec": 6.120621919631958, "total_duration_sec": 6.112323764, "load_duration_sec": 0.011269008, "tokens_prompt": 136, "prompt_eval_sec": 0.016628594, "tokens_completion": 243, "completion_eval_sec": 6.083706644, "tokens_total": 379, "tokens_per_sec": 61.92181202768849, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL filters products by ecoFriendly = TRUE, orders by price DESC, limits to 3 rows, and then joins with Suppliers. The Generated SQL joins Products and Suppliers first, then filters with ecoFriendly = TRUE AND s.country = 'Europe', and orders/limits after. The additional 's.country = 'Europe'' condition in the Generated SQL introduces a different filtering criterion not present in the Reference SQL, leading to potentially different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in their approach to filtering European suppliers. The reference query focuses solely on eco-friendly products without considering the supplier's country, while the generated query explicitly filters suppliers in Europe (s.country = 'Europe'). This makes the generated query technically more accurate for the business requirement of 'eco-friendly products in Europe'. Both queries correctly identify top-priced eco-friendly products, but the generated query ensures the supplier's location aligns with the geographic requirement. The generated query also maintains clarity by applying filters before ordering/limiting, which could improve performance.", "overall_assessment": "differently_correct"}}
{"example_id": 3715, "sql_complexity": "aggregation", "prompt": "What is the average age of engines still in service for each engine type?", "context": "CREATE TABLE Engine (id INT, aircraft_id INT, engine_type VARCHAR(255), hours_since_last_service INT, manufacture_year INT); INSERT INTO Engine (id, aircraft_id, engine_type, hours_since_last_service, manufacture_year) VALUES (1, 1, 'GE90-115B', 500, 2000); INSERT INTO Engine (id, aircraft_id, engine_type, hours_since_last_service, manufacture_year) VALUES (2, 2, 'CFM56-5B', 1000, 1995); INSERT INTO Engine (id, aircraft_id, engine_type, hours_since_last_service, manufacture_year) VALUES (3, 1, 'GE90-115B', 700, 2002);", "reference_sql": "SELECT engine_type, AVG(YEAR(CURRENT_DATE) - manufacture_year) as avg_age FROM Engine GROUP BY engine_type;", "generated_sql": "SELECT \n    engine_type,\n    AVG(YEAR(CURRENT_DATE) - manufacture_year) AS avg_age\nFROM \n    Engine\nWHERE \n    hours_since_last_service > 0\nGROUP BY \n    engine_type;", "raw_model_output": "To calculate the average age of engines still in service for each engine type, we need to determine how old each engine is based on its `manufacture_year` and then compute the average age grouped by `engine_type`. Assuming \"still in service\" means any engine with a non-zero `hours_since_last_service`, here's the SQL query:\n\n```sql\nSELECT \n    engine_type,\n    AVG(YEAR(CURRENT_DATE) - manufacture_year) AS avg_age\nFROM \n    Engine\nWHERE \n    hours_since_last_service > 0\nGROUP BY \n    engine_type;\n```\n\nThis query does the following:\n- Filters engines that are still in service by checking if `hours_since_last_service` is greater than zero.\n- Calculates the age of each engine using `YEAR(CURRENT_DATE) - manufacture_year`.\n- Computes the average age for each `engine_type` using the `AVG()` function.\n- Groups the results by `engine_type`.", "latency_sec": 5.007872104644775, "total_duration_sec": 5.003066301, "load_duration_sec": 0.014743753, "tokens_prompt": 239, "prompt_eval_sec": 0.036615917, "tokens_completion": 194, "completion_eval_sec": 4.951032606, "tokens_total": 433, "tokens_per_sec": 86.46386947430122, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes all rows from the Engine table, while the Generated SQL adds a WHERE clause filtering for rows where hours_since_last_service > 0. Although the provided data has no rows with hours_since_last_service = 0, the queries are not semantically equivalent because the Generated SQL could exclude rows in other datasets, leading to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in the WHERE clause: the generated query filters for engines with hours_since_last_service > 0. The original question specifies 'engines still in service,' which likely implies engines that are actively used (i.e., have accumulated operating hours). The reference query includes all engines, including those potentially retired or unused. The generated query better aligns with the business intent by focusing on active engines. Both calculate average age correctly using manufacture_year, but the generated query's filter improves relevance to 'in service' engines. The generated query is more precise without sacrificing efficiency.", "overall_assessment": "differently_correct"}}
{"example_id": 1957, "sql_complexity": "set operations", "prompt": "What is the average temperature recorded for the 'polar_bear' species in the 'Arctic_Animals' table compared to the 'penguin' species in the 'Antarctic_Animals' table?", "context": "CREATE TABLE Arctic_Animals (species TEXT, avg_temp FLOAT); CREATE TABLE Antarctic_Animals (species TEXT, avg_temp FLOAT);", "reference_sql": "SELECT AVG(Arctic_Animals.avg_temp) FROM Arctic_Animals WHERE Arctic_Animals.species = 'polar_bear' INTERSECT SELECT AVG(Antarctic_Animals.avg_temp) FROM Antarctic_Animals WHERE Antarctic_Animals.species = 'penguin'", "generated_sql": "SELECT \n    (SELECT avg_temp FROM Arctic_Animals WHERE species = 'polar_bear') AS polar_bear_avg_temp,\n    (SELECT avg_temp FROM Antarctic_Animals WHERE species = 'penguin') AS penguin_avg_temp;", "raw_model_output": "To find the average temperatures recorded for the 'polar_bear' species in the `Arctic_Animals` table and the 'penguin' species in the `Antarctic_Animals` table, you can use a query that selects these specific records. Here's how you can write it:\n\n```sql\nSELECT \n    (SELECT avg_temp FROM Arctic_Animals WHERE species = 'polar_bear') AS polar_bear_avg_temp,\n    (SELECT avg_temp FROM Antarctic_Animals WHERE species = 'penguin') AS penguin_avg_temp;\n```\n\nThis query uses subqueries to fetch the average temperature for each specified species from their respective tables. The results are returned as two columns: `polar_bear_avg_temp` and `penguin_avg_temp`.", "latency_sec": 3.996011972427368, "total_duration_sec": 3.99110672, "load_duration_sec": 0.021638578, "tokens_prompt": 141, "prompt_eval_sec": 0.017736832, "tokens_completion": 158, "completion_eval_sec": 3.950820701, "tokens_total": 299, "tokens_per_sec": 74.82460064261848, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL computes the intersection of two average temperature values (polar bear in Arctic vs penguin in Antarctic), returning only when they are equal. The Generated SQL retrieves both average temperatures as separate columns regardless of their values. The first returns a single value (or nothing) if averages match, while the second always returns a single row with two values.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL uses INTERSECT which returns only common values between two queries. Since each subquery returns a single average value, INTERSECT would only produce a result if both averages are identical (which is unlikely). This fundamentally misrepresents the question's intent to compare two separate averages. The Generated SQL correctly retrieves both averages in separate columns using scalar subqueries, enabling direct comparison. While both queries are syntactically valid, only the Generated SQL addresses the business requirement to compare the two species' average temperatures.", "overall_assessment": "differently_correct"}}
{"example_id": 1311, "sql_complexity": "basic SQL", "prompt": "What is the total number of veteran job applications in Texas in the last year?", "context": "CREATE TABLE veteran_jobs (id INT, state VARCHAR(50), application_date DATE); INSERT INTO veteran_jobs (id, state, application_date) VALUES (1, 'Texas', '2021-02-15'), (2, 'California', '2021-04-10'), (3, 'Texas', '2022-01-05');", "reference_sql": "SELECT COUNT(*) FROM veteran_jobs WHERE state = 'Texas' AND application_date >= DATE_SUB(CURRENT_DATE, INTERVAL 1 YEAR);", "generated_sql": "SELECT COUNT(*) AS total_applications_in_texas_last_year\nFROM veteran_jobs\nWHERE state = 'Texas'\nAND application_date >= DATE('2023-10-01', '-1 year')\nAND application_date < DATE('2023-10-01');", "raw_model_output": "To determine the total number of veteran job applications in Texas for the last year from today's date, we need to calculate a date range that covers the past 12 months. Assuming today's date is October 1, 2023, the last year would be from October 1, 2022, to September 30, 2023.\n\nHere's the SQL query to achieve this:\n\n```sql\nSELECT COUNT(*) AS total_applications_in_texas_last_year\nFROM veteran_jobs\nWHERE state = 'Texas'\nAND application_date >= DATE('2023-10-01', '-1 year')\nAND application_date < DATE('2023-10-01');\n```\n\nThis query counts the number of rows in `veteran_jobs` where:\n- The `state` is 'Texas'.\n- The `application_date` falls within the last year from October 1, 2022, to September 30, 2023. \n\nThe `DATE('2023-10-01', '-1 year')` function calculates the date one year before October 1, 2023, and `DATE('2023-10-01')` represents the start of the current day in 2023 for comparison purposes. Adjust the dates if today's date is different from October 1, 2023.", "latency_sec": 6.837125062942505, "total_duration_sec": 6.832269, "load_duration_sec": 0.016831138, "tokens_prompt": 160, "prompt_eval_sec": 0.022006783, "tokens_completion": 270, "completion_eval_sec": 6.792839819, "tokens_total": 430, "tokens_per_sec": 62.8919313368447, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses DATE_SUB(CURRENT_DATE, INTERVAL 1 YEAR) which includes all dates from exactly one year ago up to the current date. The Generated SQL uses application_date >= DATE('2023-10-01', '-1 year') (equivalent to 2022-10-01) AND application_date < DATE('2023-10-01'), which excludes the current date (2023-10-01) and creates a half-open interval [2022-10-01, 2023-10-01). This means the Generated SQL misses any applications on the exact current date, making them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries differ in date calculation logic. The reference uses dynamic CURRENT_DATE, ensuring the last 12 months from the current day. The generated query uses a fixed date ('2023-10-01') and calculates relative dates from that point. While both count Texas applications in the 12-month window ending 2023-10-01, the reference is more universally accurate for any current date. The generated query would fail if run on a date other than 2023-10-01, making it less reliable. Both fulfill the business intent, but the reference is technically superior due to its dynamic date calculation.", "overall_assessment": "correct"}}
{"example_id": 2997, "sql_complexity": "window functions", "prompt": "What is the earliest capture time for each satellite image in the 'satellite_images' table?", "context": "CREATE TABLE satellite_images (image_id INT, image_url TEXT, capture_time TIMESTAMP); INSERT INTO satellite_images (image_id, image_url, capture_time) VALUES (1, 'image1.jpg', '2022-01-01 10:00:00'), (2, 'image2.jpg', '2021-05-01 10:00:00');", "reference_sql": "SELECT image_id, MIN(capture_time) OVER (PARTITION BY image_id) FROM satellite_images;", "generated_sql": "SELECT image_url, MIN(capture_time) AS earliest_capture_time\nFROM satellite_images\nGROUP BY image_url;", "raw_model_output": "To find the earliest capture time for each unique satellite image URL in the `satellite_images` table, you can use a SQL query that groups by the `image_url` and selects the minimum `capture_time`. Here's how you can write this query:\n\n```sql\nSELECT image_url, MIN(capture_time) AS earliest_capture_time\nFROM satellite_images\nGROUP BY image_url;\n```\n\nThis query will return each unique `image_url` along with its earliest `capture_time`.", "latency_sec": 2.5412821769714355, "total_duration_sec": 2.534221205, "load_duration_sec": 0.021900892, "tokens_prompt": 167, "prompt_eval_sec": 0.023927243, "tokens_completion": 99, "completion_eval_sec": 2.486654267, "tokens_total": 266, "tokens_per_sec": 104.67157185866097, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns image_id and the minimum capture_time (which equals the row's capture_time since each image_id is unique), while the Generated SQL returns image_url and the minimum capture_time (also equal to the row's capture_time since each image_url is unique). Although the values may appear similar, the column names and grouping logic differ: the first uses a window function with image_id partitioning, while the second uses GROUP BY on image_url. The output schemas are not identical.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL uses a window function that returns the same capture_time for each row (since image_id is unique), failing to aggregate or group data. It incorrectly returns per-row minima instead of true earliest capture times per satellite image. The Generated SQL groups by image_url (assuming it uniquely identifies satellite images) and correctly calculates the earliest capture time for each group. However, neither query perfectly aligns with the question's intent due to ambiguity in 'satellite image' definition. The Generated SQL better addresses the implicit goal of finding earliest times per image, assuming image_url represents distinct images.", "overall_assessment": "differently_correct"}}
{"example_id": 3743, "sql_complexity": "aggregation", "prompt": "What is the maximum budget spent on peacekeeping operations by each department?", "context": "CREATE TABLE DepartmentPeacekeeping (id INT, department VARCHAR(50), budget INT);", "reference_sql": "SELECT department, MAX(budget) FROM DepartmentPeacekeeping GROUP BY department;", "generated_sql": "SELECT department, MAX(budget) AS max_budget\nFROM DepartmentPeacekeeping\nGROUP BY department;", "raw_model_output": "To find the maximum budget spent on peacekeeping operations by each department from the `DepartmentPeacekeeping` table, you can use the following SQL query:\n\n```sql\nSELECT department, MAX(budget) AS max_budget\nFROM DepartmentPeacekeeping\nGROUP BY department;\n```\n\nThis query groups the records by the `department` column and calculates the maximum budget for each group using the `MAX()` aggregate function. The result will show each department along with its corresponding maximum budget spent on peacekeeping operations.", "latency_sec": 2.5342798233032227, "total_duration_sec": 2.526491527, "load_duration_sec": 0.01036092, "tokens_prompt": 103, "prompt_eval_sec": 0.014759045, "tokens_completion": 101, "completion_eval_sec": 2.500555375, "tokens_total": 204, "tokens_per_sec": 80.49624122962987, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries group by 'department' and calculate the maximum 'budget' for each group. The generated query adds an alias 'max_budget' to the MAX(budget) column, but this does not affect the semantic result set (the data returned). Column aliases are metadata and do not change the underlying data values.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the maximum budget per department using GROUP BY and MAX(). The generated query adds an explicit alias (max_budget) for the calculated column, which improves readability but does not alter the result set. The reference query omits the alias but produces identical data. Neither query introduces logical errors or misses the business intent of identifying the highest budget per department. The difference is purely stylistic and does not affect technical correctness or semantic equivalence.", "overall_assessment": "correct"}}
{"example_id": 4664, "sql_complexity": "multiple_joins", "prompt": "Calculate the total number of volunteer hours contributed by volunteers from 'California' in 'Health' projects in 2021.", "context": "CREATE TABLE volunteers (volunteer_id INT, name VARCHAR(255), state VARCHAR(255));", "reference_sql": "SELECT SUM(vh.hours) as total_hours FROM volunteer_projects vp JOIN volunteer_hours vh ON vp.project_id = vh.project_id JOIN volunteers vol ON vh.volunteer_id = vol.volunteer_id WHERE vp.cause = 'Health' AND vol.state = 'California' AND vh.volunteer_date BETWEEN '2021-01-01' AND '2021-12-31';", "generated_sql": "SELECT SUM(h.hours) AS total_hours\nFROM volunteers v\nJOIN project_volunteers pv ON v.volunteer_id = pv.volunteer_id\nJOIN projects p ON pv.project_id = p.project_id\nJOIN hours_contributed h ON pv.volunteer_project_id = h.volunteer_project_id\nWHERE v.state = 'California'\n  AND p.category = 'Health'\n  AND YEAR(h.date) = 2021;", "raw_model_output": "To calculate the total number of volunteer hours contributed by volunteers from 'California' in 'Health' projects in 2021, we need to consider additional tables that would typically store information about projects and volunteer hours. However, since only the `volunteers` table is provided in your schema, I'll outline a hypothetical solution assuming there are relevant tables such as `projects`, `project_volunteers`, and `hours_contributed`.\n\nHere's how you might structure the SQL query:\n\n```sql\nSELECT SUM(h.hours) AS total_hours\nFROM volunteers v\nJOIN project_volunteers pv ON v.volunteer_id = pv.volunteer_id\nJOIN projects p ON pv.project_id = p.project_id\nJOIN hours_contributed h ON pv.volunteer_project_id = h.volunteer_project_id\nWHERE v.state = 'California'\n  AND p.category = 'Health'\n  AND YEAR(h.date) = 2021;\n```\n\n### Explanation:\n\n- **volunteers (v)**: This table contains information about the volunteers, including their state.\n- **project_volunteers (pv)**: A hypothetical junction table that links volunteers to projects they are involved in. It includes `volunteer_id` and `project_id`.\n- **projects (p)**: A hypothetical table containing details of each project, including a category field for 'Health'.\n- **hours_contributed (h)**: A hypothetical table recording the hours contributed by volunteers to specific volunteer-project combinations, with a date field.\n\nThe query joins these tables based on their relationships and filters the results to include only those records where:\n- The volunteer is from California.\n- The project category is Health.\n- The year of contribution is 2021.\n\nFinally, it sums up all the hours contributed under these conditions. \n\nPlease note that this solution assumes the existence of additional tables (`projects`, `project_volunteers`, and `hours_contributed`) which are not provided in your schema. You would need to adjust the query based on the actual database schema you have.", "latency_sec": 10.210774898529053, "total_duration_sec": 10.202911017, "load_duration_sec": 0.012711366, "tokens_prompt": 115, "prompt_eval_sec": 0.019887693, "tokens_completion": 404, "completion_eval_sec": 10.168505229, "tokens_total": 519, "tokens_per_sec": 50.82865944628417, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in join conditions (project_id vs volunteer_project_id) and date filtering (BETWEEN vs YEAR()). The generated query uses 'category' instead of 'cause' and may include dates outside 2021 if the date column isn't strictly date-type. These differences could lead to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries differ in table/column naming and date filtering logic. The reference uses 'volunteer_projects' and 'volunteer_hours' with explicit date range filtering, while the generated query uses 'project_volunteers' and 'hours_contributed' with YEAR() function. The reference's date range (BETWEEN) is more efficient for indexed columns than the generated query's YEAR() function. Although both aim to calculate total hours, the reference better aligns with typical schema patterns (e.g., 'cause' vs 'category') and uses more efficient date filtering. Both fulfill the business intent but the reference is technically more robust.", "overall_assessment": "differently_correct"}}
{"example_id": 251, "sql_complexity": "set operations", "prompt": "Compare the number of economic diversification projects in two regions, one in Europe and one in Oceania, by showing the project type and the number of projects in each region.", "context": "CREATE TABLE economic_diversification (region VARCHAR(50), project_type VARCHAR(50), project_start_date DATE);", "reference_sql": "SELECT 'Europe' as region, project_type, COUNT(*) as project_count FROM economic_diversification WHERE region = 'Europe' UNION ALL SELECT 'Oceania' as region, project_type, COUNT(*) as project_count FROM economic_diversification WHERE region = 'Oceania';", "generated_sql": "SELECT \n    ed1.project_type,\n    COUNT(ed1.project_type) AS europe_project_count,\n    COUNT(ed2.project_type) AS oceania_project_count\nFROM \n    economic_diversification ed1\nFULL OUTER JOIN \n    economic_diversification ed2 ON ed1.project_type = ed2.project_type\nWHERE \n    (ed1.region IN ('Europe_Region1', 'Europe_Region2') AND ed2.region IS NULL)\n    OR \n    (ed2.region IN ('Oceania_Region1', 'Oceania_Region2') AND ed1.region IS NULL)\nGROUP BY \n    ed1.project_type, ed2.project_type\nORDER BY \n    ed1.project_type;", "raw_model_output": "To compare the number of economic diversification projects between a European region and an Oceanian region based on their project types, you can use the following SQL query. This query assumes that you have specific regions from Europe and Oceania to compare:\n\n```sql\nSELECT \n    ed1.project_type,\n    COUNT(ed1.project_type) AS europe_project_count,\n    COUNT(ed2.project_type) AS oceania_project_count\nFROM \n    economic_diversification ed1\nFULL OUTER JOIN \n    economic_diversification ed2 ON ed1.project_type = ed2.project_type\nWHERE \n    (ed1.region IN ('Europe_Region1', 'Europe_Region2') AND ed2.region IS NULL)\n    OR \n    (ed2.region IN ('Oceania_Region1', 'Oceania_Region2') AND ed1.region IS NULL)\nGROUP BY \n    ed1.project_type, ed2.project_type\nORDER BY \n    ed1.project_type;\n```\n\n### Explanation:\n- **Tables and Columns**: The query uses the `economic_diversification` table with columns `region`, `project_type`, and `project_start_date`.\n  \n- **Regions**: Replace `'Europe_Region1', 'Europe_Region2'` with actual European region names you want to compare, and replace `'Oceania_Region1', 'Oceania_Region2'` with actual Oceanian region names.\n\n- **FULL OUTER JOIN**: This join is used to ensure that all project types from both regions are included in the result set, even if a project type exists in only one of the regions.\n\n- **WHERE Clause**: \n  - `(ed1.region IN ('Europe_Region1', 'Europe_Region2') AND ed2.region IS NULL)` ensures we count projects only for specified European regions.\n  - `(ed2.region IN ('Oceania_Region1', 'Oceania_Region2') AND ed1.region IS NULL)` ensures we count projects only for specified Oceanian regions.\n\n- **GROUP BY**: Groups the results by `project_type` to get counts per project type.\n\n- **ORDER BY**: Orders the result set by `project_type` for better readability.", "latency_sec": 11.44363021850586, "total_duration_sec": 11.436088956, "load_duration_sec": 0.015928539, "tokens_prompt": 131, "prompt_eval_sec": 0.017398226, "tokens_completion": 453, "completion_eval_sec": 11.401842519, "tokens_total": 584, "tokens_per_sec": 51.03275698786518, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The reference query counts projects in 'Europe' and 'Oceania' regions separately, while the generated query uses a FULL OUTER JOIN with region-specific conditions ('Europe_Region1', 'Europe_Region2', etc.) that differ from the original. Additionally, the generated query's structure groups by both ed1 and ed2 project_types, leading to different aggregation logic. The output columns and region filtering criteria also differ, resulting in non-matching results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The Reference SQL correctly addresses the question by separately aggregating project counts for Europe and Oceania, producing clear region-specific results. The Generated SQL contains critical flaws: 1) It references non-existent region names ('Europe_Region1', 'Oceania_Region2') not present in the schema, 2) The FULL OUTER JOIN logic incorrectly attempts to combine regions rather than maintaining separate aggregations, 3) The WHERE clause's complex null-checking conditions would produce inaccurate results. While both queries aim to compare regions, the Reference's approach is technically sound, semantically clear, and directly fulfills the business intent of showing project types with counts per region.", "overall_assessment": "correct"}}
{"example_id": 610, "sql_complexity": "subqueries", "prompt": "What is the percentage of community development projects completed in 'Caribbean' in 2020?", "context": "CREATE TABLE community_projects (project_id INT, project_name TEXT, location TEXT, completion_year INT); INSERT INTO community_projects (project_id, project_name, location, completion_year) VALUES (1, 'Community Center', 'Southern Region, Caribbean', 2020); INSERT INTO community_projects (project_id, project_name, location, completion_year) VALUES (2, 'Park Renovation', 'Northern Region, Caribbean', 2019); INSERT INTO community_projects (project_id, project_name, location, completion_year) VALUES (3, 'Library Construction', 'Caribbean', 2020);", "reference_sql": "SELECT (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM community_projects WHERE location = 'Caribbean')) FROM community_projects WHERE completion_year = 2020 AND location = 'Caribbean';", "generated_sql": "SELECT \n    (COUNT(CASE WHEN location LIKE '%Caribbean%' AND completion_year = 2020 THEN 1 END) * 100.0 / COUNT(*)) AS percentage_caribbean_2020\nFROM \n    community_projects\nWHERE \n    completion_year = 2020;", "raw_model_output": "To calculate the percentage of community development projects completed in 'Caribbean' in 2020, we need to determine two things:\n\n1. The total number of projects completed in 2020.\n2. The number of those projects that were specifically located in 'Caribbean'.\n\nHere's how you can write the SQL query to achieve this:\n\n```sql\nSELECT \n    (COUNT(CASE WHEN location LIKE '%Caribbean%' AND completion_year = 2020 THEN 1 END) * 100.0 / COUNT(*)) AS percentage_caribbean_2020\nFROM \n    community_projects\nWHERE \n    completion_year = 2020;\n```\n\n### Explanation:\n\n- `COUNT(*)` counts all projects completed in the year 2020.\n- `COUNT(CASE WHEN location LIKE '%Caribbean%' AND completion_year = 2020 THEN 1 END)` counts only those projects where the location includes 'Caribbean' and were completed in 2020.\n- The percentage is calculated by dividing the count of Caribbean projects by the total count of projects for 2020, then multiplying by 100 to get a percentage.\n- `* 100.0` ensures that the division results in a floating-point number rather than an integer, preserving decimal precision in the result.", "latency_sec": 6.655529022216797, "total_duration_sec": 6.647376311, "load_duration_sec": 0.015366513, "tokens_prompt": 212, "prompt_eval_sec": 0.037654251, "tokens_completion": 259, "completion_eval_sec": 6.592002224, "tokens_total": 471, "tokens_per_sec": 70.76822870545026, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the percentage of Caribbean projects completed in 2020 relative to all Caribbean projects (denominator: total Caribbean projects). The Generated SQL calculates the percentage of Caribbean projects completed in 2020 relative to all projects completed in 2020 (denominator: total 2020 projects). The denominators differ, leading to different results in general cases.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference query correctly calculates the percentage of Caribbean projects completed in 2020 by using the total Caribbean projects (regardless of completion year) as the denominator. The generated query incorrectly uses all 2020 projects as the denominator, which changes the metric being calculated. The reference query also explicitly filters for 'Caribbean' in both numerator and denominator, ensuring semantic alignment with the business question. The generated query uses a LIKE pattern match ('%Caribbean%') which could include unintended locations (e.g., 'Caribbean Sea') and misplaces the completion_year filter in the WHERE clause rather than the numerator calculation.", "overall_assessment": "incorrect"}}
{"example_id": 421, "sql_complexity": "set operations", "prompt": "What is the combined landfill capacity for 'City A' and 'City B'?", "context": "CREATE TABLE landfill_capacity (city VARCHAR(255), capacity INT); INSERT INTO landfill_capacity (city, capacity) VALUES ('City A', 500000), ('City B', 600000);", "reference_sql": "SELECT SUM(capacity) FROM (SELECT capacity FROM landfill_capacity WHERE city = 'City A' UNION ALL SELECT capacity FROM landfill_capacity WHERE city = 'City B') AS combined_capacity;", "generated_sql": "SELECT SUM(capacity) AS total_capacity\nFROM landfill_capacity\nWHERE city IN ('City A', 'City B');", "raw_model_output": "To find the combined landfill capacity for 'City A' and 'City B', you can use a `SELECT` statement with a `SUM` function to add up their capacities. Here's the SQL query:\n\n```sql\nSELECT SUM(capacity) AS total_capacity\nFROM landfill_capacity\nWHERE city IN ('City A', 'City B');\n```\n\nThis query calculates the sum of the `capacity` column for rows where the `city` is either 'City A' or 'City B'. The result will be labeled as `total_capacity`.", "latency_sec": 2.8146350383758545, "total_duration_sec": 2.806418158, "load_duration_sec": 0.025444106, "tokens_prompt": 128, "prompt_eval_sec": 0.018991822, "tokens_completion": 111, "completion_eval_sec": 2.760725108, "tokens_total": 239, "tokens_per_sec": 84.91331797600003, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the sum of capacities for 'City A' and 'City B'. The reference query uses a subquery with UNION ALL to combine the two cities' capacities before summing, while the generated query directly filters using IN. Since SUM aggregates all matching rows regardless of grouping, both approaches yield the same total.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the combined landfill capacity for 'City A' and 'City B'. The Reference SQL uses a subquery with UNION ALL to combine individual city capacities before summing, while the Generated SQL directly sums capacities where the city matches either 'City A' or 'City B'. Both produce identical results. However, the Generated SQL is more efficient and elegant, avoiding unnecessary subquery complexity. The business intent of combining capacities is fulfilled by both, but the Generated SQL achieves it with simpler logic.", "overall_assessment": "correct"}}
{"example_id": 880, "sql_complexity": "aggregation", "prompt": "Show veteran employment statistics for each state in the 'veteran_employment' table", "context": "CREATE TABLE veteran_employment (employee_id INT, state VARCHAR(2), job_title VARCHAR(50), employment_date DATE);", "reference_sql": "SELECT state, COUNT(*) as veteran_employees FROM veteran_employment WHERE state IN ('CA', 'NY', 'TX', 'FL', 'PA') GROUP BY state;", "generated_sql": "SELECT \n    state,\n    COUNT(employee_id) AS total_veterans_employed\nFROM \n    veteran_employment\nGROUP BY \n    state;", "raw_model_output": "To show veteran employment statistics for each state from the `veteran_employment` table, we can write an SQL query that counts the number of veterans employed in each state. Here's how you can do it:\n\n```sql\nSELECT \n    state,\n    COUNT(employee_id) AS total_veterans_employed\nFROM \n    veteran_employment\nGROUP BY \n    state;\n```\n\nThis query does the following:\n- Selects the `state` column to group the results by each state.\n- Uses `COUNT(employee_id)` to count the number of veterans employed in each state. The `employee_id` is used as a unique identifier for counting purposes.\n- Groups the results by `state` using the `GROUP BY` clause, which ensures that we get one row per state with the total count of veterans employed there.", "latency_sec": 4.2729408740997314, "total_duration_sec": 4.266932645, "load_duration_sec": 0.015667307, "tokens_prompt": 115, "prompt_eval_sec": 0.015433828, "tokens_completion": 170, "completion_eval_sec": 4.234814148, "tokens_total": 285, "tokens_per_sec": 66.6987932661359, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes a WHERE clause filtering states to ('CA', 'NY', 'TX', 'FL', 'PA'), while the Generated SQL does not apply any state filter. This means the Generated SQL will count employees across all states, whereas the Reference only counts the specified states. The column alias difference does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in their scope: the reference query explicitly filters for specific states ('CA', 'NY', 'TX', 'FL', 'PA'), while the generated query analyzes all states in the table. The original question asks for statistics 'for each state' without restricting to specific states, making the generated query more aligned with the business intent. Both count veterans correctly (COUNT(*) vs COUNT(employee_id) are equivalent here), but the generated query provides broader, unfiltered insights. The reference query may be incorrect if the goal was to analyze all states, not just the hardcoded subset.", "overall_assessment": "differently_correct"}}
{"example_id": 454, "sql_complexity": "single join", "prompt": "Which excavation sites have more than 10 artifacts?", "context": "CREATE TABLE ExcavationSite (SiteID INT, SiteName VARCHAR(50)); INSERT INTO ExcavationSite (SiteID, SiteName) VALUES (1, 'Site A'), (2, 'Site B'), (3, 'Site C'); CREATE TABLE Artifact (ArtifactID INT, SiteID INT, ObjectType VARCHAR(50)); INSERT INTO Artifact (ArtifactID, SiteID, ObjectType) VALUES (1, 1, 'Pottery'), (2, 1, 'Tool'), (3, 2, 'Statue'), (4, 2, 'Bead'), (5, 3, 'Bead'), (6, 3, 'Bead'), (7, 3, 'Bead'), (8, 3, 'Bead'), (9, 3, 'Bead'), (10, 3, 'Bead'), (11, 3, 'Bead');", "reference_sql": "SELECT e.SiteName FROM ExcavationSite e JOIN Artifact a ON e.SiteID = a.SiteID GROUP BY e.SiteName HAVING COUNT(a.ArtifactID) > 10;", "generated_sql": "SELECT e.SiteID, e.SiteName\nFROM ExcavationSite e\nJOIN (\n    SELECT SiteID\n    FROM Artifact\n    GROUP BY SiteID\n    HAVING COUNT(ArtifactID) > 10\n) a ON e.SiteID = a.SiteID;", "raw_model_output": "To determine which excavation sites have more than 10 artifacts, you need to count the number of artifacts associated with each site and then filter for those counts that exceed 10. Here's how you can write this query using standard ANSI SQL:\n\n```sql\nSELECT e.SiteID, e.SiteName\nFROM ExcavationSite e\nJOIN (\n    SELECT SiteID\n    FROM Artifact\n    GROUP BY SiteID\n    HAVING COUNT(ArtifactID) > 10\n) a ON e.SiteID = a.SiteID;\n```\n\n### Explanation:\n- The subquery `(SELECT SiteID FROM Artifact GROUP BY SiteID HAVING COUNT(ArtifactID) > 10)` calculates the number of artifacts for each `SiteID` and filters to include only those sites with more than 10 artifacts.\n- This result is then joined with the `ExcavationSite` table on `SiteID` to retrieve the site names along with their IDs.", "latency_sec": 5.012153148651123, "total_duration_sec": 5.007617609, "load_duration_sec": 0.017653393, "tokens_prompt": 273, "prompt_eval_sec": 0.04369173, "tokens_completion": 193, "completion_eval_sec": 4.945225038, "tokens_total": 466, "tokens_per_sec": 92.97401459598467, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns only SiteName, while the Generated SQL returns both SiteID and SiteName. Although both queries filter sites with more than 10 artifacts (which none have in the given data), their result sets differ in column structure. The Reference SQL also groups by SiteName (which could be problematic if SiteNames were non-unique) whereas the Generated SQL correctly groups by SiteID in the subquery.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly identify excavation sites with more than 10 artifacts. However, the generated query is more robust because it groups by SiteID (the primary key) in the subquery, ensuring accurate aggregation even if SiteNames were non-unique. The reference query groups by SiteName, which could produce incorrect results if multiple sites shared the same name. While both return the same results in the given dataset, the generated query better addresses the business intent by using the authoritative identifier (SiteID) and avoids potential semantic ambiguity.", "overall_assessment": "differently_correct"}}
{"example_id": 1086, "sql_complexity": "aggregation", "prompt": "What is the total CO2 emission for each equipment type, excluding equipment that is older than 8 years?", "context": "CREATE TABLE EmissionData (EquipmentID INT, EquipmentType VARCHAR(50), CO2Emission INT, Age INT); INSERT INTO EmissionData (EquipmentID, EquipmentType, CO2Emission, Age) VALUES (1, 'Excavator', 50, 8); INSERT INTO EmissionData (EquipmentID, EquipmentType, CO2Emission, Age) VALUES (2, 'Haul Truck', 70, 7); INSERT INTO EmissionData (EquipmentID, EquipmentType, CO2Emission, Age) VALUES (3, 'Shovel', 30, 6); INSERT INTO EmissionData (EquipmentID, EquipmentType, CO2Emission, Age) VALUES (4, 'Drilling Rig', 40, 3);", "reference_sql": "SELECT EquipmentType, SUM(CO2Emission) as TotalCO2Emission FROM EmissionData WHERE Age <= 8 GROUP BY EquipmentType;", "generated_sql": "SELECT EquipmentType, SUM(CO2Emission) AS TotalCO2Emission\nFROM EmissionData\nWHERE Age <= 8\nGROUP BY EquipmentType;", "raw_model_output": "To calculate the total CO2 emissions for each equipment type while excluding equipment that is older than 8 years, you can use the following SQL query:\n\n```sql\nSELECT EquipmentType, SUM(CO2Emission) AS TotalCO2Emission\nFROM EmissionData\nWHERE Age <= 8\nGROUP BY EquipmentType;\n```\n\nThis query works as follows:\n- It selects the `EquipmentType` and calculates the sum of `CO2Emission` for each type.\n- The `WHERE` clause filters out any equipment that is older than 8 years by ensuring only records with an `Age` less than or equal to 8 are included.\n- The `GROUP BY` clause groups the results by `EquipmentType`, allowing the sum of CO2 emissions to be calculated for each type.", "latency_sec": 4.271468877792358, "total_duration_sec": 4.264813672, "load_duration_sec": 0.020120816, "tokens_prompt": 254, "prompt_eval_sec": 0.037457092, "tokens_completion": 164, "completion_eval_sec": 4.205882653, "tokens_total": 418, "tokens_per_sec": 97.85860835208443, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The two queries are identical in structure and logic. They both select EquipmentType and sum CO2Emission with the same WHERE condition (Age <= 8) and GROUP BY clause. The only differences are formatting (line breaks, capitalization of keywords) which do not affect semantic meaning.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are identical in structure, logic, and output. They correctly filter equipment with Age <= 8 (excluding those older than 8 years) and calculate total CO2 emissions per EquipmentType. The WHERE clause aligns with the business requirement to exclude older equipment, and the GROUP BY ensures proper aggregation. Since the queries are identical, neither is more efficient or elegant than the other.", "overall_assessment": "correct"}}
{"example_id": 3455, "sql_complexity": "basic SQL", "prompt": "What are the names of all innovation projects in the 'rural_infrastructure' table, excluding those with a budget over 50000?", "context": "CREATE TABLE rural_infrastructure (name VARCHAR(255), budget INT); INSERT INTO rural_infrastructure (name, budget) VALUES ('Dam Construction', 40000), ('Well Digging', 30000), ('Irrigation System', 70000);", "reference_sql": "SELECT name FROM rural_infrastructure WHERE budget <= 50000;", "generated_sql": "SELECT name \nFROM rural_infrastructure \nWHERE budget <= 50000;", "raw_model_output": "To retrieve the names of all projects from the `rural_infrastructure` table that have a budget not exceeding 50,000, you can use the following SQL query:\n\n```sql\nSELECT name \nFROM rural_infrastructure \nWHERE budget <= 50000;\n```\n\nThis query selects the `name` column from the `rural_infrastructure` table and filters the results to include only those rows where the `budget` is less than or equal to 50,000.", "latency_sec": 2.493957042694092, "total_duration_sec": 2.489135608, "load_duration_sec": 0.020159369, "tokens_prompt": 152, "prompt_eval_sec": 0.02091626, "tokens_completion": 98, "completion_eval_sec": 2.447113051, "tokens_total": 250, "tokens_per_sec": 100.2423039852916, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries select the 'name' column from the 'rural_infrastructure' table where the 'budget' is less than or equal to 50000. The syntax, structure, and conditions are identical, resulting in the same output.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are structurally identical in terms of syntax, logic, and result set. The generated SQL is merely a formatted (line-break-separated) version of the reference query. The WHERE clause correctly filters projects with budget <= 50000, directly addressing the exclusion of projects over 50000 as required. Neither query has performance advantages over the other, and both perfectly align with the business intent of retrieving valid project names.", "overall_assessment": "correct"}}
{"example_id": 3936, "sql_complexity": "window functions", "prompt": "What is the total investment per client for each investment type?", "context": "CREATE TABLE clients (client_id INT, name TEXT, investment_type TEXT, investment FLOAT); INSERT INTO clients (client_id, name, investment_type, investment) VALUES (1, 'John Doe', 'Stocks', 3000.00), (1, 'John Doe', 'Bonds', 2000.00), (2, 'Jane Smith', 'Stocks', 5000.00);", "reference_sql": "SELECT client_id, name, investment_type, SUM(investment) OVER (PARTITION BY client_id, investment_type ORDER BY client_id) as total_investment FROM clients;", "generated_sql": "SELECT \n    client_id,\n    name,\n    investment_type,\n    SUM(investment) AS total_investment\nFROM \n    clients\nGROUP BY \n    client_id, \n    name, \n    investment_type;", "raw_model_output": "To calculate the total investment per client for each investment type, you can use a `GROUP BY` clause to group the results by both `client_id` and `investment_type`. Then, sum up the `investment` values within these groups. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    client_id,\n    name,\n    investment_type,\n    SUM(investment) AS total_investment\nFROM \n    clients\nGROUP BY \n    client_id, \n    name, \n    investment_type;\n```\n\nThis query will provide a list of each client along with their respective investment types and the total amount invested in each type.", "latency_sec": 3.3798828125, "total_duration_sec": 3.374948487, "load_duration_sec": 0.019003911, "tokens_prompt": 168, "prompt_eval_sec": 0.023338746, "tokens_completion": 133, "completion_eval_sec": 3.331648704, "tokens_total": 301, "tokens_per_sec": 89.05634209765964, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query uses a window function to calculate a running total within partitions, retaining all rows. The generated query groups rows, aggregating values and reducing the number of rows. While both calculate sums, the reference query preserves individual rows with repeated totals, whereas the generated query collapses rows into aggregated groups. This difference in output structure makes them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL uses a window function that calculates a running total within partitions, but does not collapse rows. This would return duplicate client-investment_type rows if multiple entries exist, whereas the Generated SQL properly aggregates values using GROUP BY. While both might return same results for the sample data, the Generated SQL is structurally correct for the business intent of summarizing totals. The GROUP BY approach is more efficient and semantically aligns with the requirement to 'total' investments per client/investment type.", "overall_assessment": "differently_correct"}}
{"example_id": 1838, "sql_complexity": "window functions", "prompt": "What are the top 3 species with the most sightings across all arctic research stations?", "context": "CREATE TABLE research_station (id INT, name TEXT); INSERT INTO research_station (id, name) VALUES (1, 'Station A'); INSERT INTO research_station (id, name) VALUES (2, 'Station B'); CREATE TABLE species_observations (station_id INT, species_name TEXT, sightings INT); INSERT INTO species_observations (station_id, species_name, sightings) VALUES (1, 'Species 1', 10); INSERT INTO species_observations (station_id, species_name, sightings) VALUES (1, 'Species 2', 5); INSERT INTO species_observations (station_id, species_name, sightings) VALUES (2, 'Species 1', 8); INSERT INTO species_observations (station_id, species_name, sightings) VALUES (2, 'Species 3', 15);", "reference_sql": "SELECT species_name, SUM(sightings) as total_sightings, RANK() OVER (ORDER BY SUM(sightings) DESC) as rank FROM species_observations GROUP BY species_name HAVING rank <= 3;", "generated_sql": "SELECT \n    species_name,\n    SUM(sightings) AS total_sightings\nFROM \n    species_observations\nGROUP BY \n    species_name\nORDER BY \n    total_sightings DESC\nLIMIT 3;", "raw_model_output": "To find the top 3 species with the most sightings across all Arctic research stations, you need to aggregate the total number of sightings for each species and then order them in descending order. Here's how you can write this query using standard ANSI SQL:\n\n```sql\nSELECT \n    species_name,\n    SUM(sightings) AS total_sightings\nFROM \n    species_observations\nGROUP BY \n    species_name\nORDER BY \n    total_sightings DESC\nLIMIT 3;\n```\n\n### Explanation:\n- **SELECT**: We select the `species_name` and calculate the sum of `sightings` for each species.\n- **SUM(sightings) AS total_sightings**: This calculates the total number of sightings per species across all stations.\n- **FROM species_observations**: The data is being pulled from the `species_observations` table.\n- **GROUP BY species_name**: We group the results by `species_name` to aggregate the sightings for each species.\n- **ORDER BY total_sightings DESC**: This orders the aggregated results in descending order based on the total number of sightings, so that species with the most sightings appear first.\n- **LIMIT 3**: This limits the result set to the top 3 species with the highest number of sightings.", "latency_sec": 6.739321947097778, "total_duration_sec": 6.734030496, "load_duration_sec": 0.020506475, "tokens_prompt": 256, "prompt_eval_sec": 0.042092731, "tokens_completion": 261, "completion_eval_sec": 6.670553482, "tokens_total": 517, "tokens_per_sec": 76.7139489785973, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses a HAVING clause with 'rank <= 3' which references a window function (RANK()) in a context where it's invalid. Window functions like RANK() cannot be used in HAVING clauses because they are evaluated after aggregation and grouping. The Generated SQL correctly orders and limits results, while the Reference SQL would likely throw an error or produce incorrect results due to invalid syntax.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL contains a critical technical error: the HAVING clause references 'rank' which is an alias from the SELECT clause, but SQL standards prohibit using column aliases in HAVING. The Generated SQL correctly groups, sums, orders, and limits without syntax issues. While both aim to find top species, the Reference SQL would fail execution. The Generated SQL directly addresses the business intent by returning the top 3 species with the highest total sightings through a straightforward approach.", "overall_assessment": "differently_correct"}}
{"example_id": 3091, "sql_complexity": "single join", "prompt": "Find the number of hybrid vehicles sold in the US, Germany, and Japan.", "context": "CREATE TABLE vehicle_sales (sale_id INT, vehicle_id INT, country VARCHAR(20), quantity INT); CREATE TABLE vehicles (vehicle_id INT, model VARCHAR(20), manufacture VARCHAR(20), vehicle_type VARCHAR(20));", "reference_sql": "SELECT SUM(vs.quantity) FROM vehicle_sales vs JOIN vehicles v ON vs.vehicle_id = v.vehicle_id WHERE v.vehicle_type = 'hybrid' AND vs.country IN ('US', 'Germany', 'Japan');", "generated_sql": "SELECT SUM(vs.quantity) AS total_hybrid_sales\nFROM vehicle_sales vs\nJOIN vehicles v ON vs.vehicle_id = v.vehicle_id\nWHERE v.vehicle_type = 'hybrid'\nAND vs.country IN ('US', 'Germany', 'Japan');", "raw_model_output": "To find the number of hybrid vehicles sold in the US, Germany, and Japan, we need to join the `vehicle_sales` table with the `vehicles` table on the `vehicle_id` column. We will filter for sales where the `country` is either 'US', 'Germany', or 'Japan' and where the `vehicle_type` is 'hybrid'. Finally, we'll sum up the `quantity` of these filtered records.\n\nHere's the SQL statement:\n\n```sql\nSELECT SUM(vs.quantity) AS total_hybrid_sales\nFROM vehicle_sales vs\nJOIN vehicles v ON vs.vehicle_id = v.vehicle_id\nWHERE v.vehicle_type = 'hybrid'\nAND vs.country IN ('US', 'Germany', 'Japan');\n```\n\nThis query performs the following steps:\n- Joins `vehicle_sales` and `vehicles` on `vehicle_id`.\n- Filters for records where `vehicle_type` is 'hybrid'.\n- Further filters for sales in 'US', 'Germany', or 'Japan'.\n- Sums up the `quantity` of these filtered sales to get the total number of hybrid vehicles sold.", "latency_sec": 5.713682174682617, "total_duration_sec": 5.70548831, "load_duration_sec": 0.011355633, "tokens_prompt": 133, "prompt_eval_sec": 0.017150353, "tokens_completion": 227, "completion_eval_sec": 5.676226623, "tokens_total": 360, "tokens_per_sec": 63.00665472699262, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. The only difference is the column alias 'total_hybrid_sales' in the Generated SQL, which does not affect the result's content. Both queries perform the same aggregation, join, and filtering operations.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the total quantity of hybrid vehicles sold in the specified countries by joining the relevant tables and applying the necessary filters. The reference query is functionally identical to the generated query, with the only difference being the addition of an explicit column alias ('total_hybrid_sales') in the generated version. This alias improves readability but does not alter the result. Neither query contains syntax errors or logical flaws. Both fulfill the business intent of counting hybrid vehicle sales in the US, Germany, and Japan. The efficiency and structure of both queries are equivalent, making them equally valid solutions.", "overall_assessment": "correct"}}
{"example_id": 2399, "sql_complexity": "set operations", "prompt": "What is the average duration of criminal trials for Indigenous defendants compared to non-Indigenous defendants in Canada and New Zealand?", "context": "CREATE TABLE canada_criminal_trials (id INT, defendant_type VARCHAR(255), days_to_completion INT); INSERT INTO canada_criminal_trials (id, defendant_type, days_to_completion) VALUES (1, 'Indigenous', 60), (2, 'Non-Indigenous', 45);CREATE TABLE nz_criminal_trials (id INT, defendant_type VARCHAR(255), days_to_completion INT); INSERT INTO nz_criminal_trials (id, defendant_type, days_to_completion) VALUES (1, 'Indigenous', 70), (2, 'Non-Indigenous', 50);", "reference_sql": "SELECT AVG(days_to_completion) AS avg_duration FROM canada_criminal_trials WHERE defendant_type = 'Indigenous' UNION ALL SELECT AVG(days_to_completion) AS avg_duration FROM canada_criminal_trials WHERE defendant_type = 'Non-Indigenous' UNION ALL SELECT AVG(days_to_completion) AS avg_duration FROM nz_criminal_trials WHERE defendant_type = 'Indigenous' UNION ALL SELECT AVG(days_to_completion) AS avg_duration FROM nz_criminal_trials WHERE defendant_type = 'Non-Indigenous';", "generated_sql": "SELECT \n    defendant_type,\n    AVG(days_to_completion) AS average_days_to_completion\nFROM (\n    SELECT \n        defendant_type, \n        days_to_completion \n    FROM \n        canada_criminal_trials\n    UNION ALL\n    SELECT \n        defendant_type, \n        days_to_completion \n    FROM \n        nz_criminal_trials\n) AS combined_trials\nGROUP BY \n    defendant_type;", "raw_model_output": "To find the average duration of criminal trials for Indigenous versus Non-Indigenous defendants in both Canada and New Zealand, we can use a `UNION ALL` query to combine data from both tables and then calculate the averages using a `GROUP BY` clause. Here's how you can write the SQL statement:\n\n```sql\nSELECT \n    defendant_type,\n    AVG(days_to_completion) AS average_days_to_completion\nFROM (\n    SELECT \n        defendant_type, \n        days_to_completion \n    FROM \n        canada_criminal_trials\n    UNION ALL\n    SELECT \n        defendant_type, \n        days_to_completion \n    FROM \n        nz_criminal_trials\n) AS combined_trials\nGROUP BY \n    defendant_type;\n```\n\nThis query does the following:\n- Uses `UNION ALL` to combine rows from both `canada_criminal_trials` and `nz_criminal_trials`.\n- Calculates the average `days_to_completion` for each `defendant_type` using `AVG()`.\n- Groups the results by `defendant_type` to get separate averages for Indigenous and Non-Indigenous defendants.", "latency_sec": 5.769038915634155, "total_duration_sec": 5.762093425, "load_duration_sec": 0.012280106, "tokens_prompt": 216, "prompt_eval_sec": 0.032762512, "tokens_completion": 225, "completion_eval_sec": 5.716379673, "tokens_total": 441, "tokens_per_sec": 76.4425420679492, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates separate averages for each defendant_type within each country (Canada and NZ), resulting in four rows. The Generated SQL combines both countries' data first and then averages by defendant_type, merging Indigenous and Non-Indigenous averages across countries. This leads to different results: the Reference SQL returns 60, 45, 70, 50, while the Generated SQL returns 65 (Indigenous) and 47.5 (Non-Indigenous).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The reference query correctly separates Canada and New Zealand data while calculating averages for each defendant type, producing four distinct rows (Canada Indigenous, Canada Non-Indigenous, NZ Indigenous, NZ Non-Indigenous). The generated query combines data from both countries into a single aggregation, resulting in only two rows (Indigenous and Non-Indigenous averages across both countries). This violates the original question's requirement to compare within each country. While the generated query is more concise, it fails to meet the business intent by collapsing geographic distinctions. The reference query is technically correct but less efficient due to repeated scans of the same table.", "overall_assessment": "differently_correct"}}
{"example_id": 2972, "sql_complexity": "set operations", "prompt": "How many indigenous communities are in the Arctic Research Station 13 and 14?", "context": "CREATE TABLE Arctic_Research_Station_13 (id INT, community TEXT); CREATE TABLE Arctic_Research_Station_14 (id INT, community TEXT);", "reference_sql": "SELECT COUNT(DISTINCT community) FROM Arctic_Research_Station_13; SELECT COUNT(DISTINCT community) FROM Arctic_Research_Station_14; SELECT COUNT(DISTINCT community) FROM (SELECT * FROM Arctic_Research_Station_13 UNION ALL SELECT * FROM Arctic_Research_Station_14) AS Arctic_Communities;", "generated_sql": "SELECT COUNT(DISTINCT community) AS total_unique_communities\nFROM (\n    SELECT community FROM Arctic_Research_Station_13\n    UNION\n    SELECT community FROM Arctic_Research_Station_14\n) AS combined_communities;", "raw_model_output": "To find out how many distinct indigenous communities are present in both Arctic Research Station 13 and 14, you can use a `UNION` to combine the results from both tables and then count the unique entries. Here's the SQL statement:\n\n```sql\nSELECT COUNT(DISTINCT community) AS total_unique_communities\nFROM (\n    SELECT community FROM Arctic_Research_Station_13\n    UNION\n    SELECT community FROM Arctic_Research_Station_14\n) AS combined_communities;\n```\n\nThis query works as follows:\n- The `UNION` operator is used to combine the communities from both tables, ensuring that duplicates are removed.\n- The outer query then counts the distinct communities in this combined result set.", "latency_sec": 3.6813220977783203, "total_duration_sec": 3.676809573, "load_duration_sec": 0.011721303, "tokens_prompt": 120, "prompt_eval_sec": 0.015209158, "tokens_completion": 147, "completion_eval_sec": 3.649245654, "tokens_total": 267, "tokens_per_sec": 72.52829089884165, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count the number of distinct 'community' values across both tables. The Reference SQL's third query uses UNION ALL (which includes duplicates) but applies COUNT(DISTINCT), while the Generated SQL uses UNION (which removes duplicates between the two selects) and then COUNT(DISTINCT). Since COUNT(DISTINCT) inherently eliminates duplicates, both approaches yield the same result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly count unique indigenous communities across stations 13 and 14. The reference SQL achieves this through three separate queries (individual counts + combined count with UNION ALL), while the generated SQL uses a single, more efficient query with UNION to eliminate duplicates before counting. The generated query is more elegant and efficient as it avoids unnecessary UNION ALL followed by COUNT(DISTINCT), which is logically equivalent but less optimal. Both fulfill the business intent of determining total unique communities, but the generated query better addresses the question with cleaner logic.", "overall_assessment": "correct"}}
{"example_id": 5576, "sql_complexity": "window functions", "prompt": "Who are the top 5 users with the most followers, and what is their location?", "context": "CREATE TABLE user_data (user_id INT, name VARCHAR(50), followers INT, location VARCHAR(50)); INSERT INTO user_data (user_id, name, followers, location) VALUES (1, 'Alice', 10000, 'New York'), (2, 'Bob', 15000, 'California'), (3, 'Charlie', 12000, 'Texas'), (4, 'David', 8000, 'Florida'), (5, 'Eve', 9000, 'Illinois');", "reference_sql": "SELECT name, location FROM (SELECT name, location, ROW_NUMBER() OVER (ORDER BY followers DESC) AS rank FROM user_data) AS user_ranks WHERE rank <= 5;", "generated_sql": "SELECT name, followers, location\nFROM user_data\nORDER BY followers DESC\nLIMIT 5;", "raw_model_output": "To find the top 5 users with the most followers along with their locations from the `user_data` table, you can use the following SQL query:\n\n```sql\nSELECT name, followers, location\nFROM user_data\nORDER BY followers DESC\nLIMIT 5;\n```\n\nThis query selects the `name`, `followers`, and `location` columns from the `user_data` table. It orders the results in descending order based on the number of `followers` to ensure that users with the most followers are at the top. Finally, it limits the result set to the top 5 records using the `LIMIT` clause.", "latency_sec": 3.2917659282684326, "total_duration_sec": 3.284192008, "load_duration_sec": 0.021584114, "tokens_prompt": 195, "prompt_eval_sec": 0.031404806, "tokens_completion": 128, "completion_eval_sec": 3.230179774, "tokens_total": 323, "tokens_per_sec": 98.123623319082, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL returns only 'name' and 'location' columns with a rank-based filter, while the Generated SQL includes 'followers' and uses LIMIT 5. The result sets differ in both column structure and ranking methodology (ROW_NUMBER() vs. simple ordering/limit).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent. The Reference SQL correctly returns only 'name' and 'location' columns as requested, using a window function to rank users. The Generated SQL includes an extra 'followers' column not requested in the original question. While both would return the top 5 users by followers, the Generated query's additional column makes it semantically incorrect for the business intent. The Reference query better fulfills the requirement by explicitly selecting only the requested fields. The Generated query is more efficient but fails to meet the exact output specification.", "overall_assessment": "differently_correct"}}
{"example_id": 1560, "sql_complexity": "basic SQL", "prompt": "What is the average media literacy score for users in the 'Young Adult' age group who have completed at least one disinformation detection course?", "context": "CREATE TABLE users (id INT, age VARCHAR(20), media_literacy_score INT, courses_completed INT);", "reference_sql": "SELECT AVG(media_literacy_score) FROM users WHERE age = 'Young Adult' AND courses_completed > 0;", "generated_sql": "SELECT AVG(media_literacy_score) AS average_media_literacy_score\nFROM users\nWHERE age = 'Young Adult' AND courses_completed >= 1;", "raw_model_output": "To solve this problem, we need to calculate the average `media_literacy_score` for users who meet two criteria: they belong to the 'Young Adult' age group and have completed at least one course. Assuming that completing a course is represented by having `courses_completed` greater than or equal to 1, here's how you can write the SQL query:\n\n```sql\nSELECT AVG(media_literacy_score) AS average_media_literacy_score\nFROM users\nWHERE age = 'Young Adult' AND courses_completed >= 1;\n```\n\nThis query does the following:\n- Selects the `media_literacy_score` from the `users` table.\n- Filters the results to include only those rows where the `age` is 'Young Adult'.\n- Further filters these results to include only users who have completed at least one course (`courses_completed >= 1`).\n- Calculates the average of the filtered `media_literacy_score` values using the `AVG()` function.", "latency_sec": 5.088669776916504, "total_duration_sec": 5.083761557, "load_duration_sec": 0.01226654, "tokens_prompt": 123, "prompt_eval_sec": 0.016809924, "tokens_completion": 203, "completion_eval_sec": 5.054070906, "tokens_total": 326, "tokens_per_sec": 64.06389376626848, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "The conditions 'courses_completed > 0' and 'courses_completed >= 1' are mathematically equivalent for integer values. Both filter rows where courses_completed is a positive integer. The generated query adds an alias to the output column, which does not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as 'courses_completed > 0' and 'courses_completed >= 1' produce identical filtering results. The generated query adds an explicit alias ('average_media_literacy_score') which improves readability but doesn't alter functionality. Both correctly address the business intent by calculating the average media literacy score for 'Young Adult' users with at least one completed course. The reference query is functionally identical but lacks the alias. Neither query has efficiency issues given the simple schema and conditions.", "overall_assessment": "correct"}}
{"example_id": 1201, "sql_complexity": "basic SQL", "prompt": "What is the maximum energy efficiency rating of hydroelectric dams in Canada?", "context": "CREATE TABLE hydro_dams (id INT, name TEXT, country TEXT, energy_efficiency_rating FLOAT); INSERT INTO hydro_dams (id, name, country, energy_efficiency_rating) VALUES (1, 'Robert-Bourassa', 'Canada', 0.94), (2, 'Churchill Falls', 'Canada', 0.92);", "reference_sql": "SELECT MAX(energy_efficiency_rating) FROM hydro_dams WHERE country = 'Canada';", "generated_sql": "SELECT MAX(energy_efficiency_rating) AS max_energy_efficiency_rating\nFROM hydro_dams\nWHERE country = 'Canada';", "raw_model_output": "To find the maximum energy efficiency rating of hydroelectric dams in Canada from the `hydro_dams` table, you can use the following SQL query:\n\n```sql\nSELECT MAX(energy_efficiency_rating) AS max_energy_efficiency_rating\nFROM hydro_dams\nWHERE country = 'Canada';\n```\n\nThis query selects the highest value of the `energy_efficiency_rating` column for rows where the `country` is 'Canada'. The result will be labeled as `max_energy_efficiency_rating`.", "latency_sec": 2.5743961334228516, "total_duration_sec": 2.570558911, "load_duration_sec": 0.01802649, "tokens_prompt": 158, "prompt_eval_sec": 0.020168138, "tokens_completion": 101, "completion_eval_sec": 2.531489791, "tokens_total": 259, "tokens_per_sec": 100.60611754246236, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the maximum energy_efficiency_rating from hydro_dams where country is 'Canada'. The generated query adds an alias (max_energy_efficiency_rating) to the column, but this does not affect the semantic result - the value returned remains the same maximum rating.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries correctly calculate the maximum energy efficiency rating for Canadian hydroelectric dams. The reference query is more concise, while the generated query adds an explicit column alias. The alias in the generated query improves readability but does not alter the result. Both queries filter the same dataset, apply the same aggregation function, and return identical numerical values. The difference in column naming has no impact on the business intent of identifying the maximum rating.", "overall_assessment": "correct"}}
{"example_id": 4243, "sql_complexity": "single join", "prompt": "How many orders were placed by new and returning customers in each month of the year 2021?'", "context": "CREATE TABLE customer (id INT, first_order_date DATE, last_order_date DATE);", "reference_sql": "INSERT INTO customer (id, first_order_date, last_order_date) SELECT customer_id, MIN(order_date) AS first_order_date, MAX(order_date) AS last_order_date FROM orders GROUP BY customer_id; SELECT YEAR(order_date) AS year, MONTH(order_date) AS month, CASE WHEN DATEDIFF(last_order_date, first_order_date) > 30 THEN 'returning' ELSE 'new' END AS customer_type, COUNT(DISTINCT id) AS num_orders FROM orders JOIN customer ON orders.customer_id = customer.id WHERE YEAR(order_date) = 2021 GROUP BY year, month, customer_type;", "generated_sql": "SELECT \n    EXTRACT(YEAR FROM first_order_date) AS order_year,\n    EXTRACT(MONTH FROM first_order_date) AS order_month,\n    COUNT(CASE WHEN EXTRACT(YEAR FROM first_order_date) = 2021 THEN id END) AS new_customers,\n    COUNT(CASE WHEN (EXTRACT(YEAR FROM last_order_date) < 2021 OR \n                     (EXTRACT(YEAR FROM last_order_date) = 2021 AND EXTRACT(MONTH FROM last_order_date) < EXTRACT(MONTH FROM first_order_date))) THEN id END) AS returning_customers\nFROM \n    customer\nWHERE \n    first_order_date BETWEEN '2021-01-01' AND '2021-12-31'\nGROUP BY \n    order_year, order_month\nORDER BY \n    order_month;", "raw_model_output": "To solve this problem, we need to determine how many orders were placed by \"new\" and \"returning\" customers for each month in the year 2021. A customer is considered \"new\" if their first order date falls within that month of 2021; otherwise, they are considered a \"returning\" customer.\n\nHere's the SQL query to achieve this:\n\n```sql\nSELECT \n    EXTRACT(YEAR FROM first_order_date) AS order_year,\n    EXTRACT(MONTH FROM first_order_date) AS order_month,\n    COUNT(CASE WHEN EXTRACT(YEAR FROM first_order_date) = 2021 THEN id END) AS new_customers,\n    COUNT(CASE WHEN (EXTRACT(YEAR FROM last_order_date) < 2021 OR \n                     (EXTRACT(YEAR FROM last_order_date) = 2021 AND EXTRACT(MONTH FROM last_order_date) < EXTRACT(MONTH FROM first_order_date))) THEN id END) AS returning_customers\nFROM \n    customer\nWHERE \n    first_order_date BETWEEN '2021-01-01' AND '2021-12-31'\nGROUP BY \n    order_year, order_month\nORDER BY \n    order_month;\n```\n\n### Explanation:\n\n1. **EXTRACT Function**: We use the `EXTRACT` function to get the year and month from the `first_order_date`.\n\n2. **Filtering by Year**: The `WHERE` clause ensures we only consider orders where the `first_order_date` is within 2021.\n\n3. **Counting New Customers**:\n   - We count customers whose `first_order_date` falls in each month of 2021 using a conditional `COUNT`.\n\n4. **Counting Returning Customers**:\n   - A customer is considered returning if their `last_order_date` is before 2021 or, within 2021, occurs before the current month being evaluated.\n   - This logic ensures that we only count customers who had orders prior to the current month in 2021.\n\n5. **Grouping and Ordering**:\n   - We group by year and month to get counts for each month of 2021.\n   - The results are ordered by `order_month` to present them chronologically.", "latency_sec": 11.608031034469604, "total_duration_sec": 11.603350015, "load_duration_sec": 0.016219924, "tokens_prompt": 109, "prompt_eval_sec": 0.015951098, "tokens_completion": 460, "completion_eval_sec": 11.570310124, "tokens_total": 569, "tokens_per_sec": 49.01778762568572, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The reference query calculates customer type based on the date difference between first and last orders, while the generated query uses year/month comparisons. The generated query also incorrectly defines 'returning' customers with a flawed condition (last_order_date before first_order_date's month in same year). Additionally, the reference query analyzes orders in 2021, while the generated query focuses on customers with first orders in 2021, leading to different data sources and logic.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "equal", "explanation": "The queries are not technically equivalent. The reference SQL contains an INSERT statement that modifies the customer table, while the generated SQL is a standalone SELECT. Both queries fail to count orders (as required by the question) and instead count customers. The reference SQL incorrectly uses DATEDIFF(last_order_date, first_order_date) > 30 to determine 'returning' customers, which doesn't align with the question's requirement to analyze orders per month. The generated SQL misuses first_order_date to filter customers, ignoring the actual order dates. Neither query accurately addresses the business intent of counting orders by customer type per month.", "overall_assessment": "incorrect"}}
{"example_id": 2321, "sql_complexity": "subqueries", "prompt": "What are the names and types of vessels used in research expeditions in the regions with the lowest ocean acidification levels?", "context": "CREATE TABLE ocean_acidification (id INT PRIMARY KEY, region VARCHAR(255), year INT, acidification_level INT); INSERT INTO ocean_acidification (id, region, year, acidification_level) VALUES (1, 'Arctic Ocean', 2018, 20), (2, 'Southern Ocean', 2019, 22); CREATE TABLE expedition_vessels (id INT PRIMARY KEY, name VARCHAR(255), type VARCHAR(255), region VARCHAR(255)); INSERT INTO expedition_vessels (id, name, type, region) VALUES (1, 'Sea Researcher', 'Research Vessel', 'Arctic Ocean');", "reference_sql": "SELECT v.name, v.type FROM expedition_vessels v INNER JOIN ocean_acidification oa ON v.region = oa.region WHERE oa.acidification_level = (SELECT MIN(acidification_level) FROM ocean_acidification);", "generated_sql": "SELECT name, type\nFROM expedition_vessels\nWHERE region IN (\n    SELECT region\n    FROM ocean_acidification\n    WHERE acidification_level = (\n        SELECT MIN(acidification_level)\n        FROM ocean_acidification\n    )\n);", "raw_model_output": "To solve this problem, we need to identify the region(s) with the lowest ocean acidification level from the `ocean_acidification` table. Then, using that information, we will find the names and types of vessels from the `expedition_vessels` table that are used in those regions.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT name, type\nFROM expedition_vessels\nWHERE region IN (\n    SELECT region\n    FROM ocean_acidification\n    WHERE acidification_level = (\n        SELECT MIN(acidification_level)\n        FROM ocean_acidification\n    )\n);\n```\n\n### Explanation:\n1. **Subquery to Find Minimum Acidification Level:**\n   - The innermost subquery `SELECT MIN(acidification_level) FROM ocean_acidification` finds the lowest acidification level across all records.\n\n2. **Subquery to Identify Regions with Lowest Acidification Level:**\n   - The next subquery `SELECT region FROM ocean_acidification WHERE acidification_level = (...)` identifies which regions have this minimum acidification level.\n\n3. **Main Query to Retrieve Vessel Information:**\n   - Finally, the main query selects `name` and `type` from the `expedition_vessels` table where the `region` matches any of those identified in the previous subquery. This ensures we only get vessels operating in regions with the lowest acidification levels.", "latency_sec": 7.495059013366699, "total_duration_sec": 7.487945593, "load_duration_sec": 0.018552753, "tokens_prompt": 229, "prompt_eval_sec": 0.038945292, "tokens_completion": 292, "completion_eval_sec": 7.429420811, "tokens_total": 521, "tokens_per_sec": 69.51246135231862, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL performs an INNER JOIN between expedition_vessels and ocean_acidification on region, filtering for rows where acidification_level equals the minimum value. This can return duplicate vessel entries if multiple ocean_acidification records exist for the same region with the minimum level. The Generated SQL uses a subquery to find regions with the minimum acidification_level and selects vessels in those regions, ensuring each vessel is returned once regardless of how many matching ocean_acidification records exist. Thus, the queries may produce different results when multiple ocean_acidification entries exist for the same region with the minimum level.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The Reference SQL uses an INNER JOIN with a direct equality condition on acidification_level = (SELECT MIN(...)), which could return duplicate vessel entries if a region has multiple ocean_acidification records with the same minimum level. The Generated SQL uses a subquery with IN to first identify regions with the minimum acidification level, ensuring each region is considered once. This avoids duplicates and is more efficient. Both fulfill the business intent by identifying vessels in regions with the lowest acidification levels, but the Generated SQL is more precise and elegant.", "overall_assessment": "differently_correct"}}
{"example_id": 4349, "sql_complexity": "multiple_joins", "prompt": "Show the research grants awarded to professors in the Computer Science department.", "context": "CREATE TABLE departments (id INT, name VARCHAR(50)); INSERT INTO departments (id, name) VALUES (1, 'Computer Science'), (2, 'Mathematics'); CREATE TABLE professors (id INT, name VARCHAR(50), department_id INT); INSERT INTO professors (id, name, department_id) VALUES (1, 'John Smith', 1), (2, 'Jane Doe', 2); CREATE TABLE grants (id INT, professor_id INT, year INT, amount FLOAT); INSERT INTO grants (id, professor_id, year, amount) VALUES (1, 1, 2021, 5000.0), (2, 2, 2020, 7000.0);", "reference_sql": "SELECT professors.name, grants.amount FROM professors INNER JOIN grants ON professors.id = grants.professor_id INNER JOIN departments ON professors.department_id = departments.id WHERE departments.name = 'Computer Science';", "generated_sql": "SELECT g.id AS grant_id, p.name AS professor_name, g.year, g.amount\nFROM grants g\nJOIN professors p ON g.professor_id = p.id\nJOIN departments d ON p.department_id = d.id\nWHERE d.name = 'Computer Science';", "raw_model_output": "To show the research grants awarded to professors in the Computer Science department, we need to join the `departments`, `professors`, and `grants` tables based on their relationships. Specifically, we will:\n\n1. Join the `departments` table with the `professors` table using the `department_id`.\n2. Further join the resulting set with the `grants` table using the `professor_id`.\n3. Filter the results to include only those professors who belong to the Computer Science department.\n\nHere is the SQL statement that accomplishes this:\n\n```sql\nSELECT g.id AS grant_id, p.name AS professor_name, g.year, g.amount\nFROM grants g\nJOIN professors p ON g.professor_id = p.id\nJOIN departments d ON p.department_id = d.id\nWHERE d.name = 'Computer Science';\n```\n\nThis query retrieves the `id`, `name`, `year`, and `amount` of each grant awarded to professors in the Computer Science department. The joins ensure that we correctly associate grants with their respective professors and departments, while the `WHERE` clause filters for the specific department name.", "latency_sec": 5.9433979988098145, "total_duration_sec": 5.937429209, "load_duration_sec": 0.011644115, "tokens_prompt": 231, "prompt_eval_sec": 0.040785228, "tokens_completion": 231, "completion_eval_sec": 5.883938118, "tokens_total": 462, "tokens_per_sec": 77.73331015229286, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL selects only 'professors.name' and 'grants.amount', while the Generated SQL selects additional columns ('g.id', 'g.year') and uses different column aliases. Although both filter for 'Computer Science' department, the result sets differ in column structure and content.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent because they select different columns (reference includes only professor name and grant amount; generated includes grant ID, year, and professor name). Both correctly join the three tables and filter for 'Computer Science' department. The generated query better fulfills the business intent by providing more comprehensive grant details (ID, year) which are relevant to research grants. While the reference query is technically correct, the generated query's additional fields make it more informative for analyzing grant data. Both queries are efficient and well-structured, but the generated version's explicit aliases and additional columns provide better clarity and completeness.", "overall_assessment": "differently_correct"}}
{"example_id": 476, "sql_complexity": "basic SQL", "prompt": "Insert new food safety records for locations \"A123\", \"B456\", and \"C789\"", "context": "CREATE TABLE food_safety_records (id INT, location VARCHAR(255), inspection_date DATE, violation_count INT);", "reference_sql": "INSERT INTO food_safety_records (location, inspection_date, violation_count) VALUES ('A123', '2022-03-01', 0), ('B456', '2022-03-05', 2), ('C789', '2022-03-10', 1);", "generated_sql": "INSERT INTO food_safety_records (id, location, inspection_date, violation_count)\nVALUES \n(1, 'A123', '2023-10-01', 0), -- Replace with actual id, date, and count\n(2, 'B456', '2023-10-02', 0), -- Replace with actual id, date, and count\n(3, 'C789', '2023-10-03', 0); -- Replace with actual id, date, and count", "raw_model_output": "To insert new food safety records into the `food_safety_records` table for the specified locations (\"A123\", \"B456\", and \"C789\"), you need to provide values for all columns in the table: `id`, `location`, `inspection_date`, and `violation_count`. Since specific values for `id`, `inspection_date`, and `violation_count` are not provided, I'll use placeholders. You can replace these with actual values as needed.\n\nHere's an example SQL statement to insert records:\n\n```sql\nINSERT INTO food_safety_records (id, location, inspection_date, violation_count)\nVALUES \n(1, 'A123', '2023-10-01', 0), -- Replace with actual id, date, and count\n(2, 'B456', '2023-10-02', 0), -- Replace with actual id, date, and count\n(3, 'C789', '2023-10-03', 0); -- Replace with actual id, date, and count\n```\n\nMake sure to replace the `id`, `inspection_date`, and `violation_count` values with appropriate data for your use case.", "latency_sec": 6.1563568115234375, "total_duration_sec": 6.151212073, "load_duration_sec": 0.017986941, "tokens_prompt": 115, "prompt_eval_sec": 0.016343907, "tokens_completion": 245, "completion_eval_sec": 6.115969837, "tokens_total": 360, "tokens_per_sec": 58.476142793762996, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL inserts specific violation counts (0, 2, 1) with inspection dates in 2022, while the Generated SQL inserts all 0 violation counts with 2023 dates. Additionally, the Generated SQL explicitly includes ID values (1, 2, 3) which are not present in the Reference SQL. The data content and values differ significantly between the two queries.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent. The reference SQL correctly inserts records without specifying the 'id' column, which is likely auto-incremented, while the generated SQL explicitly includes 'id' values and placeholder dates (2023) with comments indicating incomplete data. The reference query uses specific dates (2022) and violation counts directly, aligning with the business intent to insert concrete records. The generated SQL's placeholders and explicit 'id' values introduce ambiguity, as the original question did not mention needing specific IDs or future dates. Both fulfill the intent of inserting records for the specified locations, but the reference is more precise and aligned with typical database design practices.", "overall_assessment": "correct"}}
{"example_id": 2908, "sql_complexity": "single join", "prompt": "List all co-owners and the properties they own in New York, NY.", "context": "CREATE TABLE properties (id INT, city VARCHAR(50), price INT); CREATE TABLE co_owners (property_id INT, owner_name VARCHAR(50)); INSERT INTO properties (id, city, price) VALUES (1, 'New York', 800000), (2, 'Los Angeles', 600000); INSERT INTO co_owners (property_id, owner_name) VALUES (1, 'David'), (1, 'Ella'), (2, 'Frank');", "reference_sql": "SELECT properties.city, co_owners.owner_name FROM properties INNER JOIN co_owners ON properties.id = co_owners.property_id WHERE properties.city = 'New York';", "generated_sql": "SELECT co_owners.owner_name, properties.id AS property_id, properties.city, properties.price\nFROM co_owners\nJOIN properties ON co_owners.property_id = properties.id\nWHERE properties.city = 'New York';", "raw_model_output": "To solve this problem, we need to retrieve information about co-owners who own properties located in New York. We will join the `properties` table with the `co_owners` table based on the property ID and filter for those properties that are located in 'New York'. Here is the SQL query:\n\n```sql\nSELECT co_owners.owner_name, properties.id AS property_id, properties.city, properties.price\nFROM co_owners\nJOIN properties ON co_owners.property_id = properties.id\nWHERE properties.city = 'New York';\n```\n\nThis query performs the following steps:\n1. Joins the `co_owners` table with the `properties` table using the common column `property_id` from `co_owners` and `id` from `properties`.\n2. Filters the results to include only those rows where the city is 'New York'.\n3. Selects the owner's name, property ID, city, and price for each co-owner of properties in New York.", "latency_sec": 5.132340908050537, "total_duration_sec": 5.127653207, "load_duration_sec": 0.02080277, "tokens_prompt": 184, "prompt_eval_sec": 0.023839091, "tokens_completion": 202, "completion_eval_sec": 5.081948582, "tokens_total": 386, "tokens_per_sec": 75.20934538750619, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL returns only 'city' and 'owner_name' columns, while the Generated SQL includes additional columns ('id', 'price') and different column ordering. The result sets have different structures, even though both filter properties in 'New York'.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent because the generated query includes additional columns (property_id, price) not present in the reference. Both correctly join properties and co_owners tables with the same WHERE condition, but the generated query provides more detailed property information. The business intent to list co-owners and their properties in New York is fulfilled by both, though the generated query offers richer data. The reference query is simpler but may lack some property details that could be relevant.", "overall_assessment": "differently_correct"}}
{"example_id": 636, "sql_complexity": "set operations", "prompt": "Insert new data into the 'cosmetic_ingredients' table for a vegan eyeshadow product by brand 'Ara' with ingredients 'Mica', 'Iron Oxide', 'Titanium Dioxide' and 'Zinc Oxide'.", "context": "CREATE TABLE cosmetic_ingredients (ingredient_id INT, product_name TEXT, brand_name TEXT, ingredient_type TEXT);", "reference_sql": "INSERT INTO cosmetic_ingredients (ingredient_id, product_name, brand_name, ingredient_type) VALUES (NULL, 'Vegan Eyeshadow', 'Ara', 'Ingredient'); INSERT INTO cosmetic_ingredients (ingredient_id, product_name, brand_name, ingredient_type, ingredient_name) SELECT ingredient_id, 'Vegan Eyeshadow', 'Ara', 'Ingredient', 'Mica' FROM cosmetic_ingredients WHERE ingredient_name = 'Mica' UNION ALL SELECT NULL, 'Vegan Eyeshadow', 'Ara', 'Ingredient', 'Iron Oxide' UNION ALL SELECT NULL, 'Vegan Eyeshadow', 'Ara', 'Ingredient', 'Titanium Dioxide' UNION ALL SELECT NULL, 'Vegan Eyeshadow', 'Ara', 'Ingredient', 'Zinc Oxide';", "generated_sql": "INSERT INTO cosmetic_ingredients (ingredient_id, product_name, brand_name, ingredient_type)\nVALUES \n(1, 'Vegan Eyeshadow', 'Ara', 'Mica'),\n(2, 'Vegan Eyeshadow', 'Ara', 'Iron Oxide'),\n(3, 'Vegan Eyeshadow', 'Ara', 'Titanium Dioxide'),\n(4, 'Vegan Eyeshadow', 'Ara', 'Zinc Oxide');", "raw_model_output": "To insert multiple rows of data into the `cosmetic_ingredient` table, you can use an `INSERT INTO` statement. Since each ingredient needs its own row with a unique `ingredient_id`, we'll assume that these IDs are not auto-incremented and must be provided manually or generated in some other way. For simplicity, I will assign sequential IDs starting from 1 for this example.\n\nHere's the SQL statement to insert the data:\n\n```sql\nINSERT INTO cosmetic_ingredients (ingredient_id, product_name, brand_name, ingredient_type)\nVALUES \n(1, 'Vegan Eyeshadow', 'Ara', 'Mica'),\n(2, 'Vegan Eyeshadow', 'Ara', 'Iron Oxide'),\n(3, 'Vegan Eyeshadow', 'Ara', 'Titanium Dioxide'),\n(4, 'Vegan Eyeshadow', 'Ara', 'Zinc Oxide');\n```\n\nThis statement inserts four rows into the `cosmetic_ingredients` table, each with a unique `ingredient_id`, and associates them all with the product name \"Vegan Eyeshadow\" from brand \"Ara\". The `ingredient_type` column is populated with the respective ingredient names. Adjust the `ingredient_id` values as necessary based on your specific requirements or constraints.", "latency_sec": 6.768156290054321, "total_duration_sec": 6.762806131, "load_duration_sec": 0.020943839, "tokens_prompt": 143, "prompt_eval_sec": 0.017215375, "tokens_completion": 268, "completion_eval_sec": 6.723628868, "tokens_total": 411, "tokens_per_sec": 60.72554804976309, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL attempts to insert rows with 'Ingredient' as the ingredient_type and includes an invalid 'ingredient_name' column (not present in the schema). The Generated SQL inserts specific ingredient names directly into the ingredient_type column with explicit ingredient_id values. The data structure and values differ significantly, particularly in how ingredient types are represented and the presence of invalid columns.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL contains critical errors: it references a non-existent 'ingredient_name' column in the schema and uses an invalid SELECT statement structure. The Generated SQL is syntactically correct, inserts all required ingredients as separate rows, and aligns with the schema's structure (though it misuses 'ingredient_type' to store ingredient names instead of categories). While both queries aim to insert data, only the Generated SQL executes without errors. The Reference SQL fails due to schema mismatch and logical flaws.", "overall_assessment": "incorrect"}}
{"example_id": 3404, "sql_complexity": "multiple_joins", "prompt": "What are the names of startups that have received funding from investors with over 3 million funds, and are involved in Genetic Research or Bioprocess Engineering?", "context": "CREATE TABLE public.investors ( id SERIAL PRIMARY KEY, name VARCHAR(100), type VARCHAR(50), funds INTEGER ); CREATE TABLE public.investments ( id SERIAL PRIMARY KEY, investor_id INTEGER, startup_id INTEGER ); CREATE TABLE public.startups ( id SERIAL PRIMARY KEY, name VARCHAR(100), industry VARCHAR(50), funding INTEGER );", "reference_sql": "SELECT startups.name FROM public.startups JOIN public.investments ON startups.id = investments.startup_id JOIN public.investors ON investments.investor_id = investors.id WHERE (startups.industry = 'Genetic Research' OR startups.industry = 'Bioprocess Engineering') AND investors.funds > 3000000;", "generated_sql": "SELECT DISTINCT s.name\nFROM startups s\nJOIN investments i ON s.id = i.startup_id\nJOIN investors inv ON i.investor_id = inv.id\nWHERE inv.funds > 3000000\nAND (s.industry = 'Genetic Research' OR s.industry = 'Bioprocess Engineering');", "raw_model_output": "To find the names of startups that have received funding from investors with over 3 million funds and are involved in either \"Genetic Research\" or \"Bioprocess Engineering\", we need to join the `investors`, `investments`, and `startups` tables. Here's how you can construct the SQL query:\n\n```sql\nSELECT DISTINCT s.name\nFROM startups s\nJOIN investments i ON s.id = i.startup_id\nJOIN investors inv ON i.investor_id = inv.id\nWHERE inv.funds > 3000000\nAND (s.industry = 'Genetic Research' OR s.industry = 'Bioprocess Engineering');\n```\n\n### Explanation:\n- **Joins**: We join the `startups` table with the `investments` table on `startup_id`, and then join the resulting set with the `investors` table on `investor_id`.\n- **Filtering**:\n  - We filter investors who have more than 3 million funds (`inv.funds > 3000000`).\n  - We also filter startups that are in either \"Genetic Research\" or \"Bioprocess Engineering\" industries.\n- **Distinct**: We use `DISTINCT` to ensure each startup name appears only once in the result, even if it has multiple qualifying investors.", "latency_sec": 6.8101420402526855, "total_duration_sec": 6.801969649, "load_duration_sec": 0.019199055, "tokens_prompt": 172, "prompt_eval_sec": 0.024464519, "tokens_completion": 268, "completion_eval_sec": 6.756817276, "tokens_total": 440, "tokens_per_sec": 64.60951877351359, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in the use of DISTINCT. The generated query explicitly removes duplicates with DISTINCT, while the reference query does not. If the joins produce multiple identical startup names (e.g., due to multiple investments by the same investor in the same startup), the generated query would return fewer rows than the reference query. This makes them semantically non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "While both queries share the same core logic and structure, the generated query includes DISTINCT which ensures unique startup names, addressing potential duplicate results from multiple investments. The reference query lacks this, potentially returning duplicates if a startup has multiple qualifying investors. Both meet the business intent of identifying startups in specified industries with funding from high-fund investors, but the generated query's DISTINCT clause makes it more robust for real-world data scenarios. The generated query also uses clearer table aliases, improving readability without affecting functionality.", "overall_assessment": "differently_correct"}}
{"example_id": 134, "sql_complexity": "subqueries", "prompt": "Who are the top 3 authors with the most citations in the Mathematics department in the past 5 years?", "context": "CREATE TABLE authors (id INT, name VARCHAR(50), department VARCHAR(50)); INSERT INTO authors (id, name, department) VALUES (1, 'Author Name', 'Mathematics'); CREATE TABLE publications (id INT, title VARCHAR(100), author VARCHAR(50), journal VARCHAR(50), year INT, cites INT); INSERT INTO publications (id, title, author, journal, year, cites) VALUES (1, 'Publication Title', 'Author Name', 'Journal Name', 2021, 10);", "reference_sql": "SELECT author, SUM(cites) as total_cites FROM publications WHERE author IN (SELECT name FROM authors WHERE department = 'Mathematics') AND year BETWEEN YEAR(CURRENT_DATE) - 5 AND YEAR(CURRENT_DATE) GROUP BY author ORDER BY total_cites DESC LIMIT 3;", "generated_sql": "SELECT a.name, SUM(p.cites) AS total_citations\nFROM authors a\nJOIN publications p ON a.name = p.author\nWHERE a.department = 'Mathematics'\nAND p.year >= YEAR(CURDATE()) - 5\nGROUP BY a.id, a.name\nORDER BY total_citations DESC\nLIMIT 3;", "raw_model_output": "To solve this problem, we need to identify authors from the \"Mathematics\" department and then calculate their total number of citations for publications within the last 5 years. We will join the `authors` table with the `publications` table on the author's name, filter by the department and publication year, group by author, order by the total citations in descending order, and limit the results to the top 3 authors.\n\nHere is the SQL query:\n\n```sql\nSELECT a.name, SUM(p.cites) AS total_citations\nFROM authors a\nJOIN publications p ON a.name = p.author\nWHERE a.department = 'Mathematics'\nAND p.year >= YEAR(CURDATE()) - 5\nGROUP BY a.id, a.name\nORDER BY total_citations DESC\nLIMIT 3;\n```\n\n### Explanation:\n\n1. **Join**: We join the `authors` table with the `publications` table on the author's name to associate publications with their respective authors.\n\n2. **Filter by Department**: The `WHERE` clause filters authors who belong to the \"Mathematics\" department.\n\n3. **Filter by Year**: We filter publications from the last 5 years using `p.year >= YEAR(CURDATE()) - 5`. This ensures we only consider recent publications.\n\n4. **Grouping and Aggregation**: We group the results by author (`a.id` and `a.name`) to calculate the total citations for each author using `SUM(p.cites)`.\n\n5. **Ordering**: The results are ordered in descending order based on the total number of citations.\n\n6. **Limiting Results**: Finally, we limit the output to the top 3 authors with the most citations using `LIMIT 3`.", "latency_sec": 9.021525859832764, "total_duration_sec": 9.014348516, "load_duration_sec": 0.011339008, "tokens_prompt": 200, "prompt_eval_sec": 0.032090316, "tokens_completion": 354, "completion_eval_sec": 8.970100136, "tokens_total": 554, "tokens_per_sec": 61.4086805943346, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their GROUP BY clauses. The Reference SQL groups by 'author' (name), which could combine multiple authors with the same name. The Generated SQL groups by both 'a.id' and 'a.name', treating authors with the same name but different IDs as separate entities. This discrepancy could lead to different aggregation results if there are authors with duplicate names in the 'authors' table.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries differ in grouping logic and handling of author uniqueness. The Reference SQL groups by 'author' (publication.author column) which may combine multiple authors with the same name. The Generated SQL groups by a.id (unique author identifier) and a.name, ensuring accurate aggregation even with name duplicates. Both handle the year filter correctly, but the Generated SQL's JOIN ensures only valid author-publication relationships. The Reference SQL's subquery approach may miss authors who have publications but aren't explicitly listed in the authors table (though the schema suggests they should be). The Generated SQL better addresses the business intent by using the authoritative author ID.", "overall_assessment": "differently_correct"}}
{"example_id": 592, "sql_complexity": "set operations", "prompt": "How many public healthcare facilities and public parks are there in total, in the 'StateData' schema's 'StateHealthcare' and 'StateParks' tables?", "context": "CREATE SCHEMA StateData; CREATE TABLE StateHealthcare (Name varchar(255), Type varchar(255)); INSERT INTO StateHealthcare (Name, Type) VALUES ('FacilityA', 'Public'), ('FacilityB', 'Public'), ('FacilityC', 'Private'); CREATE TABLE StateParks (Name varchar(255), Type varchar(255)); INSERT INTO StateParks (Name, Type) VALUES ('ParkA', 'Public'), ('ParkB', 'Public'), ('ParkC', 'Private');", "reference_sql": "SELECT COUNT(*) FROM StateData.StateHealthcare WHERE Type = 'Public' UNION ALL SELECT COUNT(*) FROM StateData.StateParks WHERE Type = 'Public';", "generated_sql": "SELECT COUNT(*) AS TotalPublicFacilitiesAndParks\nFROM (\n    SELECT Name FROM StateHealthcare WHERE Type = 'Public'\n    UNION ALL\n    SELECT Name FROM StateParks WHERE Type = 'Public'\n) AS PublicEntities;", "raw_model_output": "To find out how many public healthcare facilities and public parks there are in total, you need to count the entries with `Type = 'Public'` from both the `StateHealthcare` and `StateParks` tables. You can achieve this by using a UNION ALL operation to combine the results of two separate SELECT statements that filter for public types, followed by summing up the counts.\n\nHere is the SQL statement:\n\n```sql\nSELECT COUNT(*) AS TotalPublicFacilitiesAndParks\nFROM (\n    SELECT Name FROM StateHealthcare WHERE Type = 'Public'\n    UNION ALL\n    SELECT Name FROM StateParks WHERE Type = 'Public'\n) AS PublicEntities;\n```\n\nThis query works as follows:\n- The first `SELECT` statement retrieves all public healthcare facilities from the `StateHealthcare` table.\n- The second `SELECT` statement retrieves all public parks from the `StateParks` table.\n- `UNION ALL` is used to combine these results into a single result set, including duplicates (though there are none in this case).\n- Finally, the outer query counts the total number of entries in this combined result set.", "latency_sec": 5.98292088508606, "total_duration_sec": 5.975127653, "load_duration_sec": 0.012476519, "tokens_prompt": 211, "prompt_eval_sec": 0.032079693, "tokens_completion": 234, "completion_eval_sec": 5.929807076, "tokens_total": 445, "tokens_per_sec": 74.37838616741111, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns two separate counts (one for StateHealthcare and one for StateParks) as two rows, while the Generated SQL combines all public entities from both tables into a single count. The first produces two rows with counts, the second produces one row with the sum of both counts.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL returns two separate counts (healthcare and parks) as two rows, while the Generated SQL combines them into a single total. The original question asks for a 'total' (sum of both), making the Generated SQL technically correct for this requirement. The Reference SQL doesn't sum the values, so it fails to fulfill the business intent. Both queries are syntactically correct, but the Generated version better addresses the explicit request for a combined total.", "overall_assessment": "differently_correct"}}
{"example_id": 1989, "sql_complexity": "single join", "prompt": "What are the names and production dates of garments made from fabrics with a sustainability score over 70, produced after 2021-01-01?", "context": "CREATE TABLE fabrics (id INT, name VARCHAR(50), type VARCHAR(50), sustainability_score INT); INSERT INTO fabrics (id, name, type, sustainability_score) VALUES (1, 'Organic Linen', 'Natural', 80); INSERT INTO fabrics (id, name, type, sustainability_score) VALUES (2, 'Recycled Nylon', 'Synthetic', 72);", "reference_sql": "SELECT garments.name, garments.production_date FROM garments JOIN fabrics ON garments.fabric_id = fabrics.id WHERE fabrics.sustainability_score > 70 AND garments.production_date > '2021-01-01';", "generated_sql": "SELECT g.name AS garment_name, g.production_date\nFROM garments g\nJOIN fabrics f ON g.fabric_id = f.id\nWHERE f.sustainability_score > 70\nAND g.production_date > '2021-01-01';", "raw_model_output": "To generate an executable SQL statement based on your question, we need to consider the following:\n\n1. **Identify Relevant Tables**: The provided schema only includes a `fabrics` table. However, your question mentions \"garments,\" which implies there might be another table related to garments that isn't included in the schema you've shared.\n\n2. **Assumptions**:\n   - There is likely a `garments` table with at least the following columns: `name`, `production_date`, and a foreign key column (e.g., `fabric_id`) linking it to the `fabrics` table.\n   - The `production_date` column in the `garments` table stores dates of production.\n\n3. **SQL Query Construction**:\n   - We need to join the `garments` table with the `fabrics` table on their respective keys.\n   - Filter fabrics with a sustainability score over 70.\n   - Filter garments produced after January 1, 2021.\n   - Select the names of the garments and their production dates.\n\nGiven these assumptions, here is how you can construct the SQL query:\n\n```sql\nSELECT g.name AS garment_name, g.production_date\nFROM garments g\nJOIN fabrics f ON g.fabric_id = f.id\nWHERE f.sustainability_score > 70\nAND g.production_date > '2021-01-01';\n```\n\n### Explanation:\n- `g` and `f` are aliases for the `garments` and `fabrics` tables, respectively.\n- The `JOIN` operation links garments to their corresponding fabrics using a foreign key (`fabric_id`) in the `garments` table that matches the `id` in the `fabrics` table.\n- The `WHERE` clause filters out fabrics with a sustainability score greater than 70 and garments produced after January 1, 2021.\n- The `SELECT` statement retrieves the garment names and their production dates.", "latency_sec": 10.049880266189575, "total_duration_sec": 10.045606257, "load_duration_sec": 0.011462972, "tokens_prompt": 181, "prompt_eval_sec": 0.025036273, "tokens_completion": 397, "completion_eval_sec": 10.008280843, "tokens_total": 578, "tokens_per_sec": 57.513123011479365, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries retrieve the same data by joining the same tables with identical conditions. The generated SQL uses table aliases and a column alias ('garment_name' vs 'name'), but these syntactic differences do not affect the result set's content. The WHERE clause and join logic are identical, ensuring semantically equivalent output.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically equivalent as they perform the same join logic, filter conditions, and select the same data. The reference query uses table names directly while the generated query uses aliases (g/f), which is a stylistic choice with no impact on results. Both correctly address the business intent by filtering fabrics with sustainability_score > 70 and production dates after 2021-01-01. The generated query is slightly more concise with aliases but neither demonstrates superior efficiency. The core logic and output are identical.", "overall_assessment": "correct"}}
{"example_id": 1388, "sql_complexity": "aggregation", "prompt": "What was the total donation amount by each organization in the last 30 days?", "context": "CREATE TABLE organization_donations (id INT, organization TEXT, donation_date DATE, donation_amount DECIMAL(10,2)); INSERT INTO organization_donations (id, organization, donation_date, donation_amount) VALUES (1, 'Organization A', '2021-03-15', 100.00), (2, 'Organization B', '2021-03-25', 200.00);", "reference_sql": "SELECT organization, SUM(donation_amount) FROM organization_donations WHERE donation_date >= DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY) GROUP BY organization;", "generated_sql": "SELECT \n    organization,\n    SUM(donation_amount) AS total_donation_amount\nFROM \n    organization_donations\nWHERE \n    donation_date >= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY \n    organization;", "raw_model_output": "To calculate the total donation amount by each organization for donations made in the last 30 days from today, we need to consider the current date and filter records accordingly. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    organization,\n    SUM(donation_amount) AS total_donation_amount\nFROM \n    organization_donations\nWHERE \n    donation_date >= CURRENT_DATE - INTERVAL '30 days'\nGROUP BY \n    organization;\n```\n\n### Explanation:\n- `CURRENT_DATE` is used to get the current date.\n- `- INTERVAL '30 days'` calculates the date 30 days before today.\n- The `WHERE` clause filters donations that occurred on or after this calculated date.\n- `SUM(donation_amount)` computes the total donation amount for each organization.\n- `GROUP BY organization` groups the results by each organization to get separate totals.", "latency_sec": 4.472566843032837, "total_duration_sec": 4.463740996, "load_duration_sec": 0.01834927, "tokens_prompt": 170, "prompt_eval_sec": 0.021873861, "tokens_completion": 176, "completion_eval_sec": 4.422536601, "tokens_total": 346, "tokens_per_sec": 77.36049837667227, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries calculate the sum of donation_amount for each organization where donation_date is within the last 30 days. The date calculation syntax differs (DATE_SUB vs. CURRENT_DATE - INTERVAL), but both expressions evaluate to the same date value. The column alias in the generated query does not affect semantic equivalence.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent due to differences in date calculation syntax. The reference query uses MySQL-specific DATE_SUB function, while the generated query uses PostgreSQL-style INTERVAL '30 days' syntax. The generated query would fail in MySQL (the likely database given the context) due to invalid syntax. Both queries correctly group by organization and sum donations, fulfilling the business intent. The reference query is more technically robust for the assumed MySQL environment.", "overall_assessment": "correct"}}
{"example_id": 1628, "sql_complexity": "window functions", "prompt": "What is the ranking of national security measures for Russia based on the publication date?", "context": "CREATE TABLE national_security (id INT, title VARCHAR(255), description TEXT, agency VARCHAR(255), date DATE); INSERT INTO national_security (id, title, description, agency, date) VALUES (1, 'National Cyber Strategy', 'Outlines the approach to protecting the American people and the American way of life in the digital age', 'White House', '2018-09-20'); INSERT INTO national_security (id, title, description, agency, date) VALUES (2, 'Cybersecurity and Infrastructure Security Agency Act of 2018', 'Establishes the Cybersecurity and Infrastructure Security Agency within the Department of Homeland Security', 'Congress', '2018-11-16'); INSERT INTO national_security (id, title, description, agency, date) VALUES (3, 'Russian Military Doctrine', 'Outlines the country\u2019s stance on military security', 'Russian Government', '2014-12-26');", "reference_sql": "SELECT title, description, agency, date, ROW_NUMBER() OVER (PARTITION BY agency ORDER BY date DESC) as ranking FROM national_security WHERE agency = 'Russian Government';", "generated_sql": "SELECT id, title, description, agency, date\nFROM national_security\nWHERE agency LIKE '%Russian%'\nORDER BY date DESC;", "raw_model_output": "To rank the national security measures related to Russia based on their publication date, we need to filter records where the `agency` column contains \"Russian\" and then order these records by the `date` column. Here's the SQL statement that accomplishes this:\n\n```sql\nSELECT id, title, description, agency, date\nFROM national_security\nWHERE agency LIKE '%Russian%'\nORDER BY date DESC;\n```\n\nThis query selects all relevant columns from the `national_security` table where the `agency` includes \"Russian\" and orders the results by the `date` in descending order to rank them based on their publication date.", "latency_sec": 3.3287668228149414, "total_duration_sec": 3.323451129, "load_duration_sec": 0.011502217, "tokens_prompt": 277, "prompt_eval_sec": 0.044907418, "tokens_completion": 127, "completion_eval_sec": 3.266100325, "tokens_total": 404, "tokens_per_sec": 121.366266099216, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in several key aspects. 1) The Reference SQL includes a ROW_NUMBER() column, while the Generated SQL does not. 2) The Reference SQL selects only specific columns (title, description, agency, date), whereas the Generated SQL selects all columns (including id). 3) The WHERE clause in the Reference SQL uses an exact match for 'Russian Government', while the Generated SQL uses a LIKE pattern that would match any agency containing 'Russian' (e.g., 'Russian Ministry', 'Russian Government', etc.). 4) The Generated SQL includes an ORDER BY clause, while the Reference SQL does not. These differences mean the queries would not produce identical results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is not technically equivalent because it filters for 'Russian Government' (a specific agency) and adds a ranking column, while the Generated SQL uses a broader 'LIKE' filter for any Russian-related agencies and orders by date. The original question asks for Russia's national security measures (country-level, not agency-specific), making the Generated SQL more aligned with the intent. However, neither query fully addresses 'ranking' as the question implies a numerical rank. The Reference SQL's ranking is per-agency, which is irrelevant here, while the Generated SQL lacks a ranking column. The Generated SQL better captures Russia's measures but misses the ranking aspect.", "overall_assessment": "differently_correct"}}
{"example_id": 2300, "sql_complexity": "aggregation", "prompt": "What is the minimum capacity for schools in each location ('community_development')?", "context": "CREATE TABLE community_development.schools (id INT, name VARCHAR(50), capacity INT, location VARCHAR(50));", "reference_sql": "SELECT location, MIN(capacity) FROM community_development.schools GROUP BY location;", "generated_sql": "SELECT location, MIN(capacity) AS min_capacity\nFROM community_development.schools\nGROUP BY location;", "raw_model_output": "To find the minimum capacity for schools in each location from the `schools` table within the `community_development` schema, you can use the following SQL query:\n\n```sql\nSELECT location, MIN(capacity) AS min_capacity\nFROM community_development.schools\nGROUP BY location;\n```\n\nThis query groups the records by their `location`, and for each group, it calculates the minimum value of the `capacity` column. The result will show each unique location along with its corresponding minimum school capacity.", "latency_sec": 2.588038206100464, "total_duration_sec": 2.580348913, "load_duration_sec": 0.01740434, "tokens_prompt": 112, "prompt_eval_sec": 0.015064875, "tokens_completion": 103, "completion_eval_sec": 2.546915633, "tokens_total": 215, "tokens_per_sec": 83.07450774614028, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries group schools by location and calculate the minimum capacity per group. The generated query adds an explicit alias (min_capacity) for the MIN(capacity) column, but this does not affect the semantic result - the data returned (location and min capacity values) remains identical.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the minimum capacity per location using GROUP BY. The generated query adds an explicit alias (min_capacity) which improves readability without altering functionality. The reference query is technically correct but less explicit. Both fulfill the business intent of identifying minimum capacities by location. The generated version is more elegant due to the column alias, making results clearer for end-users.", "overall_assessment": "correct"}}
{"example_id": 4976, "sql_complexity": "set operations", "prompt": "What is the most common hashtag used in posts made by users from Brazil?", "context": "CREATE TABLE posts (id INT, user_id INT, content TEXT, hashtags TEXT, post_date DATE); INSERT INTO posts (id, user_id, content, hashtags, post_date) VALUES (1, 1, 'Hello World', '#datascience', '2022-06-01'), (2, 1, 'I love data', '#ai', '2022-06-02'), (3, 2, 'Ol\u00e1 Mundo', '#brasil', '2022-06-03'); CREATE TABLE users (id INT, name VARCHAR(100), country VARCHAR(50)); INSERT INTO users (id, name, country) VALUES (1, 'Jo\u00e3o Silva', 'Brazil'), (2, 'Maria Souza', 'Brazil');", "reference_sql": "SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(hashtags, ' ', n.n), ' ', -1) hashtag, COUNT(*) count FROM posts JOIN users ON posts.user_id = users.id CROSS JOIN (SELECT 1 n UNION SELECT 2 UNION SELECT 3 UNION SELECT 4 UNION SELECT 5) n WHERE users.country = 'Brazil' GROUP BY hashtag ORDER BY count DESC LIMIT 1;", "generated_sql": "WITH brazilian_posts AS (\n    SELECT p.hashtags\n    FROM posts p\n    JOIN users u ON p.user_id = u.id\n    WHERE u.country = 'Brazil'\n),\nsplit_hashtags AS (\n    SELECT \n        TRIM(SUBSTRING_INDEX(SUBSTRING_INDEX(bp.hashtags, ',', numbers.n), ',', -1)) AS hashtag\n    FROM \n        brazilian_posts bp\n    CROSS JOIN \n        (SELECT 1 n UNION ALL SELECT 2 UNION ALL SELECT 3) numbers\n    WHERE \n        numbers.n <= LENGTH(bp.hashtags) - LENGTH(REPLACE(bp.hashtags, ',', '')) + 1\n)\nSELECT \n    hashtag,\n    COUNT(*) AS frequency\nFROM \n    split_hashtags\nWHERE \n    hashtag <> ''\nGROUP BY \n    hashtag\nORDER BY \n    frequency DESC\nLIMIT 1;", "raw_model_output": "To find the most common hashtag used in posts made by Brazilian users, we need to join the `posts` and `users` tables on the `user_id` and `id` columns respectively. Then, filter for users whose country is 'Brazil'. After that, split the hashtags from each post into individual hashtags, count their occurrences, and finally determine which hashtag appears most frequently.\n\nHere's how you can achieve this using SQL:\n\n```sql\nWITH brazilian_posts AS (\n    SELECT p.hashtags\n    FROM posts p\n    JOIN users u ON p.user_id = u.id\n    WHERE u.country = 'Brazil'\n),\nsplit_hashtags AS (\n    SELECT \n        TRIM(SUBSTRING_INDEX(SUBSTRING_INDEX(bp.hashtags, ',', numbers.n), ',', -1)) AS hashtag\n    FROM \n        brazilian_posts bp\n    CROSS JOIN \n        (SELECT 1 n UNION ALL SELECT 2 UNION ALL SELECT 3) numbers\n    WHERE \n        numbers.n <= LENGTH(bp.hashtags) - LENGTH(REPLACE(bp.hashtags, ',', '')) + 1\n)\nSELECT \n    hashtag,\n    COUNT(*) AS frequency\nFROM \n    split_hashtags\nWHERE \n    hashtag <> ''\nGROUP BY \n    hashtag\nORDER BY \n    frequency DESC\nLIMIT 1;\n```\n\n### Explanation:\n\n1. **brazilian_posts CTE**: This common table expression (CTE) selects the `hashtags` from posts made by users whose country is 'Brazil'.\n\n2. **split_hashtags CTE**: This CTE splits the hashtags string into individual hashtags using a numbers table approach. The `SUBSTRING_INDEX` function is used to extract each hashtag, and `TRIM` ensures any leading or trailing spaces are removed.\n\n3. **Final SELECT Statement**: \n   - It counts occurrences of each hashtag.\n   - Filters out empty strings that might result from splitting.\n   - Groups by the hashtag to get frequency counts.\n   - Orders the results in descending order based on frequency and limits the output to the most common hashtag using `LIMIT 1`.", "latency_sec": 10.741603136062622, "total_duration_sec": 10.736214341, "load_duration_sec": 0.011455442, "tokens_prompt": 243, "prompt_eval_sec": 0.03932483, "tokens_completion": 422, "completion_eval_sec": 10.684665329, "tokens_total": 665, "tokens_per_sec": 61.90882232163331, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in delimiter handling (space vs comma) and split logic. The Reference SQL splits on spaces using SUBSTRING_INDEX, while the Generated SQL uses commas and a different split count mechanism. Additionally, the Generated SQL includes a WHERE clause to limit splits based on comma count, which the Reference SQL lacks. These differences in delimiter and split logic make them non-equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL is technically correct and fulfills the business intent, while the Generated SQL contains critical flaws. The Reference correctly uses space as the delimiter (matching the sample data's '#datascience' format) and handles multiple hashtags per post. The Generated SQL incorrectly uses commas as delimiters, which would fail to split space-separated hashtags. Additionally, the Generated SQL's numbers table only supports up to 3 hashtags per post (vs. the Reference's 5), and its WHERE clause for counting hashtags is flawed. Both queries correctly filter Brazilian users, but the Generated SQL's splitting logic is fundamentally incorrect for the given data format.", "overall_assessment": "incorrect"}}
{"example_id": 4637, "sql_complexity": "single join", "prompt": "What is the total value of transactions for each customer in the last 30 days?", "context": "CREATE TABLE transactions (id INT, customer_id INT, value DECIMAL(10, 2), transaction_date DATE); INSERT INTO transactions (id, customer_id, value, transaction_date) VALUES (1, 1, 100, '2022-01-01'), (2, 1, 200, '2022-01-15'), (3, 2, 50, '2022-01-05'), (4, 2, 150, '2022-01-30'), (5, 3, 300, '2022-01-20');", "reference_sql": "SELECT c.id, SUM(t.value) FROM customers c INNER JOIN transactions t ON c.id = t.customer_id WHERE t.transaction_date >= CURDATE() - INTERVAL 30 DAY GROUP BY c.id;", "generated_sql": "WITH LatestDate AS (\n    SELECT MAX(transaction_date) AS max_date FROM transactions\n)\nSELECT \n    t.customer_id,\n    SUM(t.value) AS total_value\nFROM \n    transactions t\nJOIN \n    LatestDate ld ON t.transaction_date BETWEEN DATE_SUB(ld.max_date, INTERVAL 30 DAY) AND ld.max_date\nGROUP BY \n    t.customer_id;", "raw_model_output": "To calculate the total value of transactions for each customer in the last 30 days from a given reference date, we need to determine what that reference date is. Since no specific reference date is provided in the question, I'll assume you want to use today's date as the reference point. However, since this is a static dataset and \"today\" isn't defined within it, let's consider using the latest transaction date from the data itself as our reference.\n\nHere's how we can construct the SQL query:\n\n1. Determine the maximum transaction date in the table.\n2. Calculate the range of dates that are within 30 days before this maximum date.\n3. Sum the values for transactions falling within this date range, grouped by customer_id.\n\n```sql\nWITH LatestDate AS (\n    SELECT MAX(transaction_date) AS max_date FROM transactions\n)\nSELECT \n    t.customer_id,\n    SUM(t.value) AS total_value\nFROM \n    transactions t\nJOIN \n    LatestDate ld ON t.transaction_date BETWEEN DATE_SUB(ld.max_date, INTERVAL 30 DAY) AND ld.max_date\nGROUP BY \n    t.customer_id;\n```\n\n### Explanation:\n\n- **LatestDate CTE**: This common table expression calculates the latest transaction date from the `transactions` table.\n  \n- **DATE_SUB Function**: Used to calculate the date that is 30 days before the maximum transaction date.\n\n- **JOIN with LatestDate**: We join the transactions table with the LatestDate CTE to filter transactions within the last 30 days of the maximum transaction date.\n\n- **GROUP BY customer_id**: This groups the results by `customer_id` and calculates the sum of `value` for each group, giving us the total value of transactions per customer in the specified period.", "latency_sec": 9.039541959762573, "total_duration_sec": 9.031465652, "load_duration_sec": 0.020711768, "tokens_prompt": 213, "prompt_eval_sec": 0.034004891, "tokens_completion": 354, "completion_eval_sec": 8.975821898, "tokens_total": 567, "tokens_per_sec": 62.7244170693459, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in how they define the date range. The Reference SQL uses `CURDATE() - INTERVAL 30 DAY` (current date minus 30 days), while the Generated SQL uses the maximum transaction date in the table and looks back 30 days from that. This leads to different date ranges unless the latest transaction date is exactly 30 days before the current date. Additionally, the Reference SQL joins with the `customers` table, whereas the Generated SQL only uses `transactions`, which could affect results if there are customers without recent transactions.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries differ fundamentally in their date logic. The reference query uses CURDATE() - INTERVAL 30 DAY to calculate the 30-day window relative to the current date, which aligns with the natural language question's intent. The generated query uses the maximum transaction_date in the table and calculates the 30-day window relative to that date, which would only match the reference if the latest transaction occurred exactly 30 days before the current date (unlikely). This makes them technically non-equivalent. While both aggregate transaction values per customer, the generated query's date logic fails to capture 'last 30 days' from the current date, potentially excluding valid transactions or including outdated ones. The reference query is more efficient (no CTE/JOIN) and directly addresses the business intent.", "overall_assessment": "correct"}}
{"example_id": 4947, "sql_complexity": "aggregation", "prompt": "What is the total revenue for drugs approved between 2017 and 2019?", "context": "CREATE TABLE drug_sales_3 (drug_name TEXT, revenue FLOAT, year INT); INSERT INTO drug_sales_3 (drug_name, revenue, year) VALUES ('DrugG', 20000000, 2019), ('DrugG', 19000000, 2018), ('DrugH', 15000000, 2017), ('DrugH', 16000000, 2018);", "reference_sql": "SELECT drug_name, SUM(revenue) FROM drug_sales_3 WHERE year BETWEEN 2017 AND 2019 GROUP BY drug_name;", "generated_sql": "SELECT SUM(revenue) AS total_revenue\nFROM drug_sales_3\nWHERE year BETWEEN 2017 AND 2019;", "raw_model_output": "To calculate the total revenue for drugs sold between the years 2017 and 2019 from the `drug_sales_3` table, you can use the following SQL query:\n\n```sql\nSELECT SUM(revenue) AS total_revenue\nFROM drug_sales_3\nWHERE year BETWEEN 2017 AND 2019;\n```\n\nThis query sums up the `revenue` column for all records where the `year` is between 2017 and 2019, inclusive. The result will be labeled as `total_revenue`.", "latency_sec": 2.8033268451690674, "total_duration_sec": 2.795442076, "load_duration_sec": 0.011896128, "tokens_prompt": 173, "prompt_eval_sec": 0.021285869, "tokens_completion": 110, "completion_eval_sec": 2.761558157, "tokens_total": 283, "tokens_per_sec": 100.95148216045153, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query groups results by drug_name and calculates individual sums per drug, while the generated query returns a single total revenue sum for all drugs combined. The absence of a GROUP BY clause in the generated query changes the result structure and aggregation scope.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query groups results by drug_name, producing per-drug totals, while the generated query calculates a single total revenue across all drugs. The original question asks for 'total revenue' (singular), which aligns with the generated query's approach. Although both queries are technically correct, the generated query better fulfills the business intent of aggregating all revenue for drugs approved between 2017-2019. The reference query would require additional aggregation to answer the original question accurately.", "overall_assessment": "differently_correct"}}
{"example_id": 4767, "sql_complexity": "window functions", "prompt": "List the top 2 AI algorithms with the highest explainability scores, by algorithm subtype, ordered by scores in descending order for the European region.", "context": "CREATE TABLE ai_algorithms (algorithm_id INT, algorithm_name VARCHAR(50), algorithm_subtype VARCHAR(50), region VARCHAR(50), explainability_score FLOAT); INSERT INTO ai_algorithms (algorithm_id, algorithm_name, algorithm_subtype, region, explainability_score) VALUES (1, 'AlgoA', 'Tree-based', 'Europe', 0.85), (2, 'AlgoB', 'Computer Vision', 'Europe', 0.92), (3, 'AlgoC', 'Tree-based', 'Europe', 0.78), (4, 'AlgoD', 'Transformer', 'Europe', 0.90), (5, 'AlgoE', 'Tree-based', 'Europe', 0.80);", "reference_sql": "SELECT algorithm_subtype, region, * FROM (SELECT algorithm_subtype, region, algorithm_id, algorithm_name, explainability_score, RANK() OVER (PARTITION BY algorithm_subtype ORDER BY explainability_score DESC) AS rank FROM ai_algorithms WHERE region = 'Europe') ranked WHERE rank <= 2 ORDER BY algorithm_subtype, region, explainability_score DESC;", "generated_sql": "WITH RankedAlgorithms AS (\n    SELECT \n        algorithm_id,\n        algorithm_name,\n        algorithm_subtype,\n        explainability_score,\n        ROW_NUMBER() OVER (\n            PARTITION BY algorithm_subtype \n            ORDER BY explainability_score DESC\n        ) as rank\n    FROM \n        ai_algorithms\n    WHERE \n        region = 'Europe'\n)\nSELECT \n    algorithm_id,\n    algorithm_name,\n    algorithm_subtype,\n    explainability_score\nFROM \n    RankedAlgorithms\nWHERE \n    rank <= 2\nORDER BY \n    algorithm_subtype, \n    explainability_score DESC;", "raw_model_output": "To solve this problem, we need to extract the top two AI algorithms with the highest explainability scores within each algorithm subtype specifically for the European region. We will use a common table expression (CTE) or subquery along with window functions to achieve this. Here's how you can construct the SQL query:\n\n```sql\nWITH RankedAlgorithms AS (\n    SELECT \n        algorithm_id,\n        algorithm_name,\n        algorithm_subtype,\n        explainability_score,\n        ROW_NUMBER() OVER (\n            PARTITION BY algorithm_subtype \n            ORDER BY explainability_score DESC\n        ) as rank\n    FROM \n        ai_algorithms\n    WHERE \n        region = 'Europe'\n)\nSELECT \n    algorithm_id,\n    algorithm_name,\n    algorithm_subtype,\n    explainability_score\nFROM \n    RankedAlgorithms\nWHERE \n    rank <= 2\nORDER BY \n    algorithm_subtype, \n    explainability_score DESC;\n```\n\n### Explanation:\n\n1. **Common Table Expression (CTE):** We use a CTE named `RankedAlgorithms` to calculate the ranking of algorithms within each subtype based on their explainability scores.\n\n2. **ROW_NUMBER() Function:** This function assigns a unique rank to each row within a partition of the result set, which is defined by `algorithm_subtype`. The rows are ordered by `explainability_score` in descending order so that higher scores get lower numbers (i.e., rank 1).\n\n3. **Filtering for Europe:** We include only those records where the region is 'Europe'.\n\n4. **Selecting Top 2 Algorithms:** In the main query, we filter out rows from the CTE where `rank` is less than or equal to 2, ensuring that we get the top two algorithms per subtype.\n\n5. **Ordering Results:** Finally, we order the results by `algorithm_subtype` and then by `explainability_score` in descending order for clarity in presentation.", "latency_sec": 9.930431127548218, "total_duration_sec": 9.924621456, "load_duration_sec": 0.012124006, "tokens_prompt": 254, "prompt_eval_sec": 0.040679451, "tokens_completion": 389, "completion_eval_sec": 9.870849979, "tokens_total": 643, "tokens_per_sec": 64.75046166084775, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in several key aspects. 1) The Reference SQL includes the 'region' column in the final output, while the Generated SQL does not. 2) The Reference SQL uses RANK() while the Generated SQL uses ROW_NUMBER(), which can produce different results when there are ties in the 'explainability_score'. 3) The Reference SQL selects all columns (using *) from the subquery, while the Generated SQL explicitly lists specific columns. These differences in column selection and ranking function make the queries not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent due to differences in ranking functions (RANK() vs ROW_NUMBER()) and output columns. The Reference SQL includes redundant 'region' in the ORDER BY and selects all columns, while the Generated SQL focuses on relevant fields and uses a more precise ordering. Both correctly identify top 2 algorithms per subtype, but the Generated SQL better aligns with the business intent by ensuring exactly 2 results per subtype (ROW_NUMBER()) and avoiding unnecessary columns. The Reference's RANK() could return more than 2 rows if ties exist, which might not match the 'top 2' requirement. The Generated SQL's structure is also more efficient and readable.", "overall_assessment": "differently_correct"}}
{"example_id": 4495, "sql_complexity": "basic SQL", "prompt": "Which countries are the top 3 sources of sustainable textiles?", "context": "CREATE TABLE Textile_Sources (Source_ID INT, Source_Country TEXT, Sustainable BOOLEAN, Quantity INT); INSERT INTO Textile_Sources (Source_ID, Source_Country, Sustainable, Quantity) VALUES (1, 'India', true, 1000), (2, 'Bangladesh', false, 800), (3, 'China', true, 1200), (4, 'Vietnam', false, 900), (5, 'Italy', true, 1100), (6, 'USA', false, 700);", "reference_sql": "SELECT Source_Country FROM Textile_Sources WHERE Sustainable = true ORDER BY Quantity DESC LIMIT 3;", "generated_sql": "SELECT Source_Country\nFROM Textile_Sources\nWHERE Sustainable = TRUE\nORDER BY Quantity DESC\nLIMIT 3;", "raw_model_output": "To find the top 3 countries that are sources of sustainable textiles based on their quantity, we need to filter for entries where `Sustainable` is true and then order by `Quantity` in descending order. Finally, we limit the results to the top 3.\n\nHere's the SQL query:\n\n```sql\nSELECT Source_Country\nFROM Textile_Sources\nWHERE Sustainable = TRUE\nORDER BY Quantity DESC\nLIMIT 3;\n```\n\nThis query selects the countries from the `Textile_Sources` table where textiles are marked as sustainable, orders them by quantity in descending order to get the highest quantities first, and limits the result set to the top 3 entries.", "latency_sec": 3.5387799739837646, "total_duration_sec": 3.532380186, "load_duration_sec": 0.01154141, "tokens_prompt": 196, "prompt_eval_sec": 0.033077578, "tokens_completion": 138, "completion_eval_sec": 3.487018876, "tokens_total": 334, "tokens_per_sec": 94.38281058881462, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The queries are semantically equivalent. The only differences are case sensitivity in the BOOLEAN literal ('true' vs 'TRUE') and formatting (line breaks/indentation), which do not affect SQL execution. Both queries select the same columns, filter on the same condition, order by Quantity descending, and limit to 3 results.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically identical in logic and structure, with the only difference being the case of the BOOLEAN literal (true vs. TRUE). SQL is case-insensitive for boolean values, so both will produce the same results. The queries correctly filter sustainable sources (Sustainable = true), order by Quantity descending, and limit to 3 records, directly addressing the business question. Neither query has efficiency advantages over the other as they execute the same operations.", "overall_assessment": "correct"}}
{"example_id": 2513, "sql_complexity": "single join", "prompt": "What is the total number of concert ticket sales for artists who released their first album between 2015 and 2017?", "context": "CREATE TABLE ConcertTicketSales (id INT, year INT, artist_id INT); CREATE TABLE ArtistAlbums (id INT, artist_id INT, year INT);", "reference_sql": "SELECT COUNT(DISTINCT cts.artist_id) FROM ConcertTicketSales cts JOIN ArtistAlbums a ON cts.artist_id = a.artist_id WHERE a.year BETWEEN 2015 AND 2017;", "generated_sql": "SELECT COUNT(*) AS total_ticket_sales\nFROM ConcertTicketSales cts\nWHERE cts.artist_id IN (\n    SELECT aa.artist_id\n    FROM ArtistAlbums aa\n    WHERE aa.year BETWEEN 2015 AND 2017\n    GROUP BY aa.artist_id\n    HAVING MIN(aa.year) BETWEEN 2015 AND 2017\n);", "raw_model_output": "To solve this problem, we need to identify artists who released their first album between 2015 and 2017. Then, we will count the total number of concert ticket sales associated with these artists.\n\nHere's how you can construct the SQL query:\n\n```sql\nSELECT COUNT(*) AS total_ticket_sales\nFROM ConcertTicketSales cts\nWHERE cts.artist_id IN (\n    SELECT aa.artist_id\n    FROM ArtistAlbums aa\n    WHERE aa.year BETWEEN 2015 AND 2017\n    GROUP BY aa.artist_id\n    HAVING MIN(aa.year) BETWEEN 2015 AND 2017\n);\n```\n\n### Explanation:\n\n1. **Subquery to Find Artists with First Album Released Between 2015 and 2017:**\n   - We select `artist_id` from the `ArtistAlbums` table.\n   - We filter albums released between 2015 and 2017 using `aa.year BETWEEN 2015 AND 2017`.\n   - We group by `artist_id` to consider each artist separately.\n   - We use `HAVING MIN(aa.year) BETWEEN 2015 AND 2017` to ensure that the earliest album release year for these artists falls within the specified range.\n\n2. **Main Query to Count Ticket Sales:**\n   - We count all entries in the `ConcertTicketSales` table where the `artist_id` matches those identified by the subquery.\n   - This gives us the total number of concert ticket sales for artists who released their first album between 2015 and 2017.", "latency_sec": 8.018107175827026, "total_duration_sec": 8.012756761, "load_duration_sec": 0.012941686, "tokens_prompt": 129, "prompt_eval_sec": 0.016968302, "tokens_completion": 318, "completion_eval_sec": 7.982107283, "tokens_total": 447, "tokens_per_sec": 55.74881829312717, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query counts distinct artist_ids from ConcertTicketSales that have at least one matching entry in ArtistAlbums with a year between 2015-2017. The generated query, however, filters artist_ids in the subquery to only those where the minimum album year (per artist) is between 2015-2017. This makes the generated query more restrictive, as it excludes artists who have albums outside the 2015-2017 range but also have at least one album within that range (e.g., an artist with albums in 2014 and 2015 would be excluded by the generated query but included in the reference query).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference SQL incorrectly counts distinct artists instead of total ticket sales. The generated SQL correctly identifies artists with first albums between 2015-2017 using HAVING MIN(year) and then counts all their ticket sales entries. While both queries filter artists by first album year, the generated query addresses the actual business intent of counting ticket sales rather than artist counts. The generated query is more precise in fulfilling the requirement for 'total concert ticket sales' given the schema.", "overall_assessment": "differently_correct"}}
{"example_id": 873, "sql_complexity": "subqueries", "prompt": "Identify attorneys who have never handled cases in the 'West' region but have in the 'North' or 'South'.", "context": "CREATE TABLE attorney_regions(attorney_id INT, region VARCHAR(20)); INSERT INTO attorney_regions(attorney_id, region) VALUES (1, 'North'), (2, 'South'), (3, 'East'), (4, 'West'), (5, 'West'), (6, 'North'); CREATE TABLE handled_cases(attorney_id INT, case_id INT); INSERT INTO handled_cases(attorney_id, case_id) VALUES (1, 101), (2, 102), (3, 103), (4, 104), (5, 105), (6, 106), (1, 107), (1, 108);", "reference_sql": "SELECT h.attorney_id FROM attorney_regions h LEFT JOIN handled_cases i ON h.attorney_id = i.attorney_id WHERE h.region IN ('North', 'South') AND h.region != 'West' AND i.attorney_id IS NOT NULL AND h.attorney_id NOT IN (SELECT attorney_id FROM attorney_regions WHERE region = 'West');", "generated_sql": "SELECT DISTINCT ar.attorney_id\nFROM attorney_regions ar\nJOIN handled_cases hc ON ar.attorney_id = hc.attorney_id\nWHERE ar.region IN ('North', 'South')\n  AND ar.attorney_id NOT IN (\n    SELECT DISTINCT ar2.attorney_id\n    FROM attorney_regions ar2\n    JOIN handled_cases hc2 ON ar2.attorney_id = hc2.attorney_id\n    WHERE ar2.region = 'West'\n  );", "raw_model_output": "To solve this problem, we need to identify attorneys who meet two criteria:\n\n1. They have never handled a case in the 'West' region.\n2. They have handled at least one case in either the 'North' or 'South' regions.\n\nHere's how you can construct the SQL query step-by-step:\n\n1. **Identify Attorneys Who Have Handled Cases in the 'West':**\n\n   We need to find attorneys who are associated with the 'West' region and have handled cases.\n\n2. **Identify Attorneys Who Have Handled Cases in the 'North' or 'South':**\n\n   We need to find attorneys who are associated with either the 'North' or 'South' regions and have handled cases.\n\n3. **Combine the Conditions:**\n\n   We want attorneys who are present in the second group but not in the first group.\n\nHere's the SQL query:\n\n```sql\nSELECT DISTINCT ar.attorney_id\nFROM attorney_regions ar\nJOIN handled_cases hc ON ar.attorney_id = hc.attorney_id\nWHERE ar.region IN ('North', 'South')\n  AND ar.attorney_id NOT IN (\n    SELECT DISTINCT ar2.attorney_id\n    FROM attorney_regions ar2\n    JOIN handled_cases hc2 ON ar2.attorney_id = hc2.attorney_id\n    WHERE ar2.region = 'West'\n  );\n```\n\n### Explanation:\n\n- **Subquery:** The subquery identifies attorneys who have handled cases in the 'West' region. We use `DISTINCT` to ensure each attorney is listed only once.\n\n- **Main Query:** \n  - Joins `attorney_regions` and `handled_cases` to find all attorneys who have handled cases.\n  - Filters for those whose regions are either 'North' or 'South'.\n  - Uses a `NOT IN` condition to exclude any attorney found in the subquery (those who have handled cases in the 'West').\n\nThis query will return the IDs of attorneys who meet both criteria.", "latency_sec": 10.353726863861084, "total_duration_sec": 10.347753681, "load_duration_sec": 0.011193258, "tokens_prompt": 231, "prompt_eval_sec": 0.037591293, "tokens_completion": 406, "completion_eval_sec": 10.298279184, "tokens_total": 637, "tokens_per_sec": 61.52374003832391, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select attorney_ids from North/South regions with handled cases. The Reference SQL's subquery (excluding West region) is redundant because the WHERE clause already restricts to North/South. The Generated SQL's subquery (excluding West with handled cases) also has no effect since the main query's region filter ensures North/South only. Both ultimately return the same result.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is technically flawed because it checks attorney regions rather than case handling history. It uses a subquery selecting attorneys in the 'West' region (not cases), which doesn't align with the business requirement of identifying attorneys who have never handled cases in the 'West'. The Generated SQL correctly filters attorneys who have handled cases in 'North'/'South' (via JOIN) and explicitly excludes those who have handled cases in 'West' (via NOT IN subquery with case-handling logic). While both queries use JOINs, the Generated SQL directly addresses the case-handling requirement, making it more semantically accurate. The Reference SQL's WHERE clause (h.region != 'West') is redundant since the main query already restricts to 'North'/'South'.", "overall_assessment": "differently_correct"}}
{"example_id": 471, "sql_complexity": "set operations", "prompt": "Find the number of donations made by first-time donors in the last quarter.", "context": "CREATE TABLE Donations (DonationID INT, DonorID INT, DonationDate DATE, DonationType TEXT, DonationAmount FLOAT); INSERT INTO Donations (DonationID, DonorID, DonationDate, DonationType, DonationAmount) VALUES (1, 1, '2021-01-01', 'Individual', 100), (2, 2, '2021-02-01', 'Corporate', 5000);", "reference_sql": "SELECT COUNT(*) FROM (SELECT DonationID FROM Donations WHERE DonationType = 'Individual' AND DonationDate >= DATEADD(quarter, -1, CURRENT_DATE) EXCEPT SELECT DonationID FROM PreviousDonations) AS FirstTimeDonors;", "generated_sql": "SELECT COUNT(*) AS FirstTimeDonationsLastQuarter\nFROM Donations d1\nWHERE DonationDate BETWEEN '2021-10-01' AND '2021-12-31'\n  AND DonationDate = (\n    SELECT MIN(d2.DonationDate)\n    FROM Donations d2\n    WHERE d2.DonorID = d1.DonorID\n  );", "raw_model_output": "To solve this problem, we need to identify first-time donors and then count their donations within the last quarter. Here's how you can approach it:\n\n1. **Identify First-Time Donors**: A donor is considered a \"first-time\" donor if their earliest donation date in the database is the same as the donation date being evaluated.\n\n2. **Determine the Last Quarter**: Assuming the current date is after '2021-12-31', the last quarter would be from '2021-10-01' to '2021-12-31'.\n\n3. **SQL Query**:\n   - Use a subquery to find the earliest donation date for each donor.\n   - Filter donations that fall within the last quarter and where the donation date matches the earliest donation date.\n\nHere's the SQL statement:\n\n```sql\nSELECT COUNT(*) AS FirstTimeDonationsLastQuarter\nFROM Donations d1\nWHERE DonationDate BETWEEN '2021-10-01' AND '2021-12-31'\n  AND DonationDate = (\n    SELECT MIN(d2.DonationDate)\n    FROM Donations d2\n    WHERE d2.DonorID = d1.DonorID\n  );\n```\n\nThis query counts the number of donations made by first-time donors in the last quarter of 2021.", "latency_sec": 6.781018018722534, "total_duration_sec": 6.76720875, "load_duration_sec": 0.015289014, "tokens_prompt": 178, "prompt_eval_sec": 0.027754567, "tokens_completion": 267, "completion_eval_sec": 6.723342836, "tokens_total": 445, "tokens_per_sec": 65.62436477404212, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in logic and purpose. The Reference SQL counts 'Individual' donations in the last quarter excluding those in PreviousDonations, while the Generated SQL counts first-time donations (minimum date per donor) in a fixed 2021 Q4 range. The EXCEPT clause and dynamic date calculation in the Reference SQL are absent in the Generated SQL, and the criteria for 'first-time' donors differ between the two queries.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The Reference SQL attempts to identify first-time donors by excluding donations from a hypothetical 'PreviousDonations' table, which is not defined in the schema. This makes it technically invalid. The Generated SQL correctly identifies first-time donors by checking if a donation is their earliest (using MIN(DonationDate)), but it uses hardcoded dates ('2021-10-01' to '2021-12-31') instead of dynamic quarter calculations, which would fail for other time periods. While the Generated SQL better captures the business intent of identifying first-time donors, its hardcoded dates prevent it from fulfilling the 'last quarter' requirement. The Reference SQL's logic is flawed due to the missing table, but its structure (EXCEPT clause) more directly addresses the 'first-time' requirement if the schema were complete.", "overall_assessment": "differently_correct"}}
{"example_id": 1301, "sql_complexity": "multiple_joins", "prompt": "What is the total quantity of corn sold by farmers in 'Summerfield'?", "context": "CREATE TABLE farmers (id INT, name VARCHAR(50), location VARCHAR(50), crops VARCHAR(50)); CREATE TABLE crops (id INT, name VARCHAR(50), yield INT); CREATE TABLE sales (id INT, farmer_id INT, crop_name VARCHAR(50), quantity INT, price DECIMAL(5,2)); INSERT INTO farmers VALUES (1, 'Jane Doe', 'Summerfield', 'Corn'); INSERT INTO crops VALUES (1, 'Corn', 100); INSERT INTO sales VALUES (1, 1, 'Corn', 50, 2.50);", "reference_sql": "SELECT SUM(quantity) FROM sales INNER JOIN farmers ON sales.farmer_id = farmers.id INNER JOIN crops ON sales.crop_name = crops.name WHERE farmers.location = 'Summerfield' AND crops.name = 'Corn';", "generated_sql": "SELECT SUM(s.quantity) AS total_quantity_sold\nFROM sales s\nJOIN farmers f ON s.farmer_id = f.id\nWHERE f.location = 'Summerfield'\n  AND s.crop_name = 'Corn';", "raw_model_output": "To find the total quantity of corn sold by farmers located in 'Summerfield', we need to join the `farmers` and `sales` tables based on the farmer's ID, filter for those who are located in 'Summerfield' and have sold 'Corn', and then sum up the quantities. Here is the SQL statement that accomplishes this:\n\n```sql\nSELECT SUM(s.quantity) AS total_quantity_sold\nFROM sales s\nJOIN farmers f ON s.farmer_id = f.id\nWHERE f.location = 'Summerfield'\n  AND s.crop_name = 'Corn';\n```\n\nThis query performs the following steps:\n1. Joins the `sales` table (`s`) with the `farmers` table (`f`) on the condition that the `farmer_id` in the `sales` table matches the `id` in the `farmers` table.\n2. Filters the results to include only those records where the farmer's location is 'Summerfield' and the crop name sold is 'Corn'.\n3. Sums up the quantities of corn sold by these farmers, resulting in the total quantity sold.", "latency_sec": 5.861534833908081, "total_duration_sec": 5.852022075, "load_duration_sec": 0.012328061, "tokens_prompt": 205, "prompt_eval_sec": 0.032399642, "tokens_completion": 229, "completion_eval_sec": 5.806300789, "tokens_total": 434, "tokens_per_sec": 74.04204057431792, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes an INNER JOIN with the 'crops' table and filters on 'crops.name = 'Corn'', which ensures that only sales with valid crop entries in the 'crops' table are considered. The Generated SQL omits this join and directly filters on 'sales.crop_name = 'Corn'', which could include sales entries with crop names not present in the 'crops' table. This difference in logic makes the queries not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly calculate the total corn quantity sold by Summerfield farmers. The reference query includes an unnecessary JOIN with the 'crops' table since the 'sales.crop_name' field directly contains the crop name. The generated query achieves the same result with fewer joins, making it more efficient. Both satisfy the business intent, but the generated query is more elegant and performant.", "overall_assessment": "correct"}}
{"example_id": 4667, "sql_complexity": "aggregation", "prompt": "Find the number of unique organizations in each country in the Philanthropy Trends table?", "context": "CREATE TABLE PhilanthropyTrends (OrgID INT, Name TEXT, Country TEXT);", "reference_sql": "SELECT Country, COUNT(DISTINCT OrgID) as UniqueOrganizations FROM PhilanthropyTrends GROUP BY Country;", "generated_sql": "SELECT \n    Country,\n    COUNT(DISTINCT OrgID) AS UniqueOrganizationsCount\nFROM \n    PhilanthropyTrends\nGROUP BY \n    Country;", "raw_model_output": "To find the number of unique organizations in each country from the `PhilanthropyTrends` table, you can use the following SQL query:\n\n```sql\nSELECT \n    Country,\n    COUNT(DISTINCT OrgID) AS UniqueOrganizationsCount\nFROM \n    PhilanthropyTrends\nGROUP BY \n    Country;\n```\n\nThis query works as follows:\n- It selects the `Country` column to group the results by each country.\n- The `COUNT(DISTINCT OrgID)` function counts the number of unique organizations (`OrgID`) for each country.\n- The `GROUP BY Country` clause ensures that the count is calculated separately for each country.", "latency_sec": 3.3774309158325195, "total_duration_sec": 3.371300231, "load_duration_sec": 0.012339959, "tokens_prompt": 107, "prompt_eval_sec": 0.013595853, "tokens_completion": 135, "completion_eval_sec": 3.344740284, "tokens_total": 242, "tokens_per_sec": 71.65209475212855, "match_exact": false, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries perform the same aggregation (COUNT(DISTINCT OrgID)) on the same table (PhilanthropyTrends) and group by the same column (Country). The only difference is the column alias name ('UniqueOrganizations' vs 'UniqueOrganizationsCount'), which does not affect the semantic result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically correct and produce identical results. They both group by 'Country' and count distinct 'OrgID' values to determine unique organizations per country. The only difference is the column alias name ('UniqueOrganizations' vs 'UniqueOrganizationsCount'), which does not affect the output structure or business meaning. Both queries fully address the original question about counting unique organizations by country. The generated query's alias is slightly more descriptive, but neither query has an advantage in efficiency or elegance.", "overall_assessment": "correct"}}
{"example_id": 1006, "sql_complexity": "subqueries", "prompt": "What is the average word count of news articles written by investigative journalists?", "context": "CREATE TABLE reporters (id INT, name VARCHAR(50), gender VARCHAR(10), age INT, position VARCHAR(20), country VARCHAR(50)); INSERT INTO reporters (id, name, gender, age, position, country) VALUES (1, 'Anna Smith', 'Female', 35, 'News Reporter', 'USA'); INSERT INTO reporters (id, name, gender, age, position, country) VALUES (2, 'Mike Johnson', 'Male', 40, 'Investigative Journalist', 'Canada'); INSERT INTO reporters (id, name, gender, age, position, country) VALUES (3, 'Sofia Rodriguez', 'Female', 32, 'Investigative Journalist', 'Mexico'); CREATE TABLE news_articles (id INT, title VARCHAR(100), content TEXT, publication_date DATE, reporter_id INT); INSERT INTO news_articles (id, title, content, publication_date, reporter_id) VALUES (1, 'News Article 1', 'Content of News Article 1', '2021-01-01', 2); INSERT INTO news_articles (id, title, content, publication_date, reporter_id) VALUES (2, 'News Article 2', 'Content of News Article 2', '2021-02-01', 3);", "reference_sql": "SELECT AVG(LENGTH(content) - LENGTH(REPLACE(content, ' ', '')) + 1) AS avg_word_count FROM news_articles WHERE reporter_id IN (SELECT id FROM reporters WHERE position = 'Investigative Journalist');", "generated_sql": "SELECT AVG(LENGTH(content) - LENGTH(REPLACE(content, ' ', '')) + 1) AS avg_word_count\nFROM news_articles\nWHERE reporter_id IN (\n    SELECT id\n    FROM reporters\n    WHERE position = 'Investigative Journalist'\n);", "raw_model_output": "To calculate the average word count of news articles written by investigative journalists, we need to follow these steps:\n\n1. Identify which reporters are investigative journalists.\n2. Retrieve the content of news articles written by those journalists.\n3. Calculate the word count for each article's content.\n4. Compute the average word count.\n\nHere is the SQL statement that accomplishes this task:\n\n```sql\nSELECT AVG(LENGTH(content) - LENGTH(REPLACE(content, ' ', '')) + 1) AS avg_word_count\nFROM news_articles\nWHERE reporter_id IN (\n    SELECT id\n    FROM reporters\n    WHERE position = 'Investigative Journalist'\n);\n```\n\n### Explanation:\n- The subquery `SELECT id FROM reporters WHERE position = 'Investigative Journalist'` retrieves the IDs of all reporters who are investigative journalists.\n- The main query selects news articles where the `reporter_id` matches one of these IDs.\n- For each article, it calculates the word count by determining the number of spaces in the content and adding 1 (since words are separated by spaces).\n- Finally, it computes the average of these word counts using `AVG()`.", "latency_sec": 6.132332801818848, "total_duration_sec": 6.127738551, "load_duration_sec": 0.020838473, "tokens_prompt": 351, "prompt_eval_sec": 0.060880246, "tokens_completion": 236, "completion_eval_sec": 6.044846827, "tokens_total": 587, "tokens_per_sec": 95.72213690455547, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "The Reference SQL and Generated SQL are identical in structure, logic, and syntax. Both calculate the average word count of news articles by filtering reporter_id values from reporters with the 'Investigative Journalist' position using the same subquery. No semantic differences exist between the two queries.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are identical in logic and structure, with the only difference being whitespace formatting. They correctly calculate the average word count by: 1) Using the standard method of counting words via length differences, 2) Filtering articles by investigative journalists through a subquery. The reference and generated queries produce identical results and fully address the business question about average word count for investigative journalism articles.", "overall_assessment": "correct"}}
{"example_id": 3635, "sql_complexity": "set operations", "prompt": "Which brands have certifications related to cruelty-free, vegan, or organic products?", "context": "CREATE TABLE brands (brand_name VARCHAR(50), is_cruelty_free BOOLEAN, is_vegan BOOLEAN, is_organic BOOLEAN); INSERT INTO brands (brand_name, is_cruelty_free, is_vegan, is_organic) VALUES ('Lush', TRUE, TRUE, FALSE), ('The Body Shop', TRUE, FALSE, FALSE), ('Est\u00e9e Lauder', FALSE, FALSE, FALSE), ('Urban Decay', TRUE, TRUE, FALSE), ('Maybelline', FALSE, FALSE, FALSE), ('Kat Von D', TRUE, TRUE, FALSE), ('Tarte', TRUE, TRUE, TRUE);", "reference_sql": "SELECT brand_name, 'Cruelty-free' as certification FROM brands WHERE is_cruelty_free = TRUE UNION SELECT brand_name, 'Vegan' as certification FROM brands WHERE is_vegan = TRUE UNION SELECT brand_name, 'Organic' as certification FROM brands WHERE is_organic = TRUE;", "generated_sql": "SELECT brand_name \nFROM brands \nWHERE is_cruelty_free = TRUE OR is_vegan = TRUE OR is_organic = BOOLEAN;", "raw_model_output": "To find the brands that have any of the certifications related to being cruelty-free, vegan, or organic, you can use a `SELECT` statement with a `WHERE` clause that checks for at least one of these conditions being true. Here's how you can write this query:\n\n```sql\nSELECT brand_name \nFROM brands \nWHERE is_cruelty_free = TRUE OR is_vegan = TRUE OR is_organic = BOOLEAN;\n```\n\nThis SQL statement selects the `brand_name` from the `brands` table where any of the columns `is_cruelty_free`, `is_vegan`, or `is_organic` are set to `TRUE`. This will return all brands that have at least one of these certifications.", "latency_sec": 3.8668222427368164, "total_duration_sec": 3.862232077, "load_duration_sec": 0.024483444, "tokens_prompt": 213, "prompt_eval_sec": 0.033029246, "tokens_completion": 150, "completion_eval_sec": 3.8035282, "tokens_total": 363, "tokens_per_sec": 93.87553324485894, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not equivalent. The Reference SQL returns brand names with their specific certification type (Cruelty-free/Vegan/Organic) as a separate column, while the Generated SQL only returns brand names without certification details. Additionally, the Generated SQL's WHERE clause contains invalid syntax ('is_organic = BOOLEAN') which would cause an error. Even if fixed, the Generated SQL would return distinct brands meeting any condition, whereas the Reference SQL could return duplicate brands for multiple certifications.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The Reference SQL is technically correct and semantically equivalent to the business intent. It explicitly lists brands with each certification type (cruelty-free, vegan, organic) using UNION to ensure distinct rows for each certification. The Generated SQL contains a critical syntax error: 'is_organic = BOOLEAN' is invalid (BOOLEAN is a keyword, not a value). Even if corrected to 'is_organic = TRUE', it would only return brand names without specifying which certification they hold, whereas the original question implies needing to know the type of certification. The Reference SQL better addresses the intent by providing both brand names and certification types.", "overall_assessment": "incorrect"}}
{"example_id": 4932, "sql_complexity": "basic SQL", "prompt": "Delete the workout row with the id of 2.", "context": "CREATE TABLE Workouts (id INT, user_id INT, workout_name TEXT, calories INT); INSERT INTO Workouts (id, user_id, workout_name, calories) VALUES (1, 1, 'Running', 300); INSERT INTO Workouts (id, user_id, workout_name, calories) VALUES (2, 1, 'Cycling', 400); INSERT INTO Workouts (id, user_id, workout_name, calories) VALUES (3, 2, 'Yoga', 200);", "reference_sql": "DELETE FROM Workouts WHERE id = 2;", "generated_sql": "DELETE FROM Workouts WHERE id = 2;", "raw_model_output": "To delete the workout row with an `id` of 2 from the `Workouts` table, you can use the following SQL statement:\n\n```sql\nDELETE FROM Workouts WHERE id = 2;\n```\n\nThis command will remove the row where the `id` column has a value of 2.", "latency_sec": 1.664175033569336, "total_duration_sec": 1.659470128, "load_duration_sec": 0.021563295, "tokens_prompt": 188, "prompt_eval_sec": 0.025095082, "tokens_completion": 64, "completion_eval_sec": 1.612090267, "tokens_total": 252, "tokens_per_sec": 151.4263793872141, "match_exact": true, "match_ast": true, "llm_equivalent": true, "llm_explanation": "Both queries are identical in structure and logic. They both delete the record with id=2 from the Workouts table, which corresponds to the 'Cycling' workout. The DELETE statements are exactly the same, so they will produce the same result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are identical in syntax, logic, and effect. They both correctly delete the row with id=2 from the Workouts table, matching the business requirement. The queries are equally efficient, semantically equivalent, and fulfill the intent of removing the specified workout record.", "overall_assessment": "correct"}}
{"example_id": 365, "sql_complexity": "aggregation", "prompt": "Identify the total number of military personnel and their corresponding rank for each branch and country in the 'military_personnel' table, sorted by the total number of personnel in descending order.", "context": "CREATE TABLE military_personnel (id INT, branch VARCHAR(255), rank VARCHAR(255), country VARCHAR(255), personnel INT);", "reference_sql": "SELECT branch, country, SUM(personnel) as total_personnel FROM military_personnel GROUP BY branch, country ORDER BY total_personnel DESC;", "generated_sql": "SELECT \n    branch,\n    country,\n    rank,\n    SUM(personnel) AS total_personnel\nFROM \n    military_personnel\nGROUP BY \n    branch, \n    country, \n    rank\nORDER BY \n    total_personnel DESC;", "raw_model_output": "```sql\nSELECT \n    branch,\n    country,\n    rank,\n    SUM(personnel) AS total_personnel\nFROM \n    military_personnel\nGROUP BY \n    branch, \n    country, \n    rank\nORDER BY \n    total_personnel DESC;\n```\n\nThis query groups the data by `branch`, `country`, and `rank` to calculate the sum of personnel for each combination. It then orders the results by the total number of personnel in descending order.", "latency_sec": 2.4761111736297607, "total_duration_sec": 2.470572862, "load_duration_sec": 0.011701733, "tokens_prompt": 137, "prompt_eval_sec": 0.016862276, "tokens_completion": 98, "completion_eval_sec": 2.441312194, "tokens_total": 235, "tokens_per_sec": 94.90688564500547, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their GROUP BY clauses. The reference query groups by (branch, country), while the generated query groups by (branch, country, rank). This makes the generated query aggregate personnel within each rank subgroup, producing more detailed but non-equivalent results. The inclusion of 'rank' in the SELECT and GROUP BY also changes the output structure.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "reference", "explanation": "The reference query correctly groups by branch and country to calculate total personnel per combination, while the generated query adds an unnecessary GROUP BY on rank. This causes the generated query to split results by rank within each branch/country, which contradicts the original question's requirement to aggregate personnel without rank segmentation. The reference query is technically correct, fulfills the business intent of summarizing total personnel per branch/country, and is more efficient. The generated query's inclusion of 'rank' in grouping and selection introduces semantic errors and misalignment with the original question's requirements.", "overall_assessment": "correct"}}
{"example_id": 521, "sql_complexity": "subqueries", "prompt": "How many vessels have not had an inspection in the past year?", "context": "CREATE TABLE safety_records(id INT, vessel_name VARCHAR(50), inspection_date DATE); CREATE TABLE vessels(id INT, name VARCHAR(50), country VARCHAR(50)); INSERT INTO vessels(id, name, country) VALUES (1, 'Vessel A', 'Philippines'), (2, 'Vessel B', 'Philippines'); INSERT INTO safety_records(id, vessel_name, inspection_date) VALUES (1, 'Vessel A', '2022-01-01');", "reference_sql": "SELECT COUNT(*) FROM vessels WHERE name NOT IN (SELECT vessel_name FROM safety_records WHERE inspection_date BETWEEN DATE_SUB(NOW(), INTERVAL 1 YEAR) AND NOW());", "generated_sql": "SELECT COUNT(DISTINCT v.id) AS vessels_without_recent_inspection\nFROM vessels v\nLEFT JOIN safety_records sr ON v.name = sr.vessel_name AND sr.inspection_date >= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)\nWHERE sr.id IS NULL;", "raw_model_output": "To determine how many vessels have not had an inspection in the past year, we need to identify vessels that do not appear in the `safety_records` table with an `inspection_date` within the last 365 days from today's date. We can achieve this by using a LEFT JOIN between the `vessels` and `safety_records` tables and filtering for those records where there is no inspection record or the inspection date is older than one year.\n\nHere's the SQL statement to accomplish that:\n\n```sql\nSELECT COUNT(DISTINCT v.id) AS vessels_without_recent_inspection\nFROM vessels v\nLEFT JOIN safety_records sr ON v.name = sr.vessel_name AND sr.inspection_date >= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)\nWHERE sr.id IS NULL;\n```\n\n### Explanation:\n- **`vessels v`:** We start by selecting from the `vessels` table.\n- **`LEFT JOIN safety_records sr ON v.name = sr.vessel_name AND sr.inspection_date >= DATE_SUB(CURDATE(), INTERVAL 1 YEAR)`:** This join attempts to match each vessel with any inspection records that occurred in the past year. The condition ensures we only consider inspections within the last year.\n- **`WHERE sr.id IS NULL`:** After the LEFT JOIN, if a vessel does not have an inspection record from the past year, `sr.id` will be `NULL`. We filter for these cases to find vessels without recent inspections.\n- **`COUNT(DISTINCT v.id) AS vessels_without_recent_inspection`:** Finally, we count the distinct IDs of such vessels to get the total number of vessels that have not been inspected in the past year.", "latency_sec": 8.876593112945557, "total_duration_sec": 8.855604769, "load_duration_sec": 0.01758136, "tokens_prompt": 181, "prompt_eval_sec": 0.028316639, "tokens_completion": 348, "completion_eval_sec": 8.807965057, "tokens_total": 529, "tokens_per_sec": 59.59493617303584, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries count vessels without a safety record in the last year. The Reference SQL uses NOT IN with a subquery filtering by date, while the Generated SQL uses a LEFT JOIN with a date condition and checks for NULL. Both approaches exclude vessels with any matching safety records in the specified period, and the date conditions are functionally equivalent. The COUNT(DISTINCT v.id) in the Generated SQL ensures unique vessel counts, matching the behavior of the Reference SQL's COUNT(*).", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly identify vessels without inspections in the past year, but with key differences:\n\n1. **Technical Correctness**: \n   - Reference uses NOT IN with a subquery that could fail if there are NULLs in vessel_name (though not present in sample data).\n   - Generated uses LEFT JOIN with explicit date filtering and checks for NULL, which is more robust.\n\n2. **Semantic Equivalence**: \n   - Both return count of vessels without recent inspections.\n   - Generated uses COUNT(DISTINCT v.id) which avoids overcounting if multiple safety records exist for a vessel.\n\n3. **Business Intent**: \n   - Both answer the question, but generated handles edge cases (e.g., multiple records per vessel) better.\n\n4. **Efficiency**: \n   - Generated's JOIN approach is typically more efficient than a subquery, especially with proper indexing.\n   - Uses CURDATE() instead of NOW() which is more appropriate for date comparisons.\n\nThe generated query is more elegant, efficient, and robust while maintaining semantic equivalence.", "overall_assessment": "correct"}}
{"example_id": 5687, "sql_complexity": "multiple_joins", "prompt": "List organizations with more than 200 volunteers, and their average donation amounts, excluding donations less than $10.", "context": "CREATE TABLE organizations (org_id INT, org_name TEXT, social_impact_score INT);CREATE TABLE volunteers (vol_id INT, org_id INT, vol_country TEXT);CREATE TABLE donations (donation_id INT, donor_id INT, donation_amount INT, donation_date DATE);", "reference_sql": "SELECT o.org_name, AVG(donation_amount) AS avg_donation_amount FROM organizations o JOIN volunteers v ON o.org_id = v.org_id JOIN donations don ON o.org_id = don.org_id WHERE donation_amount >= 10 GROUP BY o.org_name HAVING COUNT(v.vol_id) > 200;", "generated_sql": "SELECT \n    o.org_id,\n    o.org_name,\n    COALESCE(AVG(d.donation_amount), 0) AS avg_donation_amount\nFROM \n    organizations o\nLEFT JOIN \n    volunteers v ON o.org_id = v.org_id\nLEFT JOIN \n    donations d ON o.org_id = d.donor_id AND d.donation_amount >= 10\nGROUP BY \n    o.org_id, o.org_name\nHAVING \n    COUNT(DISTINCT v.vol_id) > 200;", "raw_model_output": "To solve this problem, we need to perform the following steps:\n\n1. Identify organizations that have more than 200 volunteers.\n2. Calculate the average donation amount for each organization, excluding donations less than $10.\n3. Join these results to get the desired output.\n\nHere's how you can write the SQL query:\n\n```sql\nSELECT \n    o.org_id,\n    o.org_name,\n    COALESCE(AVG(d.donation_amount), 0) AS avg_donation_amount\nFROM \n    organizations o\nLEFT JOIN \n    volunteers v ON o.org_id = v.org_id\nLEFT JOIN \n    donations d ON o.org_id = d.donor_id AND d.donation_amount >= 10\nGROUP BY \n    o.org_id, o.org_name\nHAVING \n    COUNT(DISTINCT v.vol_id) > 200;\n```\n\n### Explanation:\n\n- **FROM organizations o**: Start with the `organizations` table.\n  \n- **LEFT JOIN volunteers v ON o.org_id = v.org_id**: Join with the `volunteers` table to count volunteers per organization.\n\n- **LEFT JOIN donations d ON o.org_id = d.donor_id AND d.donation_amount >= 10**: Join with the `donations` table, filtering out donations less than $10.\n\n- **GROUP BY o.org_id, o.org_name**: Group by organization to calculate counts and averages.\n\n- **HAVING COUNT(DISTINCT v.vol_id) > 200**: Filter organizations that have more than 200 distinct volunteers.\n\n- **COALESCE(AVG(d.donation_amount), 0)**: Calculate the average donation amount, using `COALESCE` to handle cases where there are no donations (resulting in `NULL`).\n\nThis query will list organizations with more than 200 volunteers and their average donation amounts, excluding donations less than $10.", "latency_sec": 9.643732070922852, "total_duration_sec": 9.611123816, "load_duration_sec": 0.014860766, "tokens_prompt": 149, "prompt_eval_sec": 0.029042299, "tokens_completion": 379, "completion_eval_sec": 9.566482418, "tokens_total": 528, "tokens_per_sec": 54.7505878550889, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in several key aspects: 1) Join types (INNER vs LEFT) affect row inclusion. 2) The Generated SQL uses donor_id instead of org_id in the donations join (schema inconsistency). 3) Grouping by org_id+org_name vs org_name only. 4) COUNT(DISTINCT v.vol_id) vs COUNT(v.vol_id) in HAVING clause. 5) COALESCE handling of NULL averages vs no default in Reference. 6) Different output columns (org_id included in Generated). These differences ensure non-equivalent results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "Both queries have critical technical issues. The Reference SQL incorrectly joins donations on `org_id` (which doesn't exist in the donations table), while the Generated SQL incorrectly joins donations on `donor_id = o.org_id` (donor_id is a donor, not an organization). However, the Generated SQL uses LEFT JOINs and `COUNT(DISTINCT v.vol_id)` which better handles edge cases (e.g., organizations with no donations or volunteers). The Reference SQL's `GROUP BY o.org_name` risks grouping errors if org_names are non-unique. Neither query correctly links donations to organizations per the schema, but the Generated SQL is more robust in structure.", "overall_assessment": "differently_correct"}}
{"example_id": 1281, "sql_complexity": "subqueries", "prompt": "Find the top 3 contributors with the lowest recycling rate in the 'waste_contributors' table.", "context": "CREATE TABLE waste_contributors (contributor VARCHAR(20), recycling_rate FLOAT); INSERT INTO waste_contributors (contributor, recycling_rate) VALUES ('Manufacturing', 0.4), ('Commercial', 0.38), ('Residential', 0.35), ('Institutional', 0.32), ('Agricultural', 0.2), ('Industrial', 0.15);", "reference_sql": "SELECT contributor FROM waste_contributors WHERE recycling_rate IN (SELECT MIN(recycling_rate) FROM waste_contributors) LIMIT 3;", "generated_sql": "SELECT contributor, recycling_rate\nFROM waste_contributors\nORDER BY recycling_rate ASC\nLIMIT 3;", "raw_model_output": "To find the top 3 contributors with the lowest recycling rates from the `waste_contributors` table, you can use an SQL query that orders the data by the `recycling_rate` column in ascending order and limits the result to the first three rows. Here's how you can write this query:\n\n```sql\nSELECT contributor, recycling_rate\nFROM waste_contributors\nORDER BY recycling_rate ASC\nLIMIT 3;\n```\n\nThis query performs the following steps:\n- Selects the `contributor` and `recycling_rate` columns from the `waste_contributors` table.\n- Orders the results by `recycling_rate` in ascending order to ensure that contributors with the lowest rates appear first.\n- Limits the output to only the top 3 rows, which correspond to the three contributors with the lowest recycling rates.", "latency_sec": 4.285144805908203, "total_duration_sec": 4.279244182, "load_duration_sec": 0.01084841, "tokens_prompt": 176, "prompt_eval_sec": 0.025613188, "tokens_completion": 169, "completion_eval_sec": 4.241856, "tokens_total": 345, "tokens_per_sec": 80.51069815057976, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The reference query selects contributors with the minimum recycling rate (only 'Industrial' in this dataset) and limits to 3 rows. The generated query orders all contributors by ascending recycling rate and returns the top 3 (Industrial, Agricultural, Institutional). The first query focuses on the minimum value(s), while the second retrieves the three lowest values, resulting in different outputs.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query uses a subquery to find contributors with the absolute minimum recycling rate (which is 0.15 for 'Industrial') and applies LIMIT 3. However, this approach would only return contributors with the single lowest rate (potentially 1-2 rows) rather than the *top 3* lowest rates. The generated query correctly sorts all contributors by recycling_rate in ascending order and explicitly returns the first 3 rows, which aligns with the requirement for the 'top 3 contributors with the lowest recycling rate'. While both queries are technically valid, the generated query better fulfills the business intent by ensuring exactly 3 results and properly ranking all contributors.", "overall_assessment": "differently_correct"}}
{"example_id": 5669, "sql_complexity": "window functions", "prompt": "What is the total number of new and returning volunteers in each program in each month?", "context": "CREATE TABLE Volunteers (VolunteerID INT, VolunteerName TEXT, ProgramID INT, VolunteerDate DATE, IsReturning BOOLEAN); INSERT INTO Volunteers (VolunteerID, VolunteerName, ProgramID, VolunteerDate, IsReturning) VALUES (6, 'David Kim', 1, '2022-03-01', FALSE), (7, 'Emily Chen', 2, '2022-03-15', TRUE), (8, 'James Lee', 2, '2022-04-01', FALSE), (9, 'Grace Park', 3, '2022-04-15', TRUE), (10, 'Daniel Kim', 1, '2022-04-01', FALSE);", "reference_sql": "SELECT ProgramID, EXTRACT(MONTH FROM VolunteerDate) AS Month, SUM(CASE WHEN IsReturning THEN 1 ELSE 0 END) OVER (PARTITION BY ProgramID, EXTRACT(MONTH FROM VolunteerDate) ORDER BY ProgramID, EXTRACT(MONTH FROM VolunteerDate)) + COUNT(DISTINCT VolunteerID) OVER (PARTITION BY ProgramID, EXTRACT(MONTH FROM VolunteerDate) ORDER BY ProgramID, EXTRACT(MONTH FROM VolunteerDate)) AS TotalVolunteers FROM Volunteers;", "generated_sql": "SELECT \n    ProgramID,\n    EXTRACT(YEAR FROM VolunteerDate) AS Year,\n    EXTRACT(MONTH FROM VolunteerDate) AS Month,\n    SUM(CASE WHEN IsReturning = FALSE THEN 1 ELSE 0 END) AS NewVolunteers,\n    SUM(CASE WHEN IsReturning = TRUE THEN 1 ELSE 0 END) AS ReturningVolunteers\nFROM \n    Volunteers\nGROUP BY \n    ProgramID, \n    EXTRACT(YEAR FROM VolunteerDate), \n    EXTRACT(MONTH FROM VolunteerDate)\nORDER BY \n    ProgramID, Year, Month;", "raw_model_output": "To solve this problem, we need to count both new and returning volunteers for each program on a monthly basis. We can achieve this by grouping the data by `ProgramID` and the month extracted from `VolunteerDate`. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    ProgramID,\n    EXTRACT(YEAR FROM VolunteerDate) AS Year,\n    EXTRACT(MONTH FROM VolunteerDate) AS Month,\n    SUM(CASE WHEN IsReturning = FALSE THEN 1 ELSE 0 END) AS NewVolunteers,\n    SUM(CASE WHEN IsReturning = TRUE THEN 1 ELSE 0 END) AS ReturningVolunteers\nFROM \n    Volunteers\nGROUP BY \n    ProgramID, \n    EXTRACT(YEAR FROM VolunteerDate), \n    EXTRACT(MONTH FROM VolunteerDate)\nORDER BY \n    ProgramID, Year, Month;\n```\n\n### Explanation:\n\n- **SELECT Clause**: We select `ProgramID`, the year and month extracted from `VolunteerDate`, and two calculated columns: `NewVolunteers` and `ReturningVolunteers`.\n  \n- **EXTRACT Function**: This function is used to extract the year and month from the `VolunteerDate`. It helps in grouping the data by each program on a monthly basis.\n\n- **SUM with CASE Statement**: \n  - For `NewVolunteers`, we sum up instances where `IsReturning` is `FALSE`.\n  - For `ReturningVolunteers`, we sum up instances where `IsReturning` is `TRUE`.\n\n- **GROUP BY Clause**: We group the results by `ProgramID`, year, and month to get counts for each program in each month.\n\n- **ORDER BY Clause**: This orders the result set by `ProgramID`, then by year and month for better readability.", "latency_sec": 9.264858961105347, "total_duration_sec": 9.262041181, "load_duration_sec": 0.011415172, "tokens_prompt": 235, "prompt_eval_sec": 0.03665247, "tokens_completion": 363, "completion_eval_sec": 9.213226486, "tokens_total": 598, "tokens_per_sec": 64.54496528338467, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL uses window functions to calculate a running total of returning volunteers and distinct volunteers per ProgramID and month, without grouping, resulting in multiple rows per group. The Generated SQL aggregates data into one row per ProgramID, year, and month, separating new and returning volunteers. The output structure, aggregation logic, and result set shape differ significantly.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is technically flawed. It uses window functions incorrectly to calculate totals, resulting in duplicated counts (e.g., adding returning volunteers to total volunteers). It also fails to separate new and returning volunteers as required. The Generated SQL correctly groups by ProgramID, Year, and Month, using conditional aggregation to count new (IsReturning=FALSE) and returning (IsReturning=TRUE) volunteers separately. While the Generated SQL doesn't explicitly calculate a 'total' column, it fulfills the business intent by providing both metrics. The Reference SQL's approach would produce incorrect results due to window function misuse, while the Generated SQL is structurally sound and directly addresses the question.", "overall_assessment": "differently_correct"}}
{"example_id": 3576, "sql_complexity": "window functions", "prompt": "What is the difference in the number of eco-friendly hotels between the top 2 countries?", "context": "CREATE TABLE eco_hotel_count (country TEXT, num_hotels INT); INSERT INTO eco_hotel_count (country, num_hotels) VALUES ('France', 100), ('Italy', 120), ('Germany', 150), ('Spain', 110), ('UK', 160);", "reference_sql": "SELECT (MAX(num_hotels) OVER (PARTITION BY num_hotels <= 2) - MIN(num_hotels) OVER (PARTITION BY num_hotels <= 2)) AS hotel_difference FROM eco_hotel_count WHERE country IN ('France', 'Italy');", "generated_sql": "WITH TopTwoCountries AS (\n    SELECT country, num_hotels\n    FROM eco_hotel_count\n    ORDER BY num_hotels DESC\n    LIMIT 2\n)\nSELECT \n    MAX(num_hotels) - MIN(num_hotels) AS difference_in_num_hotels\nFROM \n    TopTwoCountries;", "raw_model_output": "To find the difference in the number of eco-friendly hotels between the top two countries with the most hotels, we can use a subquery to first determine these top two countries based on their `num_hotels` values. Then, we calculate the difference between their hotel counts.\n\nHere's the SQL statement:\n\n```sql\nWITH TopTwoCountries AS (\n    SELECT country, num_hotels\n    FROM eco_hotel_count\n    ORDER BY num_hotels DESC\n    LIMIT 2\n)\nSELECT \n    MAX(num_hotels) - MIN(num_hotels) AS difference_in_num_hotels\nFROM \n    TopTwoCountries;\n```\n\n### Explanation:\n1. **CTE (Common Table Expression)**: We use a CTE named `TopTwoCountries` to select the top two countries with the highest number of eco-friendly hotels.\n2. **Ordering and Limiting**: The `ORDER BY num_hotels DESC LIMIT 2` clause ensures that we only get the top two countries based on their hotel counts.\n3. **Calculating Difference**: In the main query, we calculate the difference between the maximum and minimum `num_hotels` values from the CTE result to find the difference in the number of hotels between these two countries.", "latency_sec": 6.409243106842041, "total_duration_sec": 6.400181776, "load_duration_sec": 0.01508209, "tokens_prompt": 149, "prompt_eval_sec": 0.019943431, "tokens_completion": 253, "completion_eval_sec": 6.364477398, "tokens_total": 402, "tokens_per_sec": 62.72191478754396, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL calculates the difference between max and min num_hotels for rows where num_hotels <= 2 (which are none in the filtered countries), resulting in NULL. However, the Generated SQL selects the top 2 hotels from the entire table (UK and Germany) and calculates their difference (160-150=10). The Reference SQL's WHERE clause restricts to France/Italy, while the Generated SQL operates on all countries, leading to different results.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL is fundamentally flawed. It incorrectly filters for only France and Italy (not the top 2 countries) and uses a nonsensical window function partitioning condition (num_hotels <= 2) that would return identical values for all rows. The Generated SQL correctly identifies the top 2 countries by ordering and limiting to 2 rows, then calculates the difference between their hotel counts. While both queries technically produce numerical results, only the Generated SQL addresses the actual business question of comparing the top 2 countries.", "overall_assessment": "incorrect"}}
{"example_id": 1970, "sql_complexity": "multiple_joins", "prompt": "List all players who have played a specific VR game, 'CyberSphere', and their ages.", "context": "CREATE TABLE Players (PlayerID INT, Age INT, Gender VARCHAR(10), Country VARCHAR(50)); CREATE TABLE VRPlayers (PlayerID INT, VRGameID INT); CREATE TABLE VRGames (VRGameID INT, Title VARCHAR(50)); INSERT INTO Players (PlayerID, Age, Gender, Country) VALUES (1, 25, 'Male', 'USA'); INSERT INTO Players (PlayerID, Age, Gender, Country) VALUES (2, 28, 'Female', 'Canada'); INSERT INTO VRPlayers (PlayerID, VRGameID) VALUES (1, 1); INSERT INTO VRPlayers (PlayerID, VRGameID) VALUES (2, 1); INSERT INTO VRGames (VRGameID, Title) VALUES (1, 'CyberSphere');", "reference_sql": "SELECT Players.Age, Players.PlayerID FROM Players INNER JOIN VRPlayers ON Players.PlayerID = VRPlayers.PlayerID INNER JOIN VRGames ON VRPlayers.VRGameID = VRGames.VRGameID WHERE VRGames.Title = 'CyberSphere';", "generated_sql": "SELECT p.PlayerID, p.Age\nFROM Players p\nJOIN VRPlayers vp ON p.PlayerID = vp.PlayerID\nJOIN VRGames vg ON vp.VRGameID = vg.VRGameID\nWHERE vg.Title = 'CyberSphere';", "raw_model_output": "To list all players who have played the specific VR game \"CyberSphere\" along with their ages, we need to join the `Players`, `VRPlayers`, and `VRGames` tables. We will filter the results based on the title of the VR game. Here is the SQL statement that accomplishes this:\n\n```sql\nSELECT p.PlayerID, p.Age\nFROM Players p\nJOIN VRPlayers vp ON p.PlayerID = vp.PlayerID\nJOIN VRGames vg ON vp.VRGameID = vg.VRGameID\nWHERE vg.Title = 'CyberSphere';\n```\n\nThis query works as follows:\n- It joins the `Players` table with the `VRPlayers` table on `PlayerID`.\n- Then, it joins the resulting dataset with the `VRGames` table on `VRGameID`.\n- Finally, it filters the results to include only those entries where the VR game title is \"CyberSphere\", and selects the player's ID and age.", "latency_sec": 5.1671142578125, "total_duration_sec": 5.160768023, "load_duration_sec": 0.011689082, "tokens_prompt": 252, "prompt_eval_sec": 0.038497789, "tokens_completion": 200, "completion_eval_sec": 5.109502918, "tokens_total": 452, "tokens_per_sec": 87.4762928488743, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries select the same columns (PlayerID and Age) from the Players table, join with VRPlayers and VRGames on identical conditions, and filter using the same WHERE clause (VRGames.Title = 'CyberSphere'). The differences are purely syntactic (alias names and column order) and do not affect the result.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are technically correct and produce identical results. They both join the Players, VRPlayers, and VRGames tables with the same conditions, filter for 'CyberSphere' via the VRGames.Title column, and select PlayerID and Age. The only difference is the use of table aliases in the generated query, which does not affect functionality. Both queries fulfill the business intent of listing players who played CyberSphere with their ages. The reference query is concise but the generated query uses aliases which may improve readability without sacrificing efficiency.", "overall_assessment": "correct"}}
{"example_id": 2414, "sql_complexity": "window functions", "prompt": "List the policy areas with the lowest citizen satisfaction scores.", "context": "CREATE TABLE Policy (Area VARCHAR(20), Score INT); INSERT INTO Policy (Area, Score) VALUES ('Transportation', 70), ('Education', 85), ('Healthcare', 75), ('PublicSafety', 80);", "reference_sql": "SELECT Area, Score FROM (SELECT Area, Score, ROW_NUMBER() OVER (ORDER BY Score) AS RN FROM Policy) X WHERE RN IN (1, 2);", "generated_sql": "SELECT Area, Score\nFROM Policy\nWHERE Score = (SELECT MIN(Score) FROM Policy);", "raw_model_output": "To find the policy areas with the lowest citizen satisfaction scores from the `Policy` table, we need to identify the minimum score and then select all entries that have this score. Here's how you can write the SQL query:\n\n```sql\nSELECT Area, Score\nFROM Policy\nWHERE Score = (SELECT MIN(Score) FROM Policy);\n```\n\nThis query works as follows:\n- The subquery `(SELECT MIN(Score) FROM Policy)` finds the lowest score in the `Policy` table.\n- The main query selects all rows from the `Policy` table where the `Score` matches this minimum value.", "latency_sec": 3.125607967376709, "total_duration_sec": 3.120300156, "load_duration_sec": 0.011889633, "tokens_prompt": 131, "prompt_eval_sec": 0.016597723, "tokens_completion": 124, "completion_eval_sec": 3.091199563, "tokens_total": 255, "tokens_per_sec": 81.5841278437804, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL retrieves the two lowest scores (using ROW_NUMBER() to rank by Score and filter RN=1,2), while the Generated SQL only retrieves the single minimum score. In the sample data, Reference returns ('Transportation', 70) and ('Healthcare', 75), whereas Generated only returns ('Transportation', 70).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query uses ROW_NUMBER() to select the first two rows ordered by Score, which may not correctly identify the lowest scores if there are ties or non-sequential values. For example, if multiple policies share the minimum score, the reference query would only return the first two (based on arbitrary ordering) rather than all policies with the minimum score. The generated query correctly identifies all policies with the minimum score using a subquery, ensuring it captures all instances of the lowest satisfaction scores. While both queries are technically valid, the generated query better fulfills the business intent of finding 'lowest' scores by focusing on the actual minimum value rather than positional ranking.", "overall_assessment": "correct"}}
{"example_id": 1898, "sql_complexity": "single join", "prompt": "What are the total sales for each drug in Q2 2020?", "context": "CREATE TABLE drugs (drug_id INT, drug_name TEXT); INSERT INTO drugs (drug_id, drug_name) VALUES (1001, 'Ibuprofen'), (1002, 'Paracetamol'), (1003, 'Aspirin'); CREATE TABLE sales (sale_id INT, drug_id INT, sale_date DATE, revenue FLOAT); INSERT INTO sales (sale_id, drug_id, sale_date, revenue) VALUES (1, 1001, '2020-04-05', 1800.0), (2, 1002, '2020-04-10', 2300.0), (3, 1003, '2020-04-15', 1400.0), (4, 1001, '2020-05-20', 1900.0), (5, 1002, '2020-06-25', 2400.0);", "reference_sql": "SELECT drug_name, SUM(revenue) as total_sales FROM sales JOIN drugs ON sales.drug_id = drugs.drug_id WHERE sale_date BETWEEN '2020-04-01' AND '2020-06-30' GROUP BY drug_name;", "generated_sql": "SELECT \n    d.drug_name,\n    SUM(s.revenue) AS total_sales\nFROM \n    sales s\nJOIN \n    drugs d ON s.drug_id = d.drug_id\nWHERE \n    s.sale_date BETWEEN '2020-04-01' AND '2020-06-30'\nGROUP BY \n    d.drug_name;", "raw_model_output": "To calculate the total sales for each drug in Q2 of 2020, we need to sum up the revenue from the `sales` table where the sale date falls within June and July of 2020. We will join this with the `drugs` table to get the names of the drugs.\n\nHere's the SQL query:\n\n```sql\nSELECT \n    d.drug_name,\n    SUM(s.revenue) AS total_sales\nFROM \n    sales s\nJOIN \n    drugs d ON s.drug_id = d.drug_id\nWHERE \n    s.sale_date BETWEEN '2020-04-01' AND '2020-06-30'\nGROUP BY \n    d.drug_name;\n```\n\n### Explanation:\n\n1. **Join Tables**: We join the `sales` table with the `drugs` table on `drug_id` to get access to both sales data and drug names.\n\n2. **Filter by Date**: The `WHERE` clause filters records where `sale_date` is between '2020-04-01' and '2020-06-30', which covers Q2 of 2020 (April, May, June).\n\n3. **Aggregate Sales**: We use the `SUM()` function to calculate total revenue for each drug.\n\n4. **Group by Drug Name**: The `GROUP BY` clause groups the results by `drug_name`, ensuring we get a separate total for each drug.", "latency_sec": 7.513215065002441, "total_duration_sec": 7.508992382, "load_duration_sec": 0.01596453, "tokens_prompt": 279, "prompt_eval_sec": 0.043530244, "tokens_completion": 292, "completion_eval_sec": 7.448816703, "tokens_total": 571, "tokens_per_sec": 75.99942169362278, "match_exact": false, "match_ast": false, "llm_equivalent": true, "llm_explanation": "Both queries perform an inner join between the 'sales' and 'drugs' tables on drug_id, filter sales within the date range '2020-04-01' to '2020-06-30', and group by drug_name to calculate total sales. The generated query uses table aliases (s for sales, d for drugs) but references the same columns and applies identical logic. The GROUP BY clause references the same drug_name column via the alias in the generated query, ensuring equivalent results.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "equal", "explanation": "Both queries are structurally identical in logic and output. The Reference SQL uses table names directly while the Generated SQL uses aliases (d/drugs, s/sales), which is a stylistic choice with no impact on results. Both correctly join the tables on drug_id, filter sales between 2020-04-01 and 2020-06-30 (covering Q2 2020), and group by drug_name to calculate total sales. The date range is accurate for Q2 (April-June). Both queries are equally efficient and fulfill the business intent of aggregating sales per drug for the specified quarter.", "overall_assessment": "correct"}}
{"example_id": 2403, "sql_complexity": "multiple_joins", "prompt": "Who is the most frequent customer ordering vegetarian items?", "context": "CREATE TABLE customers (customer_id INT, customer_name VARCHAR(50)); INSERT INTO customers VALUES (1, 'John Doe'), (2, 'Jane Smith'), (3, 'Alice Johnson'); CREATE TABLE orders (order_id INT, customer_id INT, menu_id INT, order_date DATE); INSERT INTO orders VALUES (1, 1, 1, '2022-01-01'), (2, 2, 3, '2022-01-02'), (3, 3, 2, '2022-01-03'); CREATE TABLE menu (menu_id INT, item_name VARCHAR(50), is_vegetarian BOOLEAN, price DECIMAL(5,2)); INSERT INTO menu VALUES (1, 'Veggie Burger', true, 8.99), (2, 'Cheeseburger', false, 7.99), (3, 'Tofu Stir Fry', true, 11.99);", "reference_sql": "SELECT customers.customer_name, COUNT(orders.order_id) as order_count FROM customers INNER JOIN orders ON customers.customer_id = orders.customer_id INNER JOIN menu ON orders.menu_id = menu.menu_id WHERE menu.is_vegetarian = true GROUP BY customers.customer_name ORDER BY order_count DESC LIMIT 1;", "generated_sql": "SELECT c.customer_name, COUNT(*) AS vegetarian_order_count\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN menu m ON o.menu_id = m.menu_id\nWHERE m.is_vegetarian = true\nGROUP BY c.customer_id, c.customer_name\nORDER BY vegetarian_order_count DESC\nLIMIT 1;", "raw_model_output": "To determine the most frequent customer who orders vegetarian items, we need to follow these steps:\n\n1. Join the `orders` table with the `menu` table on `menu_id` to get access to the `is_vegetarian` column.\n2. Filter the results to include only those orders where `is_vegetarian` is true.\n3. Join the filtered result with the `customers` table on `customer_id` to get customer names.\n4. Group by `customer_id` (or `customer_name`) and count the number of vegetarian orders for each customer.\n5. Order the results in descending order based on the count, and select the top customer.\n\nHere is the SQL query that accomplishes this:\n\n```sql\nSELECT c.customer_name, COUNT(*) AS vegetarian_order_count\nFROM customers c\nJOIN orders o ON c.customer_id = o.customer_id\nJOIN menu m ON o.menu_id = m.menu_id\nWHERE m.is_vegetarian = true\nGROUP BY c.customer_id, c.customer_name\nORDER BY vegetarian_order_count DESC\nLIMIT 1;\n```\n\nThis query will return the name of the customer who has placed the most orders for vegetarian items.", "latency_sec": 6.259706735610962, "total_duration_sec": 6.238526866, "load_duration_sec": 0.019910308, "tokens_prompt": 276, "prompt_eval_sec": 0.043706063, "tokens_completion": 241, "completion_eval_sec": 6.173857848, "tokens_total": 517, "tokens_per_sec": 82.59172862824852, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries differ in their GROUP BY clauses. The Reference SQL groups by customer_name, which may not be unique, while the Generated SQL groups by both customer_id and customer_name (ensuring uniqueness). This could lead to different results if multiple customers share the same name. Additionally, the Generated SQL uses COUNT(*) while the Reference uses COUNT(orders.order_id), but this difference is negligible here due to inner joins. However, the GROUP BY discrepancy makes them non-equivalent in general cases.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly identify the most frequent customer for vegetarian items by joining customers, orders, and menu tables with a vegetarian filter. The key difference lies in grouping: the reference query groups by customer_name (which could fail if names are duplicated) while the generated query groups by both customer_id and customer_name (ensuring accuracy). The generated query is more robust, uses clearer aliases, and follows better practices by grouping on the primary key. Both produce the same results in the given dataset, but the generated version is technically superior.", "overall_assessment": "differently_correct"}}
{"example_id": 124, "sql_complexity": "set operations", "prompt": "Find the intersection of AI and accessibility research projects in the EU and those in Africa.", "context": "CREATE SCHEMA if not exists accessibility; CREATE TABLE if not exists accessibility.research (id INT PRIMARY KEY, project_name VARCHAR(255), region VARCHAR(255)); INSERT INTO accessibility.research (id, project_name, region) VALUES (1, 'AI for Accessibility EU', 'EU'), (2, 'Accessibility Africa', 'Africa'), (3, 'AI for Accessibility Africa', 'Africa'), (4, 'Accessibility EU', 'EU');", "reference_sql": "SELECT project_name FROM accessibility.research WHERE region = 'EU' INTERSECT SELECT project_name FROM accessibility.research WHERE region = 'Africa';", "generated_sql": "WITH eu_projects AS (\n    SELECT id, project_name\n    FROM accessibility.research\n    WHERE region = 'EU'\n      AND project_name LIKE '%AI%'\n      AND project_name LIKE '%Accessibility%'\n),\nafrica_projects AS (\n    SELECT id, project_name\n    FROM accessibility.research\n    WHERE region = 'Africa'\n      AND project_name LIKE '%AI%'\n      AND project_name LIKE '%Accessibility%'\n)\nSELECT eu.id AS eu_id, africa.id AS africa_id, eu.project_name\nFROM eu_projects eu\nJOIN africa_projects africa ON eu.project_name = africa.project_name;", "raw_model_output": "To find the intersection of AI and accessibility research projects in both the EU and Africa, we need to identify projects that contain \"AI\" and \"Accessibility\" in their names for each region. Then, we'll determine which projects are common between these two regions.\n\nHere's the SQL query to achieve this:\n\n```sql\nWITH eu_projects AS (\n    SELECT id, project_name\n    FROM accessibility.research\n    WHERE region = 'EU'\n      AND project_name LIKE '%AI%'\n      AND project_name LIKE '%Accessibility%'\n),\nafrica_projects AS (\n    SELECT id, project_name\n    FROM accessibility.research\n    WHERE region = 'Africa'\n      AND project_name LIKE '%AI%'\n      AND project_name LIKE '%Accessibility%'\n)\nSELECT eu.id AS eu_id, africa.id AS africa_id, eu.project_name\nFROM eu_projects eu\nJOIN africa_projects africa ON eu.project_name = africa.project_name;\n```\n\nThis query uses Common Table Expressions (CTEs) to first filter the projects in the EU and Africa that contain both \"AI\" and \"Accessibility\" in their names. Then, it performs an inner join on these filtered results based on the project name to find common projects between the two regions.", "latency_sec": 5.896050930023193, "total_duration_sec": 5.889324307, "load_duration_sec": 0.016575611, "tokens_prompt": 180, "prompt_eval_sec": 0.024743112, "tokens_completion": 246, "completion_eval_sec": 5.847313137, "tokens_total": 426, "tokens_per_sec": 72.25175037596296, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses INTERSECT to find project names present in both 'EU' and 'Africa' regions, while the Generated SQL applies additional LIKE filters ('%AI%' and '%Accessibility%') on project names and performs a join. The Generated SQL's conditions restrict results to projects containing both 'AI' and 'Accessibility' in their names, which the Reference SQL does not enforce. This makes them semantically different.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The Reference SQL fails to incorporate the 'AI and accessibility' filter criteria entirely, directly returning project names that exist in both regions without checking their content. The Generated SQL correctly applies the required filters (project_name LIKE '%AI%' and LIKE '%Accessibility%') to both EU and Africa projects before finding their intersection. While both queries use different approaches (INTERSECT vs. JOIN), the Generated SQL explicitly enforces the business requirements. The Reference SQL would return incorrect results like 'Accessibility EU' and 'Accessibility Africa' if they existed in both regions, whereas the Generated SQL correctly filters out such cases.", "overall_assessment": "differently_correct"}}
{"example_id": 1231, "sql_complexity": "basic SQL", "prompt": "What is the average ticket price for performances at the 'Downtown Theater'?", "context": "CREATE TABLE DowntownTheater (show_name TEXT, date DATE, ticket_price FLOAT); INSERT INTO DowntownTheater (show_name, date, ticket_price) VALUES ('Play 1', '2022-01-01', 30.0), ('Play 2', '2022-01-02', 40.0), ('Concert 1', '2022-01-03', 50.0);", "reference_sql": "SELECT AVG(ticket_price) FROM DowntownTheater WHERE show_name = 'Downtown Theater'", "generated_sql": "SELECT AVG(ticket_price) AS average_ticket_price\nFROM DowntownTheater;", "raw_model_output": "To find the average ticket price for performances at the Downtown Theater, you can use the `AVG()` aggregate function in SQL. Here's the SQL statement that calculates this:\n\n```sql\nSELECT AVG(ticket_price) AS average_ticket_price\nFROM DowntownTheater;\n```\n\nThis query computes the average of all values in the `ticket_price` column from the `DowntownTheater` table and labels it as `average_ticket_price`.", "latency_sec": 2.1563050746917725, "total_duration_sec": 2.149847308, "load_duration_sec": 0.011801694, "tokens_prompt": 175, "prompt_eval_sec": 0.02359776, "tokens_completion": 89, "completion_eval_sec": 2.113698627, "tokens_total": 264, "tokens_per_sec": 122.43165547330393, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL filters for show_name = 'Downtown Theater' which doesn't exist in the sample data (returns NULL), while the Generated SQL calculates the average of all tickets. The WHERE clause in Reference SQL changes the result set significantly.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": false, "superiority": "generated", "explanation": "The reference query incorrectly filters for show_name = 'Downtown Theater', but the table contains shows like 'Play 1', 'Play 2', and 'Concert 1' - none of which match the filter. This would return NULL/0 instead of the actual average. The generated query correctly calculates the average of all ticket prices in the DowntownTheater table, which contains the relevant data. While neither query perfectly matches the business intent (the table name vs. show_name ambiguity), the generated query technically fulfills the requirement by averaging all performances in the correct dataset.", "overall_assessment": "differently_correct"}}
{"example_id": 1485, "sql_complexity": "set operations", "prompt": "How many public schools and public libraries exist in total, in the 'CityData' schema's 'CityEducation' and 'CityLibrary' tables?", "context": "CREATE SCHEMA CityData; CREATE TABLE CityEducation (Name varchar(255), Type varchar(255)); INSERT INTO CityEducation (Name, Type) VALUES ('SchoolA', 'Public'), ('SchoolB', 'Public'), ('SchoolC', 'Private'); CREATE TABLE CityLibrary (Name varchar(255), Type varchar(255)); INSERT INTO CityLibrary (Name, Type) VALUES ('LibraryA', 'Public'), ('LibraryB', 'Public'), ('LibraryC', 'Private');", "reference_sql": "SELECT COUNT(*) FROM CityData.CityEducation WHERE Type = 'Public' UNION ALL SELECT COUNT(*) FROM CityData.CityLibrary WHERE Type = 'Public';", "generated_sql": "SELECT SUM(public_count) AS total_public_entities\nFROM (\n    SELECT COUNT(*) AS public_count\n    FROM CityData.CityEducation\n    WHERE Type = 'Public'\n    \n    UNION ALL\n    \n    SELECT COUNT(*)\n    FROM CityData.CityLibrary\n    WHERE Type = 'Public'\n) AS combined_counts;", "raw_model_output": "To find out how many public schools and public libraries exist in total, you need to count the entries with `Type = 'Public'` from both the `CityEducation` and `CityLibrary` tables. You can achieve this by using a UNION ALL operation to combine the results of two separate queries that count the number of public entities in each table, and then summing these counts.\n\nHere is the SQL statement:\n\n```sql\nSELECT SUM(public_count) AS total_public_entities\nFROM (\n    SELECT COUNT(*) AS public_count\n    FROM CityData.CityEducation\n    WHERE Type = 'Public'\n    \n    UNION ALL\n    \n    SELECT COUNT(*)\n    FROM CityData.CityLibrary\n    WHERE Type = 'Public'\n) AS combined_counts;\n```\n\nThis query works as follows:\n- The first subquery counts the number of rows in `CityEducation` where `Type` is `'Public'`.\n- The second subquery counts the number of rows in `CityLibrary` where `Type` is `'Public'`.\n- These results are combined using `UNION ALL`, which allows duplicate values and preserves all counts.\n- Finally, the outer query sums these counts to get the total number of public schools and libraries.", "latency_sec": 5.944082021713257, "total_duration_sec": 5.938670019, "load_duration_sec": 0.013302234, "tokens_prompt": 200, "prompt_eval_sec": 0.03038778, "tokens_completion": 247, "completion_eval_sec": 5.894229297, "tokens_total": 447, "tokens_per_sec": 75.2008465507617, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns two separate counts (public entities in CityEducation and CityLibrary as two rows), while the Generated SQL sums those counts into a single row. The output structure and result differ (two rows vs. one row with summed value).", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL returns two separate counts (schools and libraries) as individual rows, while the Generated SQL properly aggregates them into a single total. Both are technically correct but produce different result structures. The Generated SQL better fulfills the business intent of providing a 'total' count. The Generated SQL is more elegant as it explicitly computes the sum, whereas the Reference SQL requires manual addition of results. The Generated query also handles potential future schema changes (e.g., additional tables) more gracefully.", "overall_assessment": "differently_correct"}}
{"example_id": 5806, "sql_complexity": "single join", "prompt": "List the top 3 countries with the most veteran employment in the IT industry", "context": "CREATE TABLE veteran_employment (employee_id INT, industry VARCHAR(255), salary DECIMAL(10,2), state VARCHAR(2), country VARCHAR(255)); CREATE TABLE countries (country_id INT, country VARCHAR(255));", "reference_sql": "SELECT country, COUNT(*) as num_veterans FROM veteran_employment JOIN countries ON veteran_employment.country = countries.country WHERE industry = 'IT' GROUP BY country ORDER BY num_veterans DESC LIMIT 3;", "generated_sql": "SELECT \n    ve.country,\n    COUNT(*) AS veteran_count\nFROM \n    veteran_employment ve\nWHERE \n    ve.industry = 'IT'\nGROUP BY \n    ve.country\nORDER BY \n    veteran_count DESC\nLIMIT 3;", "raw_model_output": "To solve this problem, we need to count the number of veterans employed in the IT industry for each country and then select the top three countries based on these counts. Here's how you can write the SQL query:\n\n```sql\nSELECT \n    ve.country,\n    COUNT(*) AS veteran_count\nFROM \n    veteran_employment ve\nWHERE \n    ve.industry = 'IT'\nGROUP BY \n    ve.country\nORDER BY \n    veteran_count DESC\nLIMIT 3;\n```\n\n### Explanation:\n- **SELECT**: We select the `country` column from the `veteran_employment` table and count the number of rows for each country using `COUNT(*)`.\n- **FROM**: The data is selected from the `veteran_employment` table, aliased as `ve`.\n- **WHERE**: We filter the records to include only those where the `industry` is 'IT'.\n- **GROUP BY**: We group the results by `country` to get counts for each country.\n- **ORDER BY**: We order the results in descending order based on the count of veterans (`veteran_count`) to find the top countries.\n- **LIMIT 3**: We limit the result to the top three countries with the most veteran employment in the IT industry.", "latency_sec": 6.128748178482056, "total_duration_sec": 6.122000513, "load_duration_sec": 0.015799299, "tokens_prompt": 134, "prompt_eval_sec": 0.017837509, "tokens_completion": 258, "completion_eval_sec": 6.086864032, "tokens_total": 392, "tokens_per_sec": 63.96085931158115, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL includes a JOIN with the countries table on veteran_employment.country = countries.country, which could filter results to only include countries present in the countries table. The Generated SQL omits this join, potentially including countries not present in the countries table. This difference in filtering may lead to different results, making the queries not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries correctly count IT industry veterans per country and return top 3 results. The reference query includes an unnecessary JOIN with the countries table, which doesn't add value since veteran_employment already contains the country column. The generated query is more efficient by avoiding this join while maintaining identical semantic results. Both fulfill the business intent of identifying countries with the highest IT veteran employment counts.", "overall_assessment": "correct"}}
{"example_id": 4126, "sql_complexity": "window functions", "prompt": "What is the average crime rate per capita in each neighborhood?", "context": "CREATE TABLE neighborhoods (name VARCHAR(255), population INT, crime_count INT); INSERT INTO neighborhoods (name, population, crime_count) VALUES ('Central Park', 1000, 25), ('Harlem', 2500, 75), ('Brooklyn', 5000, 120);", "reference_sql": "SELECT name, AVG(crime_count/population) OVER (PARTITION BY name) FROM neighborhoods;", "generated_sql": "SELECT \n    name,\n    (CAST(crime_count AS FLOAT) / population) AS crime_rate_per_capita\nFROM \n    neighborhoods;", "raw_model_output": "To calculate the average crime rate per capita for each neighborhood, you need to divide the `crime_count` by the `population` for each neighborhood. Here's how you can write this as an SQL query:\n\n```sql\nSELECT \n    name,\n    (CAST(crime_count AS FLOAT) / population) AS crime_rate_per_capita\nFROM \n    neighborhoods;\n```\n\n### Explanation:\n- **SELECT**: We are selecting two columns: `name` and the calculated `crime_rate_per_capita`.\n- **CAST**: The `crime_count` is cast to a floating-point number to ensure that division results in a decimal rather than an integer. This is important for accuracy, especially when dealing with small populations.\n- **Division**: We divide `crime_count` by `population` to get the crime rate per capita.\n- **AS**: We use `AS` to give a name (`crime_rate_per_capita`) to the calculated column for clarity in the result set.", "latency_sec": 4.72196888923645, "total_duration_sec": 4.715042063, "load_duration_sec": 0.01205111, "tokens_prompt": 145, "prompt_eval_sec": 0.020374764, "tokens_completion": 198, "completion_eval_sec": 4.681562734, "tokens_total": 343, "tokens_per_sec": 72.63919099125273, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses an AVG() window function with PARTITION BY name, which would return the same value for each row within the same name group (but the number of rows remains unchanged). The Generated SQL directly computes the ratio for each row. While they produce the same results for the given sample data (where each name is unique), they are not equivalent in general. If multiple rows shared the same name, the Reference SQL would return the average ratio for each row in the group, whereas the Generated SQL would return individual ratios. Thus, they are not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": true, "fulfills_intent": true, "superiority": "generated", "explanation": "Both queries produce the same numerical results for the given dataset. The reference query uses an unnecessary window function (AVG(...) OVER (PARTITION BY name)) which, for single-row neighborhoods, returns the same value as the raw calculation. The generated query directly computes the crime rate per capita with explicit type casting to ensure floating-point division. While technically equivalent, the generated query is more efficient, readable, and directly addresses the business intent by avoiding overcomplicated logic.", "overall_assessment": "differently_correct"}}
{"example_id": 4559, "sql_complexity": "basic SQL", "prompt": "List the top 3 energy efficient appliances in the US by energy star rating?", "context": "CREATE TABLE appliances (id INT, name VARCHAR(255), country VARCHAR(255), energy_star_rating INT); INSERT INTO appliances (id, name, country, energy_star_rating) VALUES (1, 'Fridge A', 'USA', 5), (2, 'TV B', 'USA', 4), (3, 'Laptop C', 'USA', 5), (4, 'Microwave D', 'USA', 3);", "reference_sql": "SELECT name, energy_star_rating FROM appliances WHERE country = 'USA' ORDER BY energy_star_rating DESC LIMIT 3;", "generated_sql": "SELECT id, name, country, energy_star_rating\nFROM appliances\nWHERE country = 'USA'\nORDER BY energy_star_rating DESC, id ASC\nLIMIT 3;", "raw_model_output": "To list the top 3 energy-efficient appliances in the US based on their Energy Star rating, you can use the following SQL query:\n\n```sql\nSELECT id, name, country, energy_star_rating\nFROM appliances\nWHERE country = 'USA'\nORDER BY energy_star_rating DESC, id ASC\nLIMIT 3;\n```\n\n### Explanation:\n- **`WHERE country = 'USA'`:** Filters the results to only include appliances from the USA.\n- **`ORDER BY energy_star_rating DESC, id ASC`:** Orders the filtered results by `energy_star_rating` in descending order (highest rating first). In case of ties in ratings, it orders by `id` in ascending order as a secondary criterion.\n- **`LIMIT 3`:** Restricts the output to the top 3 appliances based on the ordering criteria.", "latency_sec": 4.0520429611206055, "total_duration_sec": 4.045184576, "load_duration_sec": 0.014224574, "tokens_prompt": 180, "prompt_eval_sec": 0.024255618, "tokens_completion": 169, "completion_eval_sec": 4.00561792, "tokens_total": 349, "tokens_per_sec": 86.12939283928098, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL selects only 'name' and 'energy_star_rating', while the Generated SQL includes all columns ('id', 'name', 'country', 'energy_star_rating'). Additionally, the Generated SQL adds an explicit 'id ASC' sort order in case of ties in 'energy_star_rating', which could affect the rows returned when multiple entries have the same energy rating. The LIMIT 3 clause may also capture different rows due to the differing ORDER BY logic.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "reference", "explanation": "The queries are not technically equivalent. The Reference SQL selects only name and energy_star_rating, while the Generated SQL includes all columns (id, name, country, energy_star_rating). The Generated query adds an additional ORDER BY clause for id ASC, which would deterministically break ties in energy_star_rating but wasn't requested. Both correctly filter USA appliances and sort by energy_star_rating descending. The Reference query is more precise for the business question as it avoids unnecessary columns. The Generated query's extra ordering criterion isn't required by the original question.", "overall_assessment": "correct"}}
{"example_id": 456, "sql_complexity": "window functions", "prompt": "List the intelligence operations and their corresponding threat levels, and rank them based on their threat level and budget.", "context": "CREATE TABLE intel_ops_threat (id INT, operation VARCHAR, threat VARCHAR, budget INT); INSERT INTO intel_ops_threat (id, operation, threat, budget) VALUES (1, 'Operation Red Folder', 'High', 5000000), (2, 'Operation Black Vault', 'Medium', 7000000), (3, 'Operation Blue Sail', 'Low', 6000000);", "reference_sql": "SELECT operation, threat, budget, ROW_NUMBER() OVER (PARTITION BY threat ORDER BY budget DESC) as rank FROM intel_ops_threat;", "generated_sql": "SELECT \n    operation,\n    threat,\n    budget,\n    CASE \n        WHEN threat = 'High' THEN 1\n        WHEN threat = 'Medium' THEN 2\n        WHEN threat = 'Low' THEN 3\n    END AS threat_rank\nFROM \n    intel_ops_threat\nORDER BY \n    threat_rank, -- Sort by threat level first (High to Low)\n    budget DESC; -- Then sort by budget in descending order within each threat level", "raw_model_output": "To list the intelligence operations along with their corresponding threat levels and rank them based on both threat level and budget, we can use a combination of `CASE` statements to assign numerical values to each threat level for sorting purposes. Here's how you can construct the SQL query:\n\n```sql\nSELECT \n    operation,\n    threat,\n    budget,\n    CASE \n        WHEN threat = 'High' THEN 1\n        WHEN threat = 'Medium' THEN 2\n        WHEN threat = 'Low' THEN 3\n    END AS threat_rank\nFROM \n    intel_ops_threat\nORDER BY \n    threat_rank, -- Sort by threat level first (High to Low)\n    budget DESC; -- Then sort by budget in descending order within each threat level\n```\n\n### Explanation:\n- The `CASE` statement assigns a numerical rank to each threat level: 'High' is ranked 1, 'Medium' is ranked 2, and 'Low' is ranked 3.\n- The `ORDER BY` clause first sorts the results by `threat_rank`, ensuring that operations with higher threat levels appear first.\n- Within each threat level group, it further sorts by `budget` in descending order to rank operations with larger budgets higher.", "latency_sec": 5.989821910858154, "total_duration_sec": 5.985868449, "load_duration_sec": 0.023935392, "tokens_prompt": 176, "prompt_eval_sec": 0.023378079, "tokens_completion": 250, "completion_eval_sec": 5.937343335, "tokens_total": 426, "tokens_per_sec": 71.12064537808061, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The queries are not semantically equivalent. The Reference SQL uses a window function to assign a row number within each threat partition ordered by budget, while the Generated SQL uses a static CASE-based ranking and explicitly sorts the results. The generated query's 'threat_rank' column assigns fixed values (1, 2, 3) based on threat levels, whereas the reference query's 'rank' column reflects dynamic row numbers within threat groups. Additionally, the generated query includes an ORDER BY clause which the reference query lacks.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The queries are not technically equivalent. The Reference SQL uses ROW_NUMBER() to rank within threat groups by budget, while the Generated SQL assigns explicit threat ranks (1-3) and orders by threat level then budget. The original question asks to 'rank based on threat level and budget' - the Generated SQL directly addresses this by creating a threat_rank column and ordering by both threat and budget. The Reference SQL only ranks within threat categories, not across all operations. While both are syntactically correct, the Generated SQL better fulfills the business intent of ordering operations by threat level priority and budget magnitude. The Reference SQL's approach would produce different results (per-threat rankings vs. global rankings).", "overall_assessment": "differently_correct"}}
{"example_id": 459, "sql_complexity": "set operations", "prompt": "What is the total installed capacity of hydroelectric power plants in Brazil and Canada?", "context": "CREATE TABLE hydroelectric_power (country TEXT, capacity INTEGER); INSERT INTO hydroelectric_power (country, capacity) VALUES ('Brazil', 104000), ('Canada', 78000), ('China', 350000), ('United States', 100000), ('Russia', 45000);", "reference_sql": "(SELECT capacity FROM hydroelectric_power WHERE country = 'Brazil') UNION (SELECT capacity FROM hydroelectric_power WHERE country = 'Canada');", "generated_sql": "SELECT SUM(capacity) AS total_capacity\nFROM hydroelectric_power\nWHERE country IN ('Brazil', 'Canada');", "raw_model_output": "To find the total installed capacity of hydroelectric power plants in Brazil and Canada, you can use the following SQL query:\n\n```sql\nSELECT SUM(capacity) AS total_capacity\nFROM hydroelectric_power\nWHERE country IN ('Brazil', 'Canada');\n```\n\nThis query calculates the sum of the `capacity` column for rows where the `country` is either 'Brazil' or 'Canada'.", "latency_sec": 1.9359619617462158, "total_duration_sec": 1.927165332, "load_duration_sec": 0.013960669, "tokens_prompt": 147, "prompt_eval_sec": 0.018113089, "tokens_completion": 80, "completion_eval_sec": 1.894271588, "tokens_total": 227, "tokens_per_sec": 117.25436991295457, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL returns two separate capacity values (Brazil and Canada) as individual rows, while the Generated SQL returns a single summed value of both countries' capacities. The output structures differ (two rows vs. one row with a total), so they are not semantically equivalent.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The reference query uses UNION to combine separate capacity values for Brazil and Canada, which would return two rows of individual capacities rather than a single total. The generated query correctly uses SUM() with a WHERE clause to calculate the combined total. While both queries retrieve data about Brazil and Canada, only the generated query addresses the explicit request for 'total installed capacity.' The generated query is also more efficient and semantically aligned with the business intent of aggregating values.", "overall_assessment": "correct"}}
{"example_id": 2356, "sql_complexity": "window functions", "prompt": "Find the total billing amount for attorneys in the 'Criminal Law' practice area, for the year 2020, partitioned by attorney's last name and ordered by the total billing amount in descending order.", "context": "CREATE TABLE Attorneys (AttorneyID INT, FirstName VARCHAR(50), LastName VARCHAR(50), PracticeArea VARCHAR(50), TotalBilling FLOAT, BillingYear INT); INSERT INTO Attorneys (AttorneyID, FirstName, LastName, PracticeArea, TotalBilling, BillingYear) VALUES (1, 'Clara', 'Rivera', 'Personal Injury', 8000.00, 2020), (2, 'Jamal', 'Lee', 'Personal Injury', 6000.00, 2019), (3, 'Sophia', 'Gomez', 'Criminal Law', 9000.00, 2020);", "reference_sql": "SELECT LastName, SUM(TotalBilling) OVER (PARTITION BY PracticeArea, LastName, BillingYear) AS TotalBilling FROM Attorneys WHERE PracticeArea = 'Criminal Law' AND BillingYear = 2020 ORDER BY TotalBilling DESC;", "generated_sql": "SELECT LastName, SUM(TotalBilling) AS TotalBillingAmount\nFROM Attorneys\nWHERE PracticeArea = 'Criminal Law' AND BillingYear = 2020\nGROUP BY LastName\nORDER BY TotalBillingAmount DESC;", "raw_model_output": "To solve this problem, we need to write an SQL query that calculates the total billing amount for attorneys who are in the 'Criminal Law' practice area for the year 2020. The results should be partitioned by each attorney's last name and ordered by the total billing amount in descending order.\n\nHere is the SQL statement:\n\n```sql\nSELECT LastName, SUM(TotalBilling) AS TotalBillingAmount\nFROM Attorneys\nWHERE PracticeArea = 'Criminal Law' AND BillingYear = 2020\nGROUP BY LastName\nORDER BY TotalBillingAmount DESC;\n```\n\n### Explanation:\n- **SELECT**: We select `LastName` and the sum of `TotalBilling`, which we alias as `TotalBillingAmount`.\n- **FROM Attorneys**: This specifies that we are querying from the `Attorneys` table.\n- **WHERE PracticeArea = 'Criminal Law' AND BillingYear = 2020**: Filters the records to include only those attorneys who practice in 'Criminal Law' and have billing data for the year 2020.\n- **GROUP BY LastName**: Groups the results by each attorney's last name, which allows us to calculate the total billing amount per attorney.\n- **ORDER BY TotalBillingAmount DESC**: Orders the grouped results by the calculated `TotalBillingAmount` in descending order.", "latency_sec": 6.454927206039429, "total_duration_sec": 6.44976883, "load_duration_sec": 0.016447611, "tokens_prompt": 246, "prompt_eval_sec": 0.035678635, "tokens_completion": 266, "completion_eval_sec": 6.39673526, "tokens_total": 512, "tokens_per_sec": 79.31925235670467, "match_exact": false, "match_ast": false, "llm_equivalent": false, "llm_explanation": "The Reference SQL uses a window function that retains all rows (with duplicate LastName entries if present) and calculates the sum per partition, while the Generated SQL groups by LastName, collapsing multiple rows into a single row per LastName. This difference in output structure (number of rows) makes them non-equivalent in general cases, even though they may produce the same result for the provided sample data.", "enhanced_judgment": {"technically_equivalent": false, "fulfills_intent": true, "superiority": "generated", "explanation": "The Reference SQL uses a window function with redundant partitions (PracticeArea and BillingYear) that are already filtered by the WHERE clause, leading to unnecessary complexity. It also fails to group results, which could produce duplicate rows for attorneys with multiple entries. The Generated SQL correctly uses GROUP BY to aggregate billing amounts by LastName, ensuring accurate totals. Both queries filter for 'Criminal Law' and 2020, but the Generated SQL's approach aligns better with the business intent of summarizing totals per attorney. The Generated SQL is more efficient and semantically precise.", "overall_assessment": "differently_correct"}}
